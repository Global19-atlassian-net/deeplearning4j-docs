<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_161) on Thu Aug 09 02:12:59 PDT 2018 -->
<title>MultiLayerNetwork</title>
<meta name="date" content="2018-08-09">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="MultiLayerNetwork";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":10,"i1":42,"i2":10,"i3":10,"i4":10,"i5":10,"i6":10,"i7":10,"i8":10,"i9":10,"i10":10,"i11":10,"i12":10,"i13":10,"i14":10,"i15":10,"i16":10,"i17":10,"i18":10,"i19":10,"i20":10,"i21":10,"i22":10,"i23":10,"i24":10,"i25":10,"i26":10,"i27":10,"i28":10,"i29":10,"i30":10,"i31":10,"i32":10,"i33":10,"i34":10,"i35":10,"i36":10,"i37":10,"i38":10,"i39":10,"i40":10,"i41":10,"i42":10,"i43":10,"i44":10,"i45":10,"i46":10,"i47":10,"i48":10,"i49":10,"i50":10,"i51":10,"i52":10,"i53":10,"i54":10,"i55":10,"i56":10,"i57":10,"i58":10,"i59":10,"i60":10,"i61":10,"i62":10,"i63":10,"i64":10,"i65":10,"i66":10,"i67":10,"i68":10,"i69":10,"i70":10,"i71":10,"i72":10,"i73":10,"i74":10,"i75":9,"i76":10,"i77":10,"i78":10,"i79":9,"i80":10,"i81":10,"i82":10,"i83":10,"i84":10,"i85":10,"i86":10,"i87":10,"i88":10,"i89":10,"i90":10,"i91":10,"i92":10,"i93":10,"i94":10,"i95":10,"i96":10,"i97":10,"i98":10,"i99":10,"i100":10,"i101":10,"i102":10,"i103":10,"i104":10,"i105":9,"i106":10,"i107":10,"i108":10,"i109":10,"i110":10,"i111":10,"i112":10,"i113":10,"i114":10,"i115":10,"i116":10,"i117":10,"i118":10,"i119":10,"i120":10,"i121":10,"i122":10,"i123":10,"i124":10,"i125":10,"i126":10,"i127":10,"i128":10,"i129":10,"i130":10,"i131":10,"i132":10,"i133":10,"i134":10,"i135":10,"i136":10,"i137":10,"i138":10,"i139":10,"i140":10,"i141":10,"i142":10,"i143":10,"i144":10,"i145":10,"i146":10,"i147":10,"i148":10,"i149":10,"i150":10,"i151":10,"i152":10,"i153":10,"i154":10,"i155":10,"i156":10,"i157":10,"i158":10,"i159":10,"i160":10,"i161":10,"i162":10,"i163":10,"i164":10,"i165":10,"i166":10,"i167":10,"i168":10,"i169":10,"i170":10,"i171":10,"i172":10,"i173":10,"i174":10,"i175":10,"i176":10,"i177":10,"i178":10,"i179":10,"i180":10,"i181":10,"i182":10,"i183":10,"i184":10};
var tabs = {65535:["t0","All Methods"],1:["t1","Static Methods"],2:["t2","Instance Methods"],8:["t4","Concrete Methods"],32:["t6","Deprecated Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev&nbsp;Class</li>
<li>Next&nbsp;Class</li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" target="_top">Frames</a></li>
<li><a href="MultiLayerNetwork.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.deeplearning4j.nn.multilayer</div>
<h2 title="Class MultiLayerNetwork" class="title">Class MultiLayerNetwork</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.deeplearning4j.nn.multilayer.MultiLayerNetwork</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, java.lang.Cloneable, <a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a>, <a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>, <a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a>, <a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html" title="interface in org.deeplearning4j.nn.api">NeuralNetwork</a>, <a href="../../../../org/deeplearning4j/nn/api/Trainable.html" title="interface in org.deeplearning4j.nn.api">Trainable</a></dd>
</dl>
<hr>
<br>
<pre>public class <span class="typeNameLabel">MultiLayerNetwork</span>
extends java.lang.Object
implements java.io.Serializable, <a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a>, <a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>, <a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html" title="interface in org.deeplearning4j.nn.api">NeuralNetwork</a></pre>
<div class="block">MultiLayerNetwork is a neural network with multiple layers in a stack, and usually an output layer.
 For neural networks with a more complex connection architecture, use <a href="../../../../org/deeplearning4j/nn/graph/ComputationGraph.html" title="class in org.deeplearning4j.nn.graph"><code>ComputationGraph</code></a>
 which allows for an arbitrary directed acyclic graph connection structure between layers.
 MultiLayerNetwork is trainable via backprop, with optional pretraining, depending on the type of layers it contains.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../serialized-form.html#org.deeplearning4j.nn.multilayer.MultiLayerNetwork">Serialized Form</a></dd>
</dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested.class.summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<ul class="blockList">
<li class="blockList"><a name="nested.classes.inherited.from.class.org.deeplearning4j.nn.api.Layer">
<!--   -->
</a>
<h3>Nested classes/interfaces inherited from interface&nbsp;org.deeplearning4j.nn.api.<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></h3>
<code><a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>, <a href="../../../../org/deeplearning4j/nn/api/Layer.Type.html" title="enum in org.deeplearning4j.nn.api">Layer.Type</a></code></li>
</ul>
</li>
</ul>
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clearTbpttState">clearTbpttState</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#defaultConfiguration">defaultConfiguration</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#flattenedGradients">flattenedGradients</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#flattenedParams">flattenedParams</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#gradient">gradient</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected java.util.Map&lt;java.lang.String,org.bytedeco.javacpp.Pointer&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#helperWorkspaces">helperWorkspaces</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initCalled">initCalled</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initDone">initDone</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#input">input</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#labels">labels</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.lang.ThreadLocal&lt;java.lang.Long&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#lastEtlTime">lastEtlTime</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layerIndex">layerIndex</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.LinkedHashMap&lt;java.lang.String,<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layerMap">layerMap</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layers">layers</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layerWiseConfigurations">layerWiseConfigurations</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#mask">mask</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score">score</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/deeplearning4j/optimize/Solver.html" title="class in org.deeplearning4j.optimize">Solver</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#solver">solver</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#trainingListeners">trainingListeners</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#WS_ALL_LAYERS_ACT">WS_ALL_LAYERS_ACT</a></span></code>
<div class="block">Workspace for storing all layers' activations - used only to store activations (layer inputs) as part of backprop
 Not used for inference</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static <a href="../../../../org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.html" title="class in org.nd4j.linalg.api.memory.conf">WorkspaceConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#WS_ALL_LAYERS_ACT_CONFIG">WS_ALL_LAYERS_ACT_CONFIG</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#WS_LAYER_ACT_1">WS_LAYER_ACT_1</a></span></code>
<div class="block">Next 2 workspaces: used for:
 (a) Inference: holds activations for one layer only
 (b) Backprop: holds activation gradients for one layer only
 In both cases, they are opened and closed on every second layer</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#WS_LAYER_ACT_2">WS_LAYER_ACT_2</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.html" title="class in org.nd4j.linalg.api.memory.conf">WorkspaceConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#WS_LAYER_ACT_X_CONFIG">WS_LAYER_ACT_X_CONFIG</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#WS_LAYER_WORKING_MEM">WS_LAYER_WORKING_MEM</a></span></code>
<div class="block">Workspace for working memory for a single layer: forward pass and backward pass
 Note that this is opened/closed once per op (activate/backpropGradient call)</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../../org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.html" title="class in org.nd4j.linalg.api.memory.conf">WorkspaceConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#WS_LAYER_WORKING_MEM_CONFIG">WS_LAYER_WORKING_MEM_CONFIG</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected static java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#WS_RNN_LOOP_WORKING_MEM">WS_RNN_LOOP_WORKING_MEM</a></span></code>
<div class="block">Workspace for working memory in RNNs - opened and closed once per RNN time step</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected static <a href="../../../../org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.html" title="class in org.nd4j.linalg.api.memory.conf">WorkspaceConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#WS_RNN_LOOP_WORKING_MEM_CONFIG">WS_RNN_LOOP_WORKING_MEM_CONFIG</a></span></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colOne" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#MultiLayerNetwork-org.deeplearning4j.nn.conf.MultiLayerConfiguration-">MultiLayerNetwork</a></span>(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;conf)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#MultiLayerNetwork-org.deeplearning4j.nn.conf.MultiLayerConfiguration-org.nd4j.linalg.api.ndarray.INDArray-">MultiLayerNetwork</a></span>(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;conf,
                 <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;params)</code>
<div class="block">Initialize the network based on the configuraiton</div>
</td>
</tr>
<tr class="altColor">
<td class="colOne"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#MultiLayerNetwork-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">MultiLayerNetwork</a></span>(java.lang.String&nbsp;conf,
                 <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;params)</code>
<div class="block">Initialize the network based on the configuration</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">Static Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t2" class="tableTab"><span><a href="javascript:show(2);">Instance Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t6" class="tableTab"><span><a href="javascript:show(32);">Deprecated Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate-boolean-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">activate</a></span>(boolean&nbsp;training,
        <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;mgr)</code>
<div class="block">Perform forward pass and return the activations array with the last set input</div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate-org.nd4j.linalg.api.ndarray.INDArray-">activate</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</code>
<div class="block"><span class="deprecatedLabel">Deprecated.</span>&nbsp;
<div class="block"><span class="deprecationComment">Use <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-"><code>output(INDArray)</code></a></span></div>
</div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">activate</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
        boolean&nbsp;training,
        <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;mgr)</code>
<div class="block">Perform forward pass and return the activations array with the specified input</div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">activate</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
        <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</code>&nbsp;</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activate-org.deeplearning4j.nn.api.Layer.TrainingMode-">activate</a></span>(<a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</code>&nbsp;</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activateSelectedLayers-int-int-org.nd4j.linalg.api.ndarray.INDArray-">activateSelectedLayers</a></span>(int&nbsp;from,
                      int&nbsp;to,
                      <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</code>
<div class="block">Calculate activation for few layers at once.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#activationFromPrevLayer-int-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">activationFromPrevLayer</a></span>(int&nbsp;curr,
                       <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                       boolean&nbsp;training,
                       <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;mgr)</code>&nbsp;</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#addListeners-org.deeplearning4j.optimize.api.TrainingListener...-">addListeners</a></span>(<a href="../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>...&nbsp;listeners)</code>
<div class="block">This method ADDS additional TrainingListener to existing listeners</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#allowInputModification-boolean-">allowInputModification</a></span>(boolean&nbsp;allow)</code>
<div class="block">A performance optimization: mark whether the layer is allowed to modify its input array in-place.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#applyConstraints-int-int-">applyConstraints</a></span>(int&nbsp;iteration,
                int&nbsp;epoch)</code>
<div class="block">Apply any constraints to the model</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/primitives/Pair.html" title="class in org.nd4j.linalg.primitives">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#backpropGradient-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">backpropGradient</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;epsilon,
                <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;workspaceMgr)</code>
<div class="block">Calculate the gradient relative to the error in the next layer</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#batchSize--">batchSize</a></span>()</code>
<div class="block">The current inputs batch size</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/nd4j/linalg/primitives/Pair.html" title="class in org.nd4j.linalg.primitives">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#calcBackpropGradients-org.nd4j.linalg.api.ndarray.INDArray-boolean-boolean-boolean-">calcBackpropGradients</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;epsilon,
                     boolean&nbsp;withOutputLayer,
                     boolean&nbsp;tbptt,
                     boolean&nbsp;returnInputActGrad)</code>
<div class="block">Calculate gradients and errors.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#calcL1-boolean-">calcL1</a></span>(boolean&nbsp;backpropParamsOnly)</code>
<div class="block">Calculate the l1 regularization term<br>
 0.0 if regularization is not used.</div>
</td>
</tr>
<tr id="i14" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#calcL2-boolean-">calcL2</a></span>(boolean&nbsp;backpropParamsOnly)</code>
<div class="block">Calculate the l2 regularization term<br>
 0.0 if regularization is not used.</div>
</td>
</tr>
<tr id="i15" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/primitives/Pair.html" title="class in org.nd4j.linalg.primitives">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#calculateGradients-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">calculateGradients</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;features,
                  <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;label,
                  <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;fMask,
                  <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelMask)</code>
<div class="block">Calculate parameter gradients and input activation gradients given the input and labels</div>
</td>
</tr>
<tr id="i16" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clear--">clear</a></span>()</code>
<div class="block">Clear the inputs.</div>
</td>
</tr>
<tr id="i17" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clearLayerMaskArrays--">clearLayerMaskArrays</a></span>()</code>
<div class="block">Remove the mask arrays from all layers.<br>
 See <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayerMaskArrays-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-"><code>setLayerMaskArrays(INDArray, INDArray)</code></a> for details on mask arrays.</div>
</td>
</tr>
<tr id="i18" class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clearLayersStates--">clearLayersStates</a></span>()</code>
<div class="block">This method just makes sure there's no state preserved within layers</div>
</td>
</tr>
<tr id="i19" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clearNoiseWeightParams--">clearNoiseWeightParams</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i20" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clone--">clone</a></span>()</code>
<div class="block">Clones the multilayernetwork</div>
</td>
</tr>
<tr id="i21" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#computeGradientAndScore--">computeGradientAndScore</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i22" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#computeGradientAndScore-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">computeGradientAndScore</a></span>(<a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;layerWorkspaceMgr)</code>
<div class="block">Update the score</div>
</td>
</tr>
<tr id="i23" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#conf--">conf</a></span>()</code>
<div class="block">The configuration for the neural network</div>
</td>
</tr>
<tr id="i24" class="altColor">
<td class="colFirst"><code>&lt;T extends <a href="../../../../org/deeplearning4j/eval/IEvaluation.html" title="interface in org.deeplearning4j.eval">IEvaluation</a>&gt;<br>T[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#doEvaluation-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-T...-">doEvaluation</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
            T...&nbsp;evaluations)</code>
<div class="block">Perform evaluation using an arbitrary IEvaluation instance.</div>
</td>
</tr>
<tr id="i25" class="rowColor">
<td class="colFirst"><code>&lt;T extends <a href="../../../../org/deeplearning4j/eval/IEvaluation.html" title="interface in org.deeplearning4j.eval">IEvaluation</a>&gt;<br>T[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#doEvaluation-org.nd4j.linalg.dataset.api.iterator.MultiDataSetIterator-T:A-">doEvaluation</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/MultiDataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">MultiDataSetIterator</a>&nbsp;iterator,
            T[]&nbsp;evaluations)</code>
<div class="block">This method executes evaluation of the model against given iterator and evaluation implementations</div>
</td>
</tr>
<tr id="i26" class="altColor">
<td class="colFirst"><code>&lt;T extends <a href="../../../../org/deeplearning4j/eval/IEvaluation.html" title="interface in org.deeplearning4j.eval">IEvaluation</a>&gt;<br>T[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#doEvaluationHelper-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-T...-">doEvaluationHelper</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
                  T...&nbsp;evaluations)</code>&nbsp;</td>
</tr>
<tr id="i27" class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#doTruncatedBPTT-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">doTruncatedBPTT</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
               <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labels,
               <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featuresMaskArray,
               <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMaskArray,
               <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;workspaceMgr)</code>&nbsp;</td>
</tr>
<tr id="i28" class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#equals-java.lang.Object-">equals</a></span>(java.lang.Object&nbsp;obj)</code>
<div class="block">Indicates whether some other object is "equal to" this one.</div>
</td>
</tr>
<tr id="i29" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/Evaluation.html" title="class in org.deeplearning4j.eval">Evaluation</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluate-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">evaluate</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator)</code>
<div class="block">Evaluate the network (classification performance)</div>
</td>
</tr>
<tr id="i30" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/Evaluation.html" title="class in org.deeplearning4j.eval">Evaluation</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluate-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-java.util.List-">evaluate</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
        java.util.List&lt;java.lang.String&gt;&nbsp;labelsList)</code>
<div class="block">Evaluate the network on the provided data set.</div>
</td>
</tr>
<tr id="i31" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/Evaluation.html" title="class in org.deeplearning4j.eval">Evaluation</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluate-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-java.util.List-int-">evaluate</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
        java.util.List&lt;java.lang.String&gt;&nbsp;labelsList,
        int&nbsp;topN)</code>
<div class="block">Evaluate the network (for classification) on the provided data set, with top N accuracy in addition to standard accuracy.</div>
</td>
</tr>
<tr id="i32" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/RegressionEvaluation.html" title="class in org.deeplearning4j.eval">RegressionEvaluation</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluateRegression-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">evaluateRegression</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator)</code>
<div class="block">Evaluate the network for regression performance</div>
</td>
</tr>
<tr id="i33" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval">ROC</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluateROC-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">evaluateROC</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator)</code>
<div class="block">Evaluate the network (must be a binary classifier) on the specified data, using the <a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval"><code>ROC</code></a> class.</div>
</td>
</tr>
<tr id="i34" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval">ROC</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluateROC-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">evaluateROC</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
           int&nbsp;rocThresholdSteps)</code>
<div class="block">Evaluate the network (must be a binary classifier) on the specified data, using the <a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval"><code>ROC</code></a> class</div>
</td>
</tr>
<tr id="i35" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval">ROCMultiClass</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluateROCMultiClass-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">evaluateROCMultiClass</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator)</code>
<div class="block">Evaluate the network on the specified data, using the <a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval"><code>ROCMultiClass</code></a> class.</div>
</td>
</tr>
<tr id="i36" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval">ROCMultiClass</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#evaluateROCMultiClass-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">evaluateROCMultiClass</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
                     int&nbsp;rocThresholdSteps)</code>
<div class="block">Evaluate the network on the specified data, using the <a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval"><code>ROCMultiClass</code></a> class</div>
</td>
</tr>
<tr id="i37" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#f1Score-org.nd4j.linalg.dataset.api.DataSet-">f1Score</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/DataSet.html" title="interface in org.nd4j.linalg.dataset.api">DataSet</a>&nbsp;data)</code>
<div class="block">Sets the input and labels and returns a score for the prediction
 wrt true labels</div>
</td>
</tr>
<tr id="i38" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#f1Score-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">f1Score</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
       <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labels)</code>
<div class="block">Sets the input and labels and returns a score for the prediction
 wrt true labels</div>
</td>
</tr>
<tr id="i39" class="rowColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward--">feedForward</a></span>()</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr id="i40" class="altColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward-boolean-">feedForward</a></span>(boolean&nbsp;train)</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr id="i41" class="rowColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward-boolean-boolean-">feedForward</a></span>(boolean&nbsp;train,
           boolean&nbsp;clearInputs)</code>
<div class="block">Perform feed-forward, optionally (not) clearing the layer input arrays.<br>
 Note: when using clearInputs=false, there can be some performance and memory overhead: this is because the arrays are
 defined outside of workspaces (which are enabled by default) - otherwise, old/invalidated arrays could still be
 accessed after calling this method.</div>
</td>
</tr>
<tr id="i42" class="altColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward-org.nd4j.linalg.api.ndarray.INDArray-">feedForward</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr id="i43" class="rowColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward-org.nd4j.linalg.api.ndarray.INDArray-boolean-">feedForward</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
           boolean&nbsp;train)</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr id="i44" class="altColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">feedForward</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
           <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featuresMask,
           <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMask)</code>
<div class="block">Compute the activations from the input to the output layer, given mask arrays (that may be null)
 The masking arrays are used in situations such an one-to-many and many-to-one rucerrent neural network (RNN)
 designs, as well as for supporting time series of varying lengths within the same minibatch for RNNs.</div>
</td>
</tr>
<tr id="i45" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/primitives/Pair.html" title="class in org.nd4j.linalg.primitives">Pair</a>&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>,<a href="../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api">MaskState</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-">feedForwardMaskArray</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;maskArray,
                    <a href="../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api">MaskState</a>&nbsp;currentMaskState,
                    int&nbsp;minibatchSize)</code>
<div class="block">Feed forward the input mask array, setting in in the layer as appropriate.</div>
</td>
</tr>
<tr id="i46" class="altColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardToLayer-int-boolean-">feedForwardToLayer</a></span>(int&nbsp;layerNum,
                  boolean&nbsp;train)</code>
<div class="block">Compute the activations from the input to the specified layer, using the currently set input for the network.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input.</div>
</td>
</tr>
<tr id="i47" class="rowColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardToLayer-int-org.nd4j.linalg.api.ndarray.INDArray-">feedForwardToLayer</a></span>(int&nbsp;layerNum,
                  <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</code>
<div class="block">Compute the activations from the input to the specified layer.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input.</div>
</td>
</tr>
<tr id="i48" class="altColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForwardToLayer-int-org.nd4j.linalg.api.ndarray.INDArray-boolean-">feedForwardToLayer</a></span>(int&nbsp;layerNum,
                  <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                  boolean&nbsp;train)</code>
<div class="block">Compute the activations from the input to the specified layer.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input.</div>
</td>
</tr>
<tr id="i49" class="rowColor">
<td class="colFirst"><code>protected java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#ffToLayerActivationsDetached-boolean-org.deeplearning4j.nn.api.FwdPassType-boolean-int-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-boolean-">ffToLayerActivationsDetached</a></span>(boolean&nbsp;train,
                            <a href="../../../../org/deeplearning4j/nn/api/FwdPassType.html" title="enum in org.deeplearning4j.nn.api">FwdPassType</a>&nbsp;fwdPassType,
                            boolean&nbsp;storeLastForTBPTT,
                            int&nbsp;layerIndex,
                            <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                            <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;fMask,
                            <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;lMask,
                            boolean&nbsp;clearInputs)</code>
<div class="block">Feed-forward through the network - returning all array activations in a list, detached from any workspace.</div>
</td>
</tr>
<tr id="i50" class="altColor">
<td class="colFirst"><code>protected java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#ffToLayerActivationsInWs-int-org.deeplearning4j.nn.api.FwdPassType-boolean-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">ffToLayerActivationsInWs</a></span>(int&nbsp;layerIndex,
                        <a href="../../../../org/deeplearning4j/nn/api/FwdPassType.html" title="enum in org.deeplearning4j.nn.api">FwdPassType</a>&nbsp;fwdPassType,
                        boolean&nbsp;storeLastForTBPTT,
                        <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                        <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;fMask,
                        <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;lMask)</code>
<div class="block">Feed-forward through the network at training time - returning a list of all activations in a workspace (WS_ALL_LAYERS_ACT)
 if workspaces are enabled for training; or detached if no workspaces are used.<br>
 Note: if using workspaces for training, this method requires that WS_ALL_LAYERS_ACT is open externally.<br>
 If using NO workspaces, requires that no external workspace is open<br>
 Note that this method does NOT clear the inputs to each layer - instead, they are in the WS_ALL_LAYERS_ACT workspace
 for use in later backprop.</div>
</td>
</tr>
<tr id="i51" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit--">fit</a></span>()</code>
<div class="block">All models have a fit method</div>
</td>
</tr>
<tr id="i52" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.dataset.api.DataSet-">fit</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/DataSet.html" title="interface in org.nd4j.linalg.dataset.api">DataSet</a>&nbsp;data)</code>
<div class="block">Fit the model</div>
</td>
</tr>
<tr id="i53" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">fit</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator)</code>
<div class="block">Perform minibatch training on all minibatches in the DataSetIterator.<br>
 Note that this method does not do layerwise  pretraining.<br>
 For pretraining use method pretrain..</div>
</td>
</tr>
<tr id="i54" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">fit</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
   int&nbsp;numEpochs)</code>
<div class="block">Perform minibatch training on all minibatches in the DataSetIterator, for the specified number of epochs.</div>
</td>
</tr>
<tr id="i55" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">fit</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;data,
   <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labels)</code>
<div class="block">Fit the model</div>
</td>
</tr>
<tr id="i56" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">fit</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;features,
   <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labels,
   <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featuresMask,
   <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMask)</code>
<div class="block">Fit the model</div>
</td>
</tr>
<tr id="i57" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.api.ndarray.INDArray-int:A-">fit</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;examples,
   int[]&nbsp;labels)</code>
<div class="block">Fit the model</div>
</td>
</tr>
<tr id="i58" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">fit</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;data,
   <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;workspaceMgr)</code>
<div class="block">Fit the model to the given data</div>
</td>
</tr>
<tr id="i59" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.dataset.api.MultiDataSet-">fit</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/MultiDataSet.html" title="interface in org.nd4j.linalg.dataset.api">MultiDataSet</a>&nbsp;dataSet)</code>
<div class="block">This method fits model with a given MultiDataSet</div>
</td>
</tr>
<tr id="i60" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.dataset.api.iterator.MultiDataSetIterator-">fit</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/MultiDataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">MultiDataSetIterator</a>&nbsp;iterator)</code>
<div class="block">Perform minibatch training on all minibatches in the MultiDataSetIterator.<br>
 Note: The MultiDataSets in the MultiDataSetIterator must have exactly 1 input and output array (as
 MultiLayerNetwork only supports 1 input and 1 output)</div>
</td>
</tr>
<tr id="i61" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.dataset.api.iterator.MultiDataSetIterator-int-">fit</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/MultiDataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">MultiDataSetIterator</a>&nbsp;iterator,
   int&nbsp;numEpochs)</code>
<div class="block">Perform minibatch training on all minibatches in the MultiDataSetIterator, for the specified number of epochs.</div>
</td>
</tr>
<tr id="i62" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/TrainingConfig.html" title="interface in org.deeplearning4j.nn.api">TrainingConfig</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getConfig--">getConfig</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i63" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getDefaultConfiguration--">getDefaultConfiguration</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i64" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getEpochCount--">getEpochCount</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i65" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getGradientsViewArray--">getGradientsViewArray</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i66" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/layers/LayerHelper.html" title="interface in org.deeplearning4j.nn.layers">LayerHelper</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getHelper--">getHelper</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i67" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getIndex--">getIndex</a></span>()</code>
<div class="block">Get the layer index.</div>
</td>
</tr>
<tr id="i68" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getInput--">getInput</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i69" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getInputMiniBatchSize--">getInputMiniBatchSize</a></span>()</code>
<div class="block">Get current/last input mini-batch size, as set by setInputMiniBatchSize(int)</div>
</td>
</tr>
<tr id="i70" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getIterationCount--">getIterationCount</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i71" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLabels--">getLabels</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i72" class="altColor">
<td class="colFirst"><code>long</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLastEtlTime--">getLastEtlTime</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i73" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayer-int-">getLayer</a></span>(int&nbsp;i)</code>&nbsp;</td>
</tr>
<tr id="i74" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayer-java.lang.String-">getLayer</a></span>(java.lang.String&nbsp;name)</code>&nbsp;</td>
</tr>
<tr id="i75" class="rowColor">
<td class="colFirst"><code>protected static <a href="../../../../org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.html" title="class in org.nd4j.linalg.api.memory.conf">WorkspaceConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayerActivationWSConfig-int-">getLayerActivationWSConfig</a></span>(int&nbsp;numLayers)</code>&nbsp;</td>
</tr>
<tr id="i76" class="altColor">
<td class="colFirst"><code>java.util.List&lt;java.lang.String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayerNames--">getLayerNames</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i77" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayers--">getLayers</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i78" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayerWiseConfigurations--">getLayerWiseConfigurations</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i79" class="rowColor">
<td class="colFirst"><code>protected static <a href="../../../../org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.html" title="class in org.nd4j.linalg.api.memory.conf">WorkspaceConfiguration</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLayerWorkingMemWSConfig-int-">getLayerWorkingMemWSConfig</a></span>(int&nbsp;numWorkingMemCycles)</code>&nbsp;</td>
</tr>
<tr id="i80" class="altColor">
<td class="colFirst"><code>java.lang.Double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getLearningRate-int-">getLearningRate</a></span>(int&nbsp;layerNumber)</code>
<div class="block">Get the current learning rate, for the specified layer, from the network.</div>
</td>
</tr>
<tr id="i81" class="rowColor">
<td class="colFirst"><code>java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getListeners--">getListeners</a></span>()</code>
<div class="block">Get the iteration listeners for this layer.</div>
</td>
</tr>
<tr id="i82" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getMask--">getMask</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i83" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getMaskArray--">getMaskArray</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i84" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getnLayers--">getnLayers</a></span>()</code>
<div class="block">Get the number of layers in the network</div>
</td>
</tr>
<tr id="i85" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/optimize/api/ConvexOptimizer.html" title="interface in org.deeplearning4j.optimize.api">ConvexOptimizer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getOptimizer--">getOptimizer</a></span>()</code>
<div class="block">Returns this models optimizer</div>
</td>
</tr>
<tr id="i86" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getOutputLayer--">getOutputLayer</a></span>()</code>
<div class="block">Get the output layer</div>
</td>
</tr>
<tr id="i87" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getParam-java.lang.String-">getParam</a></span>(java.lang.String&nbsp;param)</code>
<div class="block">Get the parameter</div>
</td>
</tr>
<tr id="i88" class="altColor">
<td class="colFirst"><code>java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getTrainingListeners--">getTrainingListeners</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i89" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getUpdater--">getUpdater</a></span>()</code>
<div class="block">Get the updater for this MultiLayerNetwork</div>
</td>
</tr>
<tr id="i90" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#getUpdater-boolean-">getUpdater</a></span>(boolean&nbsp;initializeIfReq)</code>&nbsp;</td>
</tr>
<tr id="i91" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#gradient--">gradient</a></span>()</code>
<div class="block">Get the gradient.</div>
</td>
</tr>
<tr id="i92" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/primitives/Pair.html" title="class in org.nd4j.linalg.primitives">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,java.lang.Double&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#gradientAndScore--">gradientAndScore</a></span>()</code>
<div class="block">Get the gradient and score</div>
</td>
</tr>
<tr id="i93" class="rowColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#hasAFrozenLayer--">hasAFrozenLayer</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i94" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#incrementEpochCount--">incrementEpochCount</a></span>()</code>
<div class="block">Increment the epoch count (in the underlying <a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf"><code>MultiLayerConfiguration</code></a> by 1).</div>
</td>
</tr>
<tr id="i95" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#init--">init</a></span>()</code>
<div class="block">Initialize the MultiLayerNetwork.</div>
</td>
</tr>
<tr id="i96" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#init-org.nd4j.linalg.api.ndarray.INDArray-boolean-">init</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;parameters,
    boolean&nbsp;cloneParametersArray)</code>
<div class="block">Initialize the MultiLayerNetwork, optionally with an existing parameters array.</div>
</td>
</tr>
<tr id="i97" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#initGradientsView--">initGradientsView</a></span>()</code>
<div class="block">This method: initializes the flattened gradients array (used in backprop) and sets the appropriate subset in all layers.</div>
</td>
</tr>
<tr id="i98" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#input--">input</a></span>()</code>
<div class="block">The input/feature matrix for the model</div>
</td>
</tr>
<tr id="i99" class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#intializeConfigurations--">intializeConfigurations</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i100" class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#isInitCalled--">isInitCalled</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i101" class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#isPretrainLayer--">isPretrainLayer</a></span>()</code>
<div class="block">Returns true if the layer can be trained in an unsupervised/pretrain manner (AE, VAE, etc)</div>
</td>
</tr>
<tr id="i102" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#labelProbabilities-org.nd4j.linalg.api.ndarray.INDArray-">labelProbabilities</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;examples)</code>
<div class="block">Returns the probabilities for each label
 for each example row wise</div>
</td>
</tr>
<tr id="i103" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layerInputSize-int-">layerInputSize</a></span>(int&nbsp;layer)</code>
<div class="block">Return the input size (number of inputs) for the specified layer.<br>
 Note that the meaning of the "input size" can depend on the type of layer.</div>
</td>
</tr>
<tr id="i104" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#layerSize-int-">layerSize</a></span>(int&nbsp;layer)</code>
<div class="block">Return the layer size (number of units) for the specified layer.<br>
 Note that the meaning of the "layer size" can depend on the type of layer.</div>
</td>
</tr>
<tr id="i105" class="rowColor">
<td class="colFirst"><code>static <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#load-java.io.File-boolean-">load</a></span>(java.io.File&nbsp;f,
    boolean&nbsp;loadUpdater)</code>
<div class="block">Restore a MultiLayerNetwork to a file, saved using <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#save-java.io.File-"><code>save(File)</code></a> or <a href="../../../../org/deeplearning4j/util/ModelSerializer.html" title="class in org.deeplearning4j.util"><code>ModelSerializer</code></a></div>
</td>
</tr>
<tr id="i106" class="altColor">
<td class="colFirst"><code>java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#memoryInfo-int-org.deeplearning4j.nn.conf.inputs.InputType-">memoryInfo</a></span>(int&nbsp;minibatch,
          <a href="../../../../org/deeplearning4j/nn/conf/inputs/InputType.html" title="class in org.deeplearning4j.nn.conf.inputs">InputType</a>&nbsp;inputType)</code>
<div class="block">Generate information regarding memory use for the network, for the given input type and minibatch size.</div>
</td>
</tr>
<tr id="i107" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#numLabels--">numLabels</a></span>()</code>
<div class="block">Returns the number of possible labels</div>
</td>
</tr>
<tr id="i108" class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#numParams--">numParams</a></span>()</code>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets and output layer</div>
</td>
</tr>
<tr id="i109" class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#numParams-boolean-">numParams</a></span>(boolean&nbsp;backwards)</code>
<div class="block">the number of parameters for the model</div>
</td>
</tr>
<tr id="i110" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">output</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator)</code>
<div class="block">Generate the output for all examples/batches in the input iterator, and concatenate them into a single array</div>
</td>
</tr>
<tr id="i111" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-boolean-">output</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
      boolean&nbsp;train)</code>
<div class="block">Generate the output for all examples/batches in the input iterator, and concatenate them into a single array</div>
</td>
</tr>
<tr id="i112" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-">output</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</code>
<div class="block">Label the probabilities of the input</div>
</td>
</tr>
<tr id="i113" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-boolean-">output</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
      boolean&nbsp;train)</code>
<div class="block">Label the probabilities of the input</div>
</td>
</tr>
<tr id="i114" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">output</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
      boolean&nbsp;train,
      <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featuresMask,
      <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMask)</code>
<div class="block">Calculate the output of the network, with masking arrays.</div>
</td>
</tr>
<tr id="i115" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.memory.MemoryWorkspace-">output</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
      boolean&nbsp;train,
      <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featuresMask,
      <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMask,
      <a href="../../../../org/nd4j/linalg/api/memory/MemoryWorkspace.html" title="interface in org.nd4j.linalg.api.memory">MemoryWorkspace</a>&nbsp;outputWorkspace)</code>
<div class="block">Get the network output, which is optionally placed in the specified memory workspace.<br>
 If no memory workspace is provided, the output will be detached (not in any workspace).<br>
 If a memory workspace is provided, the output activation array (i.e., the INDArray returned by this method)
 will be placed in the specified workspace.</div>
</td>
</tr>
<tr id="i116" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.nd4j.linalg.api.memory.MemoryWorkspace-">output</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
      boolean&nbsp;train,
      <a href="../../../../org/nd4j/linalg/api/memory/MemoryWorkspace.html" title="interface in org.nd4j.linalg.api.memory">MemoryWorkspace</a>&nbsp;outputWorkspace)</code>
<div class="block">Get the network output, which is optionally placed in the specified memory workspace.<br>
 If no memory workspace is provided, the output will be detached (not in any workspace).<br>
 If a memory workspace is provided, the output activation array (i.e., the INDArray returned by this method)
 will be placed in the specified workspace.</div>
</td>
</tr>
<tr id="i117" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">output</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
      <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;train)</code>
<div class="block">Label the probabilities of the input</div>
</td>
</tr>
<tr id="i118" class="altColor">
<td class="colFirst"><code>protected <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#outputOfLayerDetached-boolean-org.deeplearning4j.nn.api.FwdPassType-int-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.memory.MemoryWorkspace-">outputOfLayerDetached</a></span>(boolean&nbsp;train,
                     <a href="../../../../org/deeplearning4j/nn/api/FwdPassType.html" title="enum in org.deeplearning4j.nn.api">FwdPassType</a>&nbsp;fwdPassType,
                     int&nbsp;layerIndex,
                     <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                     <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featureMask,
                     <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMask,
                     <a href="../../../../org/nd4j/linalg/api/memory/MemoryWorkspace.html" title="interface in org.nd4j.linalg.api.memory">MemoryWorkspace</a>&nbsp;outputWorkspace)</code>
<div class="block">Provide the output of the specified layer, detached from any workspace.</div>
</td>
</tr>
<tr id="i119" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#params--">params</a></span>()</code>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets(w,hbias NOT VBIAS) and output layer</div>
</td>
</tr>
<tr id="i120" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#params-boolean-">params</a></span>(boolean&nbsp;backwardOnly)</code>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets(w,hbias NOT VBIAS) and output layer</div>
</td>
</tr>
<tr id="i121" class="rowColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.String,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#paramTable--">paramTable</a></span>()</code>
<div class="block">The param table</div>
</td>
</tr>
<tr id="i122" class="altColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.String,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#paramTable-boolean-">paramTable</a></span>(boolean&nbsp;backpropParamsOnly)</code>
<div class="block">Table of parameters by key, for backprop
 For many models (dense layers, etc) - all parameters are backprop parameters</div>
</td>
</tr>
<tr id="i123" class="rowColor">
<td class="colFirst"><code>java.util.List&lt;java.lang.String&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#predict-org.nd4j.linalg.dataset.api.DataSet-">predict</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/DataSet.html" title="interface in org.nd4j.linalg.dataset.api">DataSet</a>&nbsp;dataSet)</code>
<div class="block">Return predicted label names</div>
</td>
</tr>
<tr id="i124" class="altColor">
<td class="colFirst"><code>int[]</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#predict-org.nd4j.linalg.api.ndarray.INDArray-">predict</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;d)</code>
<div class="block">Returns the predictions for each example in the dataset</div>
</td>
</tr>
<tr id="i125" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrain-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">pretrain</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iter)</code>
<div class="block">Perform layerwise pretraining for one epoch - see <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrain-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-"><code>pretrain(DataSetIterator, int)</code></a></div>
</td>
</tr>
<tr id="i126" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrain-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">pretrain</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iter,
        int&nbsp;numEpochs)</code>
<div class="block">Perform layerwise pretraining on all pre-trainable layers in the network (VAEs, Autoencoders, etc), for the specified
 number of epochs each.</div>
</td>
</tr>
<tr id="i127" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">pretrainLayer</a></span>(int&nbsp;layerIdx,
             <a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iter)</code>
<div class="block">Fit for one epoch - see <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-"><code>pretrainLayer(int, DataSetIterator, int)</code></a></div>
</td>
</tr>
<tr id="i128" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">pretrainLayer</a></span>(int&nbsp;layerIdx,
             <a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iter,
             int&nbsp;numEpochs)</code>
<div class="block">Perform layerwise unsupervised training on a single pre-trainable layer in the network (VAEs, Autoencoders, etc)
 for the specified number of epochs<br>
 If the specified layer index (0 to numLayers - 1) is not a pretrainable layer, this is a no-op.</div>
</td>
</tr>
<tr id="i129" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.api.ndarray.INDArray-">pretrainLayer</a></span>(int&nbsp;layerIdx,
             <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;features)</code>
<div class="block">Perform layerwise unsupervised training on a single pre-trainable layer in the network (VAEs, Autoencoders, etc)<br>
 If the specified layer index (0 to numLayers - 1) is not a pretrainable layer, this is a no-op.</div>
</td>
</tr>
<tr id="i130" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#printConfiguration--">printConfiguration</a></span>()</code>
<div class="block">Prints the configuration</div>
</td>
</tr>
<tr id="i131" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#reconstruct-org.nd4j.linalg.api.ndarray.INDArray-int-">reconstruct</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;x,
           int&nbsp;layerNum)</code>
<div class="block">Reconstructs the input.</div>
</td>
</tr>
<tr id="i132" class="altColor">
<td class="colFirst"><code>java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnActivateUsingStoredState-org.nd4j.linalg.api.ndarray.INDArray-boolean-boolean-">rnnActivateUsingStoredState</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                           boolean&nbsp;training,
                           boolean&nbsp;storeLastForTBPTT)</code>
<div class="block">Similar to rnnTimeStep and feedForward() methods.</div>
</td>
</tr>
<tr id="i133" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnClearPreviousState--">rnnClearPreviousState</a></span>()</code>
<div class="block">Clear the previous state of the RNN layers (if any).</div>
</td>
</tr>
<tr id="i134" class="altColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.String,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnGetPreviousState-int-">rnnGetPreviousState</a></span>(int&nbsp;layer)</code>
<div class="block">Get the state of the RNN layer, as used in rnnTimeStep().</div>
</td>
</tr>
<tr id="i135" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnSetPreviousState-int-java.util.Map-">rnnSetPreviousState</a></span>(int&nbsp;layer,
                   java.util.Map&lt;java.lang.String,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;state)</code>
<div class="block">Set the state of the RNN layer.</div>
</td>
</tr>
<tr id="i136" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#rnnTimeStep-org.nd4j.linalg.api.ndarray.INDArray-">rnnTimeStep</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</code>
<div class="block">If this MultiLayerNetwork contains one or more RNN layers: conduct forward pass (prediction)
 but using previous stored state for any RNN layers.</div>
</td>
</tr>
<tr id="i137" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#save-java.io.File-">save</a></span>(java.io.File&nbsp;f)</code>
<div class="block">Save the MultiLayerNetwork to a file.</div>
</td>
</tr>
<tr id="i138" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#save-java.io.File-boolean-">save</a></span>(java.io.File&nbsp;f,
    boolean&nbsp;saveUpdater)</code>
<div class="block">Save the MultiLayerNetwork to a file.</div>
</td>
</tr>
<tr id="i139" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score--">score</a></span>()</code>
<div class="block">Score of the model (relative to the objective function)</div>
</td>
</tr>
<tr id="i140" class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-">score</a></span>(<a href="../../../../org/nd4j/linalg/dataset/DataSet.html" title="class in org.nd4j.linalg.dataset">DataSet</a>&nbsp;data)</code>
<div class="block">Sets the input and labels and returns a score for the prediction with respect to the true labels<br>
 This is equivalent to <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-boolean-"><code>score(DataSet, boolean)</code></a> with training==false.</div>
</td>
</tr>
<tr id="i141" class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-boolean-">score</a></span>(<a href="../../../../org/nd4j/linalg/dataset/DataSet.html" title="class in org.nd4j.linalg.dataset">DataSet</a>&nbsp;data,
     boolean&nbsp;training)</code>
<div class="block">Calculate the score (loss function) of the prediction with respect to the true labels<br></div>
</td>
</tr>
<tr id="i142" class="altColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#scoreExamples-org.nd4j.linalg.dataset.DataSet-boolean-">scoreExamples</a></span>(<a href="../../../../org/nd4j/linalg/dataset/DataSet.html" title="class in org.nd4j.linalg.dataset">DataSet</a>&nbsp;data,
             boolean&nbsp;addRegularizationTerms)</code>
<div class="block">Calculate the score for each example in a DataSet individually.</div>
</td>
</tr>
<tr id="i143" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#scoreExamples-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-boolean-">scoreExamples</a></span>(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iter,
             boolean&nbsp;addRegularizationTerms)</code>&nbsp;</td>
</tr>
<tr id="i144" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setBackpropGradientsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">setBackpropGradientsViewArray</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;gradients)</code>
<div class="block">Set the gradients array as a view of the full (backprop) network parameters
 NOTE: this is intended to be used internally in MultiLayerNetwork and ComputationGraph, not by users.</div>
</td>
</tr>
<tr id="i145" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setCacheMode-org.deeplearning4j.nn.conf.CacheMode-">setCacheMode</a></span>(<a href="../../../../org/deeplearning4j/nn/conf/CacheMode.html" title="enum in org.deeplearning4j.nn.conf">CacheMode</a>&nbsp;mode)</code>
<div class="block">This method sets specified CacheMode for all layers within network</div>
</td>
</tr>
<tr id="i146" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setConf-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">setConf</a></span>(<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf)</code>
<div class="block">Setter for the configuration</div>
</td>
</tr>
<tr id="i147" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setEpochCount-int-">setEpochCount</a></span>(int&nbsp;epochCount)</code>
<div class="block">Set the current epoch count (number of epochs passed ) for the layer/network</div>
</td>
</tr>
<tr id="i148" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setGradientsAccumulator-org.deeplearning4j.optimize.solvers.accumulation.GradientsAccumulator-">setGradientsAccumulator</a></span>(<a href="../../../../org/deeplearning4j/optimize/solvers/accumulation/GradientsAccumulator.html" title="interface in org.deeplearning4j.optimize.solvers.accumulation">GradientsAccumulator</a>&nbsp;accumulator)</code>
<div class="block">This method allows you to specificy GradientsAccumulator instance to be used with this model

 PLEASE NOTE: Do not use this method unless you understand how to use GradientsAccumulator & updates sharing.</div>
</td>
</tr>
<tr id="i149" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setIndex-int-">setIndex</a></span>(int&nbsp;index)</code>
<div class="block">Set the layer index.</div>
</td>
</tr>
<tr id="i150" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setInput-org.nd4j.linalg.api.ndarray.INDArray-">setInput</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</code>
<div class="block">Note that if input isn't null
 and the neuralNets are null, this is a way
 of initializing the neural network</div>
</td>
</tr>
<tr id="i151" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setInput-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">setInput</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
        <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;mgr)</code>
<div class="block">Set the layer input.</div>
</td>
</tr>
<tr id="i152" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setInputMiniBatchSize-int-">setInputMiniBatchSize</a></span>(int&nbsp;size)</code>
<div class="block">Set current/last input mini-batch size.<br>
 Used for score and gradient calculations.</div>
</td>
</tr>
<tr id="i153" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setIterationCount-int-">setIterationCount</a></span>(int&nbsp;iterationCount)</code>
<div class="block">Set the current iteration count (number of parameter updates) for the layer/network</div>
</td>
</tr>
<tr id="i154" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLabels-org.nd4j.linalg.api.ndarray.INDArray-">setLabels</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labels)</code>&nbsp;</td>
</tr>
<tr id="i155" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLastEtlTime-long-">setLastEtlTime</a></span>(long&nbsp;time)</code>&nbsp;</td>
</tr>
<tr id="i156" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayerMaskArrays-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">setLayerMaskArrays</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featuresMaskArray,
                  <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMaskArray)</code>
<div class="block">Set the mask arrays for features and labels.</div>
</td>
</tr>
<tr id="i157" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayers-org.deeplearning4j.nn.api.Layer:A-">setLayers</a></span>(<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]&nbsp;layers)</code>&nbsp;</td>
</tr>
<tr id="i158" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayerWiseConfigurations-org.deeplearning4j.nn.conf.MultiLayerConfiguration-">setLayerWiseConfigurations</a></span>(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;layerWiseConfigurations)</code>&nbsp;</td>
</tr>
<tr id="i159" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-double-">setLearningRate</a></span>(double&nbsp;newLr)</code>
<div class="block">Set the learning rate for all layers in the network to the specified value.</div>
</td>
</tr>
<tr id="i160" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-int-double-">setLearningRate</a></span>(int&nbsp;layerNumber,
               double&nbsp;newLr)</code>
<div class="block">Set the learning rate for a single layer in the network to the specified value.</div>
</td>
</tr>
<tr id="i161" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-int-org.nd4j.linalg.schedule.ISchedule-">setLearningRate</a></span>(int&nbsp;layerNumber,
               <a href="../../../../org/nd4j/linalg/schedule/ISchedule.html" title="interface in org.nd4j.linalg.schedule">ISchedule</a>&nbsp;newLr)</code>
<div class="block">Set the learning rate schedule for a single layer in the network to the specified value.<br>
 Note also that <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-org.nd4j.linalg.schedule.ISchedule-"><code>setLearningRate(ISchedule)</code></a> should also be used in preference, when all layers need
 to be set to a new LR schedule.<br>
 This schedule will replace any/all existing schedules, and also any fixed learning rate values.<br>
 Note also that the iteration/epoch counts will <i>not</i> be reset.</div>
</td>
</tr>
<tr id="i162" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-org.nd4j.linalg.schedule.ISchedule-">setLearningRate</a></span>(<a href="../../../../org/nd4j/linalg/schedule/ISchedule.html" title="interface in org.nd4j.linalg.schedule">ISchedule</a>&nbsp;newLr)</code>
<div class="block">Set the learning rate schedule for all layers in the network to the specified schedule.</div>
</td>
</tr>
<tr id="i163" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setListeners-java.util.Collection-">setListeners</a></span>(java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>&gt;&nbsp;listeners)</code>
<div class="block">Set the trainingListeners for the ComputationGraph (and all layers in the network)</div>
</td>
</tr>
<tr id="i164" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setListeners-org.deeplearning4j.optimize.api.TrainingListener...-">setListeners</a></span>(<a href="../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>...&nbsp;listeners)</code>
<div class="block">Set the trainingListeners for the ComputationGraph (and all layers in the network)</div>
</td>
</tr>
<tr id="i165" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setMask-org.nd4j.linalg.api.ndarray.INDArray-">setMask</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;mask)</code>&nbsp;</td>
</tr>
<tr id="i166" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setMaskArray-org.nd4j.linalg.api.ndarray.INDArray-">setMaskArray</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;maskArray)</code>
<div class="block">Set the mask array.</div>
</td>
</tr>
<tr id="i167" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParam-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">setParam</a></span>(java.lang.String&nbsp;key,
        <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;val)</code>
<div class="block">Set the parameter with a new ndarray</div>
</td>
</tr>
<tr id="i168" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParameters-org.nd4j.linalg.api.ndarray.INDArray-">setParameters</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;params)</code>
<div class="block">Sets parameters for the model.</div>
</td>
</tr>
<tr id="i169" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParams-org.nd4j.linalg.api.ndarray.INDArray-">setParams</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;params)</code>
<div class="block">Set the parameters for this model.</div>
</td>
</tr>
<tr id="i170" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParamsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">setParamsViewArray</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;params)</code>
<div class="block">Set the initial parameters array as a view of the full (backprop) network parameters
 NOTE: this is intended to be used internally in MultiLayerNetwork and ComputationGraph, not by users.</div>
</td>
</tr>
<tr id="i171" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setParamTable-java.util.Map-">setParamTable</a></span>(java.util.Map&lt;java.lang.String,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;paramTable)</code>
<div class="block">Setter for the param table</div>
</td>
</tr>
<tr id="i172" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setScore-double-">setScore</a></span>(double&nbsp;score)</code>&nbsp;</td>
</tr>
<tr id="i173" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setUpdater-org.deeplearning4j.nn.api.Updater-">setUpdater</a></span>(<a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a>&nbsp;updater)</code>
<div class="block">Set the updater for the MultiLayerNetwork</div>
</td>
</tr>
<tr id="i174" class="altColor">
<td class="colFirst"><code>java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#summary--">summary</a></span>()</code>
<div class="block">String detailing the architecture of the multilayernetwork.</div>
</td>
</tr>
<tr id="i175" class="rowColor">
<td class="colFirst"><code>java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#summary-org.deeplearning4j.nn.conf.inputs.InputType-">summary</a></span>(<a href="../../../../org/deeplearning4j/nn/conf/inputs/InputType.html" title="class in org.deeplearning4j.nn.conf.inputs">InputType</a>&nbsp;inputType)</code>
<div class="block">String detailing the architecture of the multilayernetwork.</div>
</td>
</tr>
<tr id="i176" class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#synchronizeIterEpochCounts--">synchronizeIterEpochCounts</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i177" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/graph/ComputationGraph.html" title="class in org.deeplearning4j.nn.graph">ComputationGraph</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#toComputationGraph--">toComputationGraph</a></span>()</code>
<div class="block">Convert this MultiLayerNetwork to a ComputationGraph</div>
</td>
</tr>
<tr id="i178" class="altColor">
<td class="colFirst"><code><a href="../../../../org/deeplearning4j/nn/api/Layer.Type.html" title="enum in org.deeplearning4j.nn.api">Layer.Type</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#type--">type</a></span>()</code>
<div class="block">Returns the layer type</div>
</td>
</tr>
<tr id="i179" class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#update-org.deeplearning4j.nn.gradient.Gradient-">update</a></span>(<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;gradient)</code>
<div class="block">Update layer weights and biases with gradient change</div>
</td>
</tr>
<tr id="i180" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#update-org.nd4j.linalg.api.ndarray.INDArray-java.lang.String-">update</a></span>(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;gradient,
      java.lang.String&nbsp;paramType)</code>
<div class="block">Perform one update  applying the gradient</div>
</td>
</tr>
<tr id="i181" class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#update-org.nd4j.linalg.heartbeat.reports.Task-">update</a></span>(<a href="../../../../org/nd4j/linalg/heartbeat/reports/Task.html" title="class in org.nd4j.linalg.heartbeat.reports">Task</a>&nbsp;task)</code>&nbsp;</td>
</tr>
<tr id="i182" class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#updateRnnStateWithTBPTTState--">updateRnnStateWithTBPTTState</a></span>()</code>&nbsp;</td>
</tr>
<tr id="i183" class="rowColor">
<td class="colFirst"><code><a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a></code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#updaterState--">updaterState</a></span>()</code>
<div class="block">This method returns updater state (if applicable), null otherwise</div>
</td>
</tr>
<tr id="i184" class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#validateArrayWorkspaces-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.ArrayType-int-boolean-java.lang.String-">validateArrayWorkspaces</a></span>(<a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;mgr,
                       <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;array,
                       <a href="../../../../org/deeplearning4j/nn/workspace/ArrayType.html" title="enum in org.deeplearning4j.nn.workspace">ArrayType</a>&nbsp;arrayType,
                       int&nbsp;layerIdx,
                       boolean&nbsp;isPreprocessor,
                       java.lang.String&nbsp;op)</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="layers">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layers</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[] layers</pre>
</li>
</ul>
<a name="layerMap">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layerMap</h4>
<pre>protected&nbsp;java.util.LinkedHashMap&lt;java.lang.String,<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&gt; layerMap</pre>
</li>
</ul>
<a name="input">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>input</h4>
<pre>protected&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a> input</pre>
</li>
</ul>
<a name="labels">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>labels</h4>
<pre>protected&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a> labels</pre>
</li>
</ul>
<a name="initCalled">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initCalled</h4>
<pre>protected&nbsp;boolean initCalled</pre>
</li>
</ul>
<a name="trainingListeners">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>trainingListeners</h4>
<pre>protected&nbsp;java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>&gt; trainingListeners</pre>
</li>
</ul>
<a name="defaultConfiguration">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>defaultConfiguration</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a> defaultConfiguration</pre>
</li>
</ul>
<a name="layerWiseConfigurations">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layerWiseConfigurations</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a> layerWiseConfigurations</pre>
</li>
</ul>
<a name="gradient">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradient</h4>
<pre>protected&nbsp;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a> gradient</pre>
</li>
</ul>
<a name="score">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>protected&nbsp;double score</pre>
</li>
</ul>
<a name="initDone">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initDone</h4>
<pre>protected&nbsp;boolean initDone</pre>
</li>
</ul>
<a name="flattenedParams">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>flattenedParams</h4>
<pre>protected&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a> flattenedParams</pre>
</li>
</ul>
<a name="flattenedGradients">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>flattenedGradients</h4>
<pre>protected transient&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a> flattenedGradients</pre>
</li>
</ul>
<a name="clearTbpttState">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clearTbpttState</h4>
<pre>protected&nbsp;boolean clearTbpttState</pre>
</li>
</ul>
<a name="lastEtlTime">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>lastEtlTime</h4>
<pre>protected transient&nbsp;java.lang.ThreadLocal&lt;java.lang.Long&gt; lastEtlTime</pre>
</li>
</ul>
<a name="mask">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>mask</h4>
<pre>protected&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a> mask</pre>
</li>
</ul>
<a name="layerIndex">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layerIndex</h4>
<pre>protected&nbsp;int layerIndex</pre>
</li>
</ul>
<a name="solver">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>solver</h4>
<pre>protected transient&nbsp;<a href="../../../../org/deeplearning4j/optimize/Solver.html" title="class in org.deeplearning4j.optimize">Solver</a> solver</pre>
</li>
</ul>
<a name="helperWorkspaces">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>helperWorkspaces</h4>
<pre>protected transient&nbsp;java.util.Map&lt;java.lang.String,org.bytedeco.javacpp.Pointer&gt; helperWorkspaces</pre>
</li>
</ul>
<a name="WS_LAYER_WORKING_MEM">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>WS_LAYER_WORKING_MEM</h4>
<pre>protected static final&nbsp;java.lang.String WS_LAYER_WORKING_MEM</pre>
<div class="block">Workspace for working memory for a single layer: forward pass and backward pass
 Note that this is opened/closed once per op (activate/backpropGradient call)</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../constant-values.html#org.deeplearning4j.nn.multilayer.MultiLayerNetwork.WS_LAYER_WORKING_MEM">Constant Field Values</a></dd>
</dl>
</li>
</ul>
<a name="WS_ALL_LAYERS_ACT">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>WS_ALL_LAYERS_ACT</h4>
<pre>protected static final&nbsp;java.lang.String WS_ALL_LAYERS_ACT</pre>
<div class="block">Workspace for storing all layers' activations - used only to store activations (layer inputs) as part of backprop
 Not used for inference</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../constant-values.html#org.deeplearning4j.nn.multilayer.MultiLayerNetwork.WS_ALL_LAYERS_ACT">Constant Field Values</a></dd>
</dl>
</li>
</ul>
<a name="WS_LAYER_ACT_1">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>WS_LAYER_ACT_1</h4>
<pre>protected static final&nbsp;java.lang.String WS_LAYER_ACT_1</pre>
<div class="block">Next 2 workspaces: used for:
 (a) Inference: holds activations for one layer only
 (b) Backprop: holds activation gradients for one layer only
 In both cases, they are opened and closed on every second layer</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../constant-values.html#org.deeplearning4j.nn.multilayer.MultiLayerNetwork.WS_LAYER_ACT_1">Constant Field Values</a></dd>
</dl>
</li>
</ul>
<a name="WS_LAYER_ACT_2">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>WS_LAYER_ACT_2</h4>
<pre>protected static final&nbsp;java.lang.String WS_LAYER_ACT_2</pre>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../constant-values.html#org.deeplearning4j.nn.multilayer.MultiLayerNetwork.WS_LAYER_ACT_2">Constant Field Values</a></dd>
</dl>
</li>
</ul>
<a name="WS_RNN_LOOP_WORKING_MEM">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>WS_RNN_LOOP_WORKING_MEM</h4>
<pre>protected static final&nbsp;java.lang.String WS_RNN_LOOP_WORKING_MEM</pre>
<div class="block">Workspace for working memory in RNNs - opened and closed once per RNN time step</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../constant-values.html#org.deeplearning4j.nn.multilayer.MultiLayerNetwork.WS_RNN_LOOP_WORKING_MEM">Constant Field Values</a></dd>
</dl>
</li>
</ul>
<a name="WS_LAYER_WORKING_MEM_CONFIG">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>WS_LAYER_WORKING_MEM_CONFIG</h4>
<pre>protected&nbsp;<a href="../../../../org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.html" title="class in org.nd4j.linalg.api.memory.conf">WorkspaceConfiguration</a> WS_LAYER_WORKING_MEM_CONFIG</pre>
</li>
</ul>
<a name="WS_ALL_LAYERS_ACT_CONFIG">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>WS_ALL_LAYERS_ACT_CONFIG</h4>
<pre>protected static final&nbsp;<a href="../../../../org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.html" title="class in org.nd4j.linalg.api.memory.conf">WorkspaceConfiguration</a> WS_ALL_LAYERS_ACT_CONFIG</pre>
</li>
</ul>
<a name="WS_LAYER_ACT_X_CONFIG">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>WS_LAYER_ACT_X_CONFIG</h4>
<pre>protected&nbsp;<a href="../../../../org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.html" title="class in org.nd4j.linalg.api.memory.conf">WorkspaceConfiguration</a> WS_LAYER_ACT_X_CONFIG</pre>
</li>
</ul>
<a name="WS_RNN_LOOP_WORKING_MEM_CONFIG">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>WS_RNN_LOOP_WORKING_MEM_CONFIG</h4>
<pre>protected static final&nbsp;<a href="../../../../org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.html" title="class in org.nd4j.linalg.api.memory.conf">WorkspaceConfiguration</a> WS_RNN_LOOP_WORKING_MEM_CONFIG</pre>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor.detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="MultiLayerNetwork-org.deeplearning4j.nn.conf.MultiLayerConfiguration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>MultiLayerNetwork</h4>
<pre>public&nbsp;MultiLayerNetwork(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;conf)</pre>
</li>
</ul>
<a name="MultiLayerNetwork-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>MultiLayerNetwork</h4>
<pre>public&nbsp;MultiLayerNetwork(java.lang.String&nbsp;conf,
                         <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;params)</pre>
<div class="block">Initialize the network based on the configuration</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>conf</code> - the configuration json</dd>
<dd><code>params</code> - the parameters</dd>
</dl>
</li>
</ul>
<a name="MultiLayerNetwork-org.deeplearning4j.nn.conf.MultiLayerConfiguration-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>MultiLayerNetwork</h4>
<pre>public&nbsp;MultiLayerNetwork(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;conf,
                         <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;params)</pre>
<div class="block">Initialize the network based on the configuraiton</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>conf</code> - the configuration</dd>
<dd><code>params</code> - the parameters</dd>
</dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="getLayerWorkingMemWSConfig-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayerWorkingMemWSConfig</h4>
<pre>protected static&nbsp;<a href="../../../../org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.html" title="class in org.nd4j.linalg.api.memory.conf">WorkspaceConfiguration</a>&nbsp;getLayerWorkingMemWSConfig(int&nbsp;numWorkingMemCycles)</pre>
</li>
</ul>
<a name="getLayerActivationWSConfig-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayerActivationWSConfig</h4>
<pre>protected static&nbsp;<a href="../../../../org/nd4j/linalg/api/memory/conf/WorkspaceConfiguration.html" title="class in org.nd4j.linalg.api.memory.conf">WorkspaceConfiguration</a>&nbsp;getLayerActivationWSConfig(int&nbsp;numLayers)</pre>
</li>
</ul>
<a name="setCacheMode-org.deeplearning4j.nn.conf.CacheMode-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setCacheMode</h4>
<pre>public&nbsp;void&nbsp;setCacheMode(<a href="../../../../org/deeplearning4j/nn/conf/CacheMode.html" title="enum in org.deeplearning4j.nn.conf">CacheMode</a>&nbsp;mode)</pre>
<div class="block">This method sets specified CacheMode for all layers within network</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setCacheMode-org.deeplearning4j.nn.conf.CacheMode-">setCacheMode</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>mode</code> - </dd>
</dl>
</li>
</ul>
<a name="setLastEtlTime-long-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLastEtlTime</h4>
<pre>public&nbsp;void&nbsp;setLastEtlTime(long&nbsp;time)</pre>
</li>
</ul>
<a name="getLastEtlTime--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLastEtlTime</h4>
<pre>public&nbsp;long&nbsp;getLastEtlTime()</pre>
</li>
</ul>
<a name="intializeConfigurations--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>intializeConfigurations</h4>
<pre>protected&nbsp;void&nbsp;intializeConfigurations()</pre>
</li>
</ul>
<a name="pretrain-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pretrain</h4>
<pre>public&nbsp;void&nbsp;pretrain(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iter)</pre>
<div class="block">Perform layerwise pretraining for one epoch - see <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrain-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-"><code>pretrain(DataSetIterator, int)</code></a></div>
</li>
</ul>
<a name="pretrain-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pretrain</h4>
<pre>public&nbsp;void&nbsp;pretrain(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iter,
                     int&nbsp;numEpochs)</pre>
<div class="block">Perform layerwise pretraining on all pre-trainable layers in the network (VAEs, Autoencoders, etc), for the specified
 number of epochs each. For example, if numEpochs=3, then layer 0 will be fit for 3 epochs, followed by layer 1
 for 3 epochs, and so on.<br>
 Note that pretraining will be performed on one layer after the other, resetting the DataSetIterator between iterations.<br>
 For multiple epochs per layer, appropriately wrap the iterator (for example, a MultipleEpochsIterator) or train
 each layer manually using <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-"><code>pretrainLayer(int, DataSetIterator)</code></a></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iter</code> - Training data</dd>
</dl>
</li>
</ul>
<a name="pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pretrainLayer</h4>
<pre>public&nbsp;void&nbsp;pretrainLayer(int&nbsp;layerIdx,
                          <a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iter)</pre>
<div class="block">Fit for one epoch - see <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-"><code>pretrainLayer(int, DataSetIterator, int)</code></a></div>
</li>
</ul>
<a name="pretrainLayer-int-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pretrainLayer</h4>
<pre>public&nbsp;void&nbsp;pretrainLayer(int&nbsp;layerIdx,
                          <a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iter,
                          int&nbsp;numEpochs)</pre>
<div class="block">Perform layerwise unsupervised training on a single pre-trainable layer in the network (VAEs, Autoencoders, etc)
 for the specified number of epochs<br>
 If the specified layer index (0 to numLayers - 1) is not a pretrainable layer, this is a no-op.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerIdx</code> - Index of the layer to train (0 to numLayers-1)</dd>
<dd><code>iter</code> - Training data</dd>
<dd><code>numEpochs</code> - Number of epochs to fit the specified layer for</dd>
</dl>
</li>
</ul>
<a name="pretrainLayer-int-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pretrainLayer</h4>
<pre>public&nbsp;void&nbsp;pretrainLayer(int&nbsp;layerIdx,
                          <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;features)</pre>
<div class="block">Perform layerwise unsupervised training on a single pre-trainable layer in the network (VAEs, Autoencoders, etc)<br>
 If the specified layer index (0 to numLayers - 1) is not a pretrainable layer, this is a no-op.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerIdx</code> - Index of the layer to train (0 to numLayers-1)</dd>
<dd><code>features</code> - Training data array</dd>
</dl>
</li>
</ul>
<a name="batchSize--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>batchSize</h4>
<pre>public&nbsp;int&nbsp;batchSize()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#batchSize--">Model</a></code></span></div>
<div class="block">The current inputs batch size</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#batchSize--">batchSize</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the current inputs batch size</dd>
</dl>
</li>
</ul>
<a name="conf--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>conf</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#conf--">Model</a></code></span></div>
<div class="block">The configuration for the neural network</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#conf--">conf</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the configuration for the neural network</dd>
</dl>
</li>
</ul>
<a name="setConf-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setConf</h4>
<pre>public&nbsp;void&nbsp;setConf(<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;conf)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setConf-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">Model</a></code></span></div>
<div class="block">Setter for the configuration</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setConf-org.deeplearning4j.nn.conf.NeuralNetConfiguration-">setConf</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="input--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>input</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#input--">Model</a></code></span></div>
<div class="block">The input/feature matrix for the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#input--">input</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the input/feature matrix for the model</dd>
</dl>
</li>
</ul>
<a name="getOptimizer--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOptimizer</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/optimize/api/ConvexOptimizer.html" title="interface in org.deeplearning4j.optimize.api">ConvexOptimizer</a>&nbsp;getOptimizer()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getOptimizer--">Model</a></code></span></div>
<div class="block">Returns this models optimizer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getOptimizer--">getOptimizer</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#getOptimizer--">getOptimizer</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html" title="interface in org.deeplearning4j.nn.api">NeuralNetwork</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>this models optimizer</dd>
</dl>
</li>
</ul>
<a name="getParam-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getParam</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;getParam(java.lang.String&nbsp;param)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getParam-java.lang.String-">Model</a></code></span></div>
<div class="block">Get the parameter</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getParam-java.lang.String-">getParam</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>param</code> - the key of the parameter</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the parameter vector/matrix with that particular key</dd>
</dl>
</li>
</ul>
<a name="paramTable--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>paramTable</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.String,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;paramTable()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#paramTable--">Model</a></code></span></div>
<div class="block">The param table</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#paramTable--">paramTable</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="paramTable-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>paramTable</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.String,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;paramTable(boolean&nbsp;backpropParamsOnly)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#paramTable-boolean-">Model</a></code></span></div>
<div class="block">Table of parameters by key, for backprop
 For many models (dense layers, etc) - all parameters are backprop parameters</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#paramTable-boolean-">paramTable</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Trainable.html#paramTable-boolean-">paramTable</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Trainable.html" title="interface in org.deeplearning4j.nn.api">Trainable</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>backpropParamsOnly</code> - If true, return backprop params only. If false: return all params (equivalent to
                           paramsTable())</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Parameter table</dd>
</dl>
</li>
</ul>
<a name="setParamTable-java.util.Map-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParamTable</h4>
<pre>public&nbsp;void&nbsp;setParamTable(java.util.Map&lt;java.lang.String,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;paramTable)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParamTable-java.util.Map-">Model</a></code></span></div>
<div class="block">Setter for the param table</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParamTable-java.util.Map-">setParamTable</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="setParam-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParam</h4>
<pre>public&nbsp;void&nbsp;setParam(java.lang.String&nbsp;key,
                     <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;val)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParam-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Set the parameter with a new ndarray</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParam-java.lang.String-org.nd4j.linalg.api.ndarray.INDArray-">setParam</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>key</code> - the key to se t</dd>
<dd><code>val</code> - the new ndarray</dd>
</dl>
</li>
</ul>
<a name="getLayerWiseConfigurations--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayerWiseConfigurations</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;getLayerWiseConfigurations()</pre>
</li>
</ul>
<a name="setLayerWiseConfigurations-org.deeplearning4j.nn.conf.MultiLayerConfiguration-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLayerWiseConfigurations</h4>
<pre>public&nbsp;void&nbsp;setLayerWiseConfigurations(<a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf">MultiLayerConfiguration</a>&nbsp;layerWiseConfigurations)</pre>
</li>
</ul>
<a name="init--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>init</h4>
<pre>public&nbsp;void&nbsp;init()</pre>
<div class="block">Initialize the MultiLayerNetwork. This should be called once before the network is used.
 This is functionally equivalent to calling
 <code>init(null, false)</code>.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#init--">init</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#init--">init</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html" title="interface in org.deeplearning4j.nn.api">NeuralNetwork</a></code></dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#init-org.nd4j.linalg.api.ndarray.INDArray-boolean-"><code>init(INDArray, boolean)</code></a></dd>
</dl>
</li>
</ul>
<a name="init-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>init</h4>
<pre>public&nbsp;void&nbsp;init(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;parameters,
                 boolean&nbsp;cloneParametersArray)</pre>
<div class="block">Initialize the MultiLayerNetwork, optionally with an existing parameters array.
 If an existing parameters array is specified, it will be used (and the values will not be modified) in the network;
 if no parameters array is specified, parameters will be initialized randomly according to the network configuration.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>parameters</code> - Network parameter. May be null. If null: randomly initialize.</dd>
<dd><code>cloneParametersArray</code> - Whether the parameter array (if any) should be cloned, or used directly</dd>
</dl>
</li>
</ul>
<a name="setGradientsAccumulator-org.deeplearning4j.optimize.solvers.accumulation.GradientsAccumulator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setGradientsAccumulator</h4>
<pre>public&nbsp;void&nbsp;setGradientsAccumulator(<a href="../../../../org/deeplearning4j/optimize/solvers/accumulation/GradientsAccumulator.html" title="interface in org.deeplearning4j.optimize.solvers.accumulation">GradientsAccumulator</a>&nbsp;accumulator)</pre>
<div class="block">This method allows you to specificy GradientsAccumulator instance to be used with this model

 PLEASE NOTE: Do not use this method unless you understand how to use GradientsAccumulator & updates sharing.
 PLEASE NOTE: Do not use this method on standalone model</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>accumulator</code> - </dd>
</dl>
</li>
</ul>
<a name="isInitCalled--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isInitCalled</h4>
<pre>public&nbsp;boolean&nbsp;isInitCalled()</pre>
</li>
</ul>
<a name="initGradientsView--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initGradientsView</h4>
<pre>public&nbsp;void&nbsp;initGradientsView()</pre>
<div class="block">This method: initializes the flattened gradients array (used in backprop) and sets the appropriate subset in all layers.
 As a general rule, this shouldn't ever need to be called manually when doing training via fit(DataSet) or fit(DataSetIterator)</div>
</li>
</ul>
<a name="activate-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>@Deprecated
public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;activate(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</pre>
<div class="block"><span class="deprecatedLabel">Deprecated.</span>&nbsp;<span class="deprecationComment">Use <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-"><code>output(INDArray)</code></a></span></div>
</li>
</ul>
<a name="activationFromPrevLayer-int-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activationFromPrevLayer</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;activationFromPrevLayer(int&nbsp;curr,
                                        <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                                        boolean&nbsp;training,
                                        <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;mgr)</pre>
</li>
</ul>
<a name="activateSelectedLayers-int-int-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activateSelectedLayers</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;activateSelectedLayers(int&nbsp;from,
                                       int&nbsp;to,
                                       <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</pre>
<div class="block">Calculate activation for few layers at once. Suitable for autoencoder partial activation.

 In example: in 10-layer deep autoencoder, layers 0 - 4 inclusive are used for encoding part, and layers 5-9 inclusive are used for decoding part.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>from</code> - first layer to be activated, inclusive</dd>
<dd><code>to</code> - last layer to be activated, inclusive</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation from the last layer</dd>
</dl>
</li>
</ul>
<a name="feedForward-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;feedForward(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                                            boolean&nbsp;train)</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the list of activations for each layer</dd>
</dl>
</li>
</ul>
<a name="feedForward-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;feedForward(boolean&nbsp;train)</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the list of activations for each layer</dd>
</dl>
</li>
</ul>
<a name="feedForward-boolean-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;feedForward(boolean&nbsp;train,
                                            boolean&nbsp;clearInputs)</pre>
<div class="block">Perform feed-forward, optionally (not) clearing the layer input arrays.<br>
 Note: when using clearInputs=false, there can be some performance and memory overhead: this is because the arrays are
 defined outside of workspaces (which are enabled by default) - otherwise, old/invalidated arrays could still be
 accessed after calling this method. Consequently: Don't use clearInputs=false unless you have a use case that
 requires them to remain after feed-forward has been completed</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>train</code> - training mode (true) or test mode (false)</dd>
<dd><code>clearInputs</code> - If false: don't clear the layer inputs</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Activations from feed-forward</dd>
</dl>
</li>
</ul>
<a name="feedForwardToLayer-int-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardToLayer</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;feedForwardToLayer(int&nbsp;layerNum,
                                                   <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</pre>
<div class="block">Compute the activations from the input to the specified layer.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input. So list.get(0) is always the original input, and
 list.get(i+1) is the activations of the ith layer.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerNum</code> - Index of the last layer to calculate activations for. Layers are zero-indexed.
                 feedForwardToLayer(i,input) will return the activations for layers 0..i (inclusive)</dd>
<dd><code>input</code> - Input to the network</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>list of activations.</dd>
</dl>
</li>
</ul>
<a name="feedForwardToLayer-int-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardToLayer</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;feedForwardToLayer(int&nbsp;layerNum,
                                                   <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                                                   boolean&nbsp;train)</pre>
<div class="block">Compute the activations from the input to the specified layer.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input. So list.get(0) is always the original input, and
 list.get(i+1) is the activations of the ith layer.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerNum</code> - Index of the last layer to calculate activations for. Layers are zero-indexed.
                 feedForwardToLayer(i,input) will return the activations for layers 0..i (inclusive)</dd>
<dd><code>input</code> - Input to the network</dd>
<dd><code>train</code> - true for training, false for test (i.e., false if using network after training)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>list of activations.</dd>
</dl>
</li>
</ul>
<a name="feedForwardToLayer-int-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardToLayer</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;feedForwardToLayer(int&nbsp;layerNum,
                                                   boolean&nbsp;train)</pre>
<div class="block">Compute the activations from the input to the specified layer, using the currently set input for the network.<br>
 To compute activations for all layers, use feedForward(...) methods<br>
 Note: output list includes the original input. So list.get(0) is always the original input, and
 list.get(i+1) is the activations of the ith layer.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerNum</code> - Index of the last layer to calculate activations for. Layers are zero-indexed.
                 feedForwardToLayer(i,input) will return the activations for layers 0..i (inclusive)</dd>
<dd><code>train</code> - true for training, false for test (i.e., false if using network after training)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>list of activations.</dd>
</dl>
</li>
</ul>
<a name="validateArrayWorkspaces-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.ArrayType-int-boolean-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>validateArrayWorkspaces</h4>
<pre>protected&nbsp;void&nbsp;validateArrayWorkspaces(<a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;mgr,
                                       <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;array,
                                       <a href="../../../../org/deeplearning4j/nn/workspace/ArrayType.html" title="enum in org.deeplearning4j.nn.workspace">ArrayType</a>&nbsp;arrayType,
                                       int&nbsp;layerIdx,
                                       boolean&nbsp;isPreprocessor,
                                       java.lang.String&nbsp;op)</pre>
</li>
</ul>
<a name="ffToLayerActivationsDetached-boolean-org.deeplearning4j.nn.api.FwdPassType-boolean-int-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>ffToLayerActivationsDetached</h4>
<pre>protected&nbsp;java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;ffToLayerActivationsDetached(boolean&nbsp;train,
                                                                @NonNull
                                                                <a href="../../../../org/deeplearning4j/nn/api/FwdPassType.html" title="enum in org.deeplearning4j.nn.api">FwdPassType</a>&nbsp;fwdPassType,
                                                                boolean&nbsp;storeLastForTBPTT,
                                                                int&nbsp;layerIndex,
                                                                @NonNull
                                                                <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                                                                <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;fMask,
                                                                <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;lMask,
                                                                boolean&nbsp;clearInputs)</pre>
<div class="block">Feed-forward through the network - returning all array activations in a list, detached from any workspace.
 Note that no workspace should be active externally when calling this method (an exception will be thrown
 if a workspace is open externally)</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>train</code> - Training mode (true) or test/inference mode (false)</dd>
<dd><code>fwdPassType</code> - Type of forward pass to perform (STANDARD or RNN_ACTIVATE_WITH_STORED_STATE only)</dd>
<dd><code>storeLastForTBPTT</code> - ONLY used if fwdPassType == FwdPassType.RNN_ACTIVATE_WITH_STORED_STATE</dd>
<dd><code>layerIndex</code> - Index (inclusive) to stop forward pass at. For all layers, use numLayers-1</dd>
<dd><code>input</code> - Input to the network</dd>
<dd><code>fMask</code> - Feature mask array. May be null.</dd>
<dd><code>lMask</code> - Label mask array. May be null.</dd>
<dd><code>clearInputs</code> - Whether the layer inputs should be cleared</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>List of activations (including the input), detached from any workspace</dd>
</dl>
</li>
</ul>
<a name="ffToLayerActivationsInWs-int-org.deeplearning4j.nn.api.FwdPassType-boolean-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>ffToLayerActivationsInWs</h4>
<pre>protected&nbsp;java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;ffToLayerActivationsInWs(int&nbsp;layerIndex,
                                                            @NonNull
                                                            <a href="../../../../org/deeplearning4j/nn/api/FwdPassType.html" title="enum in org.deeplearning4j.nn.api">FwdPassType</a>&nbsp;fwdPassType,
                                                            boolean&nbsp;storeLastForTBPTT,
                                                            @NonNull
                                                            <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                                                            <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;fMask,
                                                            <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;lMask)</pre>
<div class="block">Feed-forward through the network at training time - returning a list of all activations in a workspace (WS_ALL_LAYERS_ACT)
 if workspaces are enabled for training; or detached if no workspaces are used.<br>
 Note: if using workspaces for training, this method requires that WS_ALL_LAYERS_ACT is open externally.<br>
 If using NO workspaces, requires that no external workspace is open<br>
 Note that this method does NOT clear the inputs to each layer - instead, they are in the WS_ALL_LAYERS_ACT workspace
 for use in later backprop.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerIndex</code> - Index (inclusive) to stop forward pass at. For all layers, use numLayers-1</dd>
<dd><code>fwdPassType</code> - Type of forward pass to perform (STANDARD or RNN_ACTIVATE_WITH_STORED_STATE only)</dd>
<dd><code>storeLastForTBPTT</code> - ONLY used if fwdPassType == FwdPassType.RNN_ACTIVATE_WITH_STORED_STATE</dd>
<dd><code>input</code> - Input to network</dd>
<dd><code>fMask</code> - Feature mask array. May be null</dd>
<dd><code>lMask</code> - Label mask aray. May be null.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="outputOfLayerDetached-boolean-org.deeplearning4j.nn.api.FwdPassType-int-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.memory.MemoryWorkspace-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>outputOfLayerDetached</h4>
<pre>protected&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;outputOfLayerDetached(boolean&nbsp;train,
                                         @NonNull
                                         <a href="../../../../org/deeplearning4j/nn/api/FwdPassType.html" title="enum in org.deeplearning4j.nn.api">FwdPassType</a>&nbsp;fwdPassType,
                                         int&nbsp;layerIndex,
                                         @NonNull
                                         <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                                         <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featureMask,
                                         <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMask,
                                         <a href="../../../../org/nd4j/linalg/api/memory/MemoryWorkspace.html" title="interface in org.nd4j.linalg.api.memory">MemoryWorkspace</a>&nbsp;outputWorkspace)</pre>
<div class="block">Provide the output of the specified layer, detached from any workspace. This is most commonly used at inference/test
 time, and is more memory efficient than <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#ffToLayerActivationsDetached-boolean-org.deeplearning4j.nn.api.FwdPassType-boolean-int-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-boolean-"><code>ffToLayerActivationsDetached(boolean, FwdPassType, boolean, int, INDArray, INDArray, INDArray, boolean)</code></a>
 and <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#ffToLayerActivationsInWs-int-org.deeplearning4j.nn.api.FwdPassType-boolean-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-"><code>ffToLayerActivationsInWs(int, FwdPassType, boolean, INDArray, INDArray, INDArray)</code></a>.<br>
 This method clears all layer inputs.

 NOTE: in general, no workspaces should be activated externally for this method!
 This method handles the workspace activation as required</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>train</code> - Training mode (true) or test/inference mode (false)</dd>
<dd><code>fwdPassType</code> - Type of forward pass to perform (STANDARD, RNN_TIMESTEP or RNN_ACTIVATE_WITH_STORED_STATE)</dd>
<dd><code>layerIndex</code> - Index (inclusive) to stop forward pass at. For all layers, use numLayers-1</dd>
<dd><code>input</code> - Input to the network</dd>
<dd><code>featureMask</code> - Input/feature mask array. May be null.</dd>
<dd><code>labelsMask</code> - Labels mask array. May be null</dd>
<dd><code>outputWorkspace</code> - Optional - if provided, outputs should be placed in this workspace. NOTE: this workspace
                          must be open</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Output of the specified layer, detached from any workspace</dd>
</dl>
</li>
</ul>
<a name="feedForward--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;feedForward()</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the list of activations for each layer</dd>
</dl>
</li>
</ul>
<a name="feedForward-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;feedForward(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the list of activations for each layer</dd>
</dl>
</li>
</ul>
<a name="feedForward-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;feedForward(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                                            <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featuresMask,
                                            <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMask)</pre>
<div class="block">Compute the activations from the input to the output layer, given mask arrays (that may be null)
 The masking arrays are used in situations such an one-to-many and many-to-one rucerrent neural network (RNN)
 designs, as well as for supporting time series of varying lengths within the same minibatch for RNNs.</div>
</li>
</ul>
<a name="gradient--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradient</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;gradient()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#gradient--">Model</a></code></span></div>
<div class="block">Get the gradient. Note that this method will not calculate the gradient, it will rather return the gradient
 that has been computed before.
 For calculating the gradient, see <a href="../../../../org/deeplearning4j/nn/api/Model.html#computeGradientAndScore-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-"><code>Model.computeGradientAndScore(LayerWorkspaceMgr)</code></a> } .</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#gradient--">gradient</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the gradient for this model, as calculated before</dd>
</dl>
</li>
</ul>
<a name="gradientAndScore--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradientAndScore</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/primitives/Pair.html" title="class in org.nd4j.linalg.primitives">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,java.lang.Double&gt;&nbsp;gradientAndScore()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#gradientAndScore--">Model</a></code></span></div>
<div class="block">Get the gradient and score</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#gradientAndScore--">gradientAndScore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the gradient and score</dd>
</dl>
</li>
</ul>
<a name="clone--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clone</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a>&nbsp;clone()</pre>
<div class="block">Clones the multilayernetwork</div>
<dl>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code>clone</code>&nbsp;in class&nbsp;<code>java.lang.Object</code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="hasAFrozenLayer--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>hasAFrozenLayer</h4>
<pre>protected&nbsp;boolean&nbsp;hasAFrozenLayer()</pre>
</li>
</ul>
<a name="params-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>params</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;params(boolean&nbsp;backwardOnly)</pre>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets(w,hbias NOT VBIAS) and output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the params for this neural net</dd>
</dl>
</li>
</ul>
<a name="params--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>params</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;params()</pre>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets(w,hbias NOT VBIAS) and output layer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#params--">params</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#params--">params</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html" title="interface in org.deeplearning4j.nn.api">NeuralNetwork</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Trainable.html#params--">params</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Trainable.html" title="interface in org.deeplearning4j.nn.api">Trainable</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the params for this neural net</dd>
</dl>
</li>
</ul>
<a name="setParams-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParams</h4>
<pre>public&nbsp;void&nbsp;setParams(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;params)</pre>
<div class="block">Set the parameters for this model.
 This expects a linear ndarray
 which then be unpacked internally
 relative to the expected ordering of the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParams-org.nd4j.linalg.api.ndarray.INDArray-">setParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>params</code> - the parameters for the model</dd>
</dl>
</li>
</ul>
<a name="setParamsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParamsViewArray</h4>
<pre>public&nbsp;void&nbsp;setParamsViewArray(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;params)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParamsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Set the initial parameters array as a view of the full (backprop) network parameters
 NOTE: this is intended to be used internally in MultiLayerNetwork and ComputationGraph, not by users.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setParamsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">setParamsViewArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>params</code> - a 1 x nParams row vector that is a view of the larger (MLN/CG) parameters array</dd>
</dl>
</li>
</ul>
<a name="getGradientsViewArray--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getGradientsViewArray</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;getGradientsViewArray()</pre>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#getGradientsViewArray--">getGradientsViewArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Trainable.html#getGradientsViewArray--">getGradientsViewArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Trainable.html" title="interface in org.deeplearning4j.nn.api">Trainable</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>1D gradients view array</dd>
</dl>
</li>
</ul>
<a name="setBackpropGradientsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setBackpropGradientsViewArray</h4>
<pre>public&nbsp;void&nbsp;setBackpropGradientsViewArray(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;gradients)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setBackpropGradientsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">Model</a></code></span></div>
<div class="block">Set the gradients array as a view of the full (backprop) network parameters
 NOTE: this is intended to be used internally in MultiLayerNetwork and ComputationGraph, not by users.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setBackpropGradientsViewArray-org.nd4j.linalg.api.ndarray.INDArray-">setBackpropGradientsViewArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>gradients</code> - a 1 x nParams row vector that is a view of the larger (MLN/CG) gradients array</dd>
</dl>
</li>
</ul>
<a name="getConfig--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getConfig</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/TrainingConfig.html" title="interface in org.deeplearning4j.nn.api">TrainingConfig</a>&nbsp;getConfig()</pre>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Trainable.html#getConfig--">getConfig</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Trainable.html" title="interface in org.deeplearning4j.nn.api">Trainable</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Training configuration</dd>
</dl>
</li>
</ul>
<a name="numParams--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numParams</h4>
<pre>public&nbsp;int&nbsp;numParams()</pre>
<div class="block">Returns a 1 x m vector where the vector is composed of
 a flattened vector of all of the weights for the
 various neuralNets and output layer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#numParams--">numParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Trainable.html#numParams--">numParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Trainable.html" title="interface in org.deeplearning4j.nn.api">Trainable</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the params for this neural net</dd>
</dl>
</li>
</ul>
<a name="numParams-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numParams</h4>
<pre>public&nbsp;int&nbsp;numParams(boolean&nbsp;backwards)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#numParams-boolean-">Model</a></code></span></div>
<div class="block">the number of parameters for the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#numParams-boolean-">numParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the number of parameters for the model</dd>
</dl>
</li>
</ul>
<a name="f1Score-org.nd4j.linalg.dataset.api.DataSet-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>f1Score</h4>
<pre>public&nbsp;double&nbsp;f1Score(<a href="../../../../org/nd4j/linalg/dataset/api/DataSet.html" title="interface in org.nd4j.linalg.dataset.api">DataSet</a>&nbsp;data)</pre>
<div class="block">Sets the input and labels and returns a score for the prediction
 wrt true labels</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#f1Score-org.nd4j.linalg.dataset.api.DataSet-">f1Score</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - the data to score</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the score for the given input,label pairs</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(@NonNull
                <a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
                int&nbsp;numEpochs)</pre>
<div class="block">Perform minibatch training on all minibatches in the DataSetIterator, for the specified number of epochs.
 Equvalent to calling <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-"><code>fit(DataSetIterator)</code></a> numEpochs times in a loop</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Training data (DataSetIterator). Iterator must support resetting</dd>
<dd><code>numEpochs</code> - Number of training epochs, >= 1</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator)</pre>
<div class="block">Perform minibatch training on all minibatches in the DataSetIterator.<br>
 Note that this method does not do layerwise  pretraining.<br>
 For pretraining use method pretrain.. <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#pretrain-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-"><code>pretrain(DataSetIterator)</code></a><br></div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#fit-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html" title="interface in org.deeplearning4j.nn.api">NeuralNetwork</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Training data (DataSetIterator)</dd>
</dl>
</li>
</ul>
<a name="calculateGradients-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calculateGradients</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/primitives/Pair.html" title="class in org.nd4j.linalg.primitives">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;calculateGradients(@NonNull
                                                  <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;features,
                                                  @NonNull
                                                  <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;label,
                                                  <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;fMask,
                                                  <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelMask)</pre>
<div class="block">Calculate parameter gradients and input activation gradients given the input and labels</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>features</code> - Features for gradient calculation</dd>
<dd><code>label</code> - Labels for gradient</dd>
<dd><code>fMask</code> - Features mask array (may be null)</dd>
<dd><code>labelMask</code> - Label mask array (may be null)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>A pair of gradient arrays: parameter gradients (in Gradient object) and input activation gradients</dd>
</dl>
</li>
</ul>
<a name="calcBackpropGradients-org.nd4j.linalg.api.ndarray.INDArray-boolean-boolean-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcBackpropGradients</h4>
<pre>protected&nbsp;<a href="../../../../org/nd4j/linalg/primitives/Pair.html" title="class in org.nd4j.linalg.primitives">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;calcBackpropGradients(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;epsilon,
                                                        boolean&nbsp;withOutputLayer,
                                                        boolean&nbsp;tbptt,
                                                        boolean&nbsp;returnInputActGrad)</pre>
<div class="block">Calculate gradients and errors. Used in two places:
 (a) backprop (for standard multi layer network learning)
 (b) backpropGradient (layer method, for when MultiLayerNetwork is used as a layer)</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>epsilon</code> - Errors (technically errors .* activations). Not used if withOutputLayer = true</dd>
<dd><code>withOutputLayer</code> - if true: assume last layer is output layer, and calculate errors based on labels. In this
                        case, the epsilon input is not used (may/should be null).
                        If false: calculate backprop gradients</dd>
<dd><code>returnInputActGrad</code> - If true: terun the input activation gradients (detached). False: don't return</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Gradients and the error (epsilon) at the input</dd>
</dl>
</li>
</ul>
<a name="doTruncatedBPTT-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>doTruncatedBPTT</h4>
<pre>protected&nbsp;void&nbsp;doTruncatedBPTT(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                               <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labels,
                               <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featuresMaskArray,
                               <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMaskArray,
                               <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;workspaceMgr)</pre>
</li>
</ul>
<a name="updateRnnStateWithTBPTTState--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>updateRnnStateWithTBPTTState</h4>
<pre>public&nbsp;void&nbsp;updateRnnStateWithTBPTTState()</pre>
</li>
</ul>
<a name="getListeners--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getListeners</h4>
<pre>public&nbsp;java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>&gt;&nbsp;getListeners()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getListeners--">Layer</a></code></span></div>
<div class="block">Get the iteration listeners for this layer.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getListeners--">getListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>listeners</dd>
</dl>
</li>
</ul>
<a name="getTrainingListeners--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getTrainingListeners</h4>
<pre>public&nbsp;java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>&gt;&nbsp;getTrainingListeners()</pre>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>trainingListeners</dd>
</dl>
</li>
</ul>
<a name="setListeners-java.util.Collection-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setListeners</h4>
<pre>public&nbsp;void&nbsp;setListeners(java.util.Collection&lt;<a href="../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>&gt;&nbsp;listeners)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setListeners-java.util.Collection-">Model</a></code></span></div>
<div class="block">Set the trainingListeners for the ComputationGraph (and all layers in the network)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setListeners-java.util.Collection-">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setListeners-java.util.Collection-">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="addListeners-org.deeplearning4j.optimize.api.TrainingListener...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>addListeners</h4>
<pre>public&nbsp;void&nbsp;addListeners(<a href="../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>...&nbsp;listeners)</pre>
<div class="block">This method ADDS additional TrainingListener to existing listeners</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#addListeners-org.deeplearning4j.optimize.api.TrainingListener...-">addListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>listeners</code> - </dd>
</dl>
</li>
</ul>
<a name="setListeners-org.deeplearning4j.optimize.api.TrainingListener...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setListeners</h4>
<pre>public&nbsp;void&nbsp;setListeners(<a href="../../../../org/deeplearning4j/optimize/api/TrainingListener.html" title="interface in org.deeplearning4j.optimize.api">TrainingListener</a>...&nbsp;listeners)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setListeners-org.deeplearning4j.optimize.api.TrainingListener...-">Model</a></code></span></div>
<div class="block">Set the trainingListeners for the ComputationGraph (and all layers in the network)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setListeners-org.deeplearning4j.optimize.api.TrainingListener...-">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#setListeners-org.deeplearning4j.optimize.api.TrainingListener...-">setListeners</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="predict-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>predict</h4>
<pre>public&nbsp;int[]&nbsp;predict(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;d)</pre>
<div class="block">Returns the predictions for each example in the dataset</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#predict-org.nd4j.linalg.api.ndarray.INDArray-">predict</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>d</code> - the matrix to predict</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the prediction for the dataset</dd>
</dl>
</li>
</ul>
<a name="predict-org.nd4j.linalg.dataset.api.DataSet-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>predict</h4>
<pre>public&nbsp;java.util.List&lt;java.lang.String&gt;&nbsp;predict(<a href="../../../../org/nd4j/linalg/dataset/api/DataSet.html" title="interface in org.nd4j.linalg.dataset.api">DataSet</a>&nbsp;dataSet)</pre>
<div class="block">Return predicted label names</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#predict-org.nd4j.linalg.dataset.api.DataSet-">predict</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>dataSet</code> - to predict</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the predicted labels for the dataSet</dd>
</dl>
</li>
</ul>
<a name="labelProbabilities-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>labelProbabilities</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelProbabilities(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;examples)</pre>
<div class="block">Returns the probabilities for each label
 for each example row wise</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#labelProbabilities-org.nd4j.linalg.api.ndarray.INDArray-">labelProbabilities</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>examples</code> - the examples to classify (one example in each row)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the likelihoods of each example and each label</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;data,
                <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labels)</pre>
<div class="block">Fit the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - the examples to classify (one example in each row)</dd>
<dd><code>labels</code> - the example labels(a binary outcome matrix)</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;features,
                <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labels,
                <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featuresMask,
                <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMask)</pre>
<div class="block">Fit the model</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>features</code> - the examples to classify (one example in each row)</dd>
<dd><code>labels</code> - the example labels(a binary outcome matrix)</dd>
<dd><code>featuresMask</code> - The mask array for the features (used for variable length time series, etc). May be null.</dd>
<dd><code>labelsMask</code> - The mask array for the labels (used for variable length time series, etc). May be null.</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;data,
                <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;workspaceMgr)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#fit-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">Model</a></code></span></div>
<div class="block">Fit the model to the given data</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#fit-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - the data to fit the model to</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.dataset.api.DataSet-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(<a href="../../../../org/nd4j/linalg/dataset/api/DataSet.html" title="interface in org.nd4j.linalg.dataset.api">DataSet</a>&nbsp;data)</pre>
<div class="block">Fit the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit-org.nd4j.linalg.dataset.api.DataSet-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#fit-org.nd4j.linalg.dataset.api.DataSet-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html" title="interface in org.deeplearning4j.nn.api">NeuralNetwork</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - the data to train on</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.api.ndarray.INDArray-int:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;examples,
                int[]&nbsp;labels)</pre>
<div class="block">Fit the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#fit-org.nd4j.linalg.api.ndarray.INDArray-int:A-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>examples</code> - the examples to classify (one example in each row)</dd>
<dd><code>labels</code> - the labels for each example (the number of labels must match</dd>
</dl>
</li>
</ul>
<a name="output-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;output(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                       <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;train)</pre>
<div class="block">Label the probabilities of the input</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to label</dd>
<dd><code>train</code> - whether the output
             is test or train. This mainly
             affect hyper parameters such as
             drop out where certain things should
             be applied with activations</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a vector of probabilities
 given each label.
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd>
</dl>
</li>
</ul>
<a name="output-org.nd4j.linalg.api.ndarray.INDArray-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;output(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                       boolean&nbsp;train)</pre>
<div class="block">Label the probabilities of the input</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to label</dd>
<dd><code>train</code> - whether the output
             is test or train. This mainly
             affect hyper parameters such as
             drop out where certain things should
             be applied with activations</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a vector of probabilities
 given each label.
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd>
</dl>
</li>
</ul>
<a name="output-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;output(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                       boolean&nbsp;train,
                       <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featuresMask,
                       <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMask)</pre>
<div class="block">Calculate the output of the network, with masking arrays. The masking arrays are used in situations such
 as one-to-many and many-to-one recurrent neural network (RNN) designs, as well as for supporting time series
 of varying lengths within the same minibatch.</div>
</li>
</ul>
<a name="output-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.nd4j.linalg.api.memory.MemoryWorkspace-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;output(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                       boolean&nbsp;train,
                       <a href="../../../../org/nd4j/linalg/api/memory/MemoryWorkspace.html" title="interface in org.nd4j.linalg.api.memory">MemoryWorkspace</a>&nbsp;outputWorkspace)</pre>
<div class="block">Get the network output, which is optionally placed in the specified memory workspace.<br>
 If no memory workspace is provided, the output will be detached (not in any workspace).<br>
 If a memory workspace is provided, the output activation array (i.e., the INDArray returned by this method)
 will be placed in the specified workspace. This workspace must be opened by the user before calling this method -
 and the user is responsible for (a) closing this workspace, and (b) ensuring the output array is not used out
 of scope (i.e., not used after closing the workspace to which it belongs - as this is likely to cause either
 an exception when used, or a crash).</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - Input to the network</dd>
<dd><code>train</code> - True for train, false otherwise</dd>
<dd><code>outputWorkspace</code> - May be null. If not null: the workspace MUST be opened before calling this method.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The output/activations from the network (either detached or in the specified workspace if provided)</dd>
</dl>
</li>
</ul>
<a name="output-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.memory.MemoryWorkspace-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;output(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                       boolean&nbsp;train,
                       <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featuresMask,
                       <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMask,
                       <a href="../../../../org/nd4j/linalg/api/memory/MemoryWorkspace.html" title="interface in org.nd4j.linalg.api.memory">MemoryWorkspace</a>&nbsp;outputWorkspace)</pre>
<div class="block">Get the network output, which is optionally placed in the specified memory workspace.<br>
 If no memory workspace is provided, the output will be detached (not in any workspace).<br>
 If a memory workspace is provided, the output activation array (i.e., the INDArray returned by this method)
 will be placed in the specified workspace. This workspace must be opened by the user before calling this method -
 and the user is responsible for (a) closing this workspace, and (b) ensuring the output array is not used out
 of scope (i.e., not used after closing the workspace to which it belongs - as this is likely to cause either
 an exception when used, or a crash).</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - Input to the network</dd>
<dd><code>train</code> - True for train, false otherwise</dd>
<dd><code>outputWorkspace</code> - May be null. If not null: the workspace MUST be opened before calling this method.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The output/activations from the network (either detached or in the specified workspace if provided)</dd>
</dl>
</li>
</ul>
<a name="output-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;output(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</pre>
<div class="block">Label the probabilities of the input</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to label</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a vector of probabilities
 given each label.
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd>
</dl>
</li>
</ul>
<a name="output-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;output(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
                       boolean&nbsp;train)</pre>
<div class="block">Generate the output for all examples/batches in the input iterator, and concatenate them into a single array</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Data to pass through the network</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>output for all examples in the iterator</dd>
</dl>
</li>
</ul>
<a name="output-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>output</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;output(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator)</pre>
<div class="block">Generate the output for all examples/batches in the input iterator, and concatenate them into a single array</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Data to pass through the network</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>output for all examples in the iterator</dd>
</dl>
</li>
</ul>
<a name="reconstruct-org.nd4j.linalg.api.ndarray.INDArray-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reconstruct</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;reconstruct(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;x,
                            int&nbsp;layerNum)</pre>
<div class="block">Reconstructs the input.
 This is equivalent functionality to a
 deep autoencoder.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>x</code> - the input to transform</dd>
<dd><code>layerNum</code> - the layer to output for encoding</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>a reconstructed matrix
 relative to the size of the last hidden layer.
 This is great for data compression and visualizing
 high dimensional data (or just doing dimensionality reduction).
 <p>
 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd>
</dl>
</li>
</ul>
<a name="printConfiguration--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>printConfiguration</h4>
<pre>public&nbsp;void&nbsp;printConfiguration()</pre>
<div class="block">Prints the configuration</div>
</li>
</ul>
<a name="f1Score-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>f1Score</h4>
<pre>public&nbsp;double&nbsp;f1Score(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                      <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labels)</pre>
<div class="block">Sets the input and labels and returns a score for the prediction
 wrt true labels</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#f1Score-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">f1Score</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to score</dd>
<dd><code>labels</code> - the true labels</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the score for the given input,label pairs</dd>
</dl>
</li>
</ul>
<a name="numLabels--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>numLabels</h4>
<pre>public&nbsp;int&nbsp;numLabels()</pre>
<div class="block">Returns the number of possible labels</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html#numLabels--">numLabels</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Classifier.html" title="interface in org.deeplearning4j.nn.api">Classifier</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the number of possible labels for this classifier</dd>
</dl>
</li>
</ul>
<a name="score-org.nd4j.linalg.dataset.DataSet-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>public&nbsp;double&nbsp;score(<a href="../../../../org/nd4j/linalg/dataset/DataSet.html" title="class in org.nd4j.linalg.dataset">DataSet</a>&nbsp;data)</pre>
<div class="block">Sets the input and labels and returns a score for the prediction with respect to the true labels<br>
 This is equivalent to <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-boolean-"><code>score(DataSet, boolean)</code></a> with training==false.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - the data to score</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the score for the given input,label pairs</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-boolean-"><code>score(DataSet, boolean)</code></a></dd>
</dl>
</li>
</ul>
<a name="score-org.nd4j.linalg.dataset.DataSet-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>public&nbsp;double&nbsp;score(<a href="../../../../org/nd4j/linalg/dataset/DataSet.html" title="class in org.nd4j.linalg.dataset">DataSet</a>&nbsp;data,
                    boolean&nbsp;training)</pre>
<div class="block">Calculate the score (loss function) of the prediction with respect to the true labels<br></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - data to calculate score for</dd>
<dd><code>training</code> - If true: score during training. If false: score at test time. This can affect the application of
                 certain features, such as dropout and dropconnect (which are applied at training time only)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the score (value of the loss function)</dd>
</dl>
</li>
</ul>
<a name="scoreExamples-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>scoreExamples</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;scoreExamples(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iter,
                              boolean&nbsp;addRegularizationTerms)</pre>
</li>
</ul>
<a name="scoreExamples-org.nd4j.linalg.dataset.DataSet-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>scoreExamples</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;scoreExamples(<a href="../../../../org/nd4j/linalg/dataset/DataSet.html" title="class in org.nd4j.linalg.dataset">DataSet</a>&nbsp;data,
                              boolean&nbsp;addRegularizationTerms)</pre>
<div class="block">Calculate the score for each example in a DataSet individually. Unlike <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-"><code>score(DataSet)</code></a> and <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#score-org.nd4j.linalg.dataset.DataSet-boolean-"><code>score(DataSet, boolean)</code></a>
 this method does not average/sum over examples. This method allows for examples to be scored individually (at test time only), which
 may be useful for example for autoencoder architectures and the like.<br>
 Each row of the output (assuming addRegularizationTerms == true) is equivalent to calling score(DataSet) with a single example.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>data</code> - The data to score</dd>
<dd><code>addRegularizationTerms</code> - If true: add l1/l2 regularization terms (if any) to the score. If false: don't add regularization terms</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>An INDArray (column vector) of size input.numRows(); the ith entry is the score (loss value) of the ith example</dd>
</dl>
</li>
</ul>
<a name="fit--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#fit--">Model</a></code></span></div>
<div class="block">All models have a fit method</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#fit--">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="update-org.nd4j.linalg.api.ndarray.INDArray-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>update</h4>
<pre>public&nbsp;void&nbsp;update(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;gradient,
                   java.lang.String&nbsp;paramType)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#update-org.nd4j.linalg.api.ndarray.INDArray-java.lang.String-">Model</a></code></span></div>
<div class="block">Perform one update  applying the gradient</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#update-org.nd4j.linalg.api.ndarray.INDArray-java.lang.String-">update</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>gradient</code> - the gradient to apply</dd>
</dl>
</li>
</ul>
<a name="score--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>score</h4>
<pre>public&nbsp;double&nbsp;score()</pre>
<div class="block">Score of the model (relative to the objective function)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#score--">score</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the score of the model (relative to the objective function)</dd>
</dl>
</li>
</ul>
<a name="setScore-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setScore</h4>
<pre>public&nbsp;void&nbsp;setScore(double&nbsp;score)</pre>
</li>
</ul>
<a name="computeGradientAndScore-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>computeGradientAndScore</h4>
<pre>public&nbsp;void&nbsp;computeGradientAndScore(<a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;layerWorkspaceMgr)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#computeGradientAndScore-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">Model</a></code></span></div>
<div class="block">Update the score</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#computeGradientAndScore-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">computeGradientAndScore</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="computeGradientAndScore--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>computeGradientAndScore</h4>
<pre>public&nbsp;void&nbsp;computeGradientAndScore()</pre>
</li>
</ul>
<a name="clear--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clear</h4>
<pre>public&nbsp;void&nbsp;clear()</pre>
<div class="block">Clear the inputs. Clears optimizer state.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#clear--">clear</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="applyConstraints-int-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applyConstraints</h4>
<pre>public&nbsp;void&nbsp;applyConstraints(int&nbsp;iteration,
                             int&nbsp;epoch)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#applyConstraints-int-int-">Model</a></code></span></div>
<div class="block">Apply any constraints to the model</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#applyConstraints-int-int-">applyConstraints</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="setInput-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setInput</h4>
<pre>public&nbsp;void&nbsp;setInput(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</pre>
<div class="block">Note that if input isn't null
 and the neuralNets are null, this is a way
 of initializing the neural network</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - </dd>
</dl>
</li>
</ul>
<a name="setInput-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setInput</h4>
<pre>public&nbsp;void&nbsp;setInput(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                     <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;mgr)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInput-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">Layer</a></code></span></div>
<div class="block">Set the layer input.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInput-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">setInput</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="getOutputLayer--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOutputLayer</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;getOutputLayer()</pre>
<div class="block">Get the output layer</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="setParameters-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setParameters</h4>
<pre>public&nbsp;void&nbsp;setParameters(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;params)</pre>
<div class="block">Sets parameters for the model.
 This is used to manipulate the weights and biases across
 all neuralNets (including the output layer)</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>params</code> - a parameter vector equal 1,numParameters</dd>
</dl>
</li>
</ul>
<a name="getDefaultConfiguration--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDefaultConfiguration</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/conf/NeuralNetConfiguration.html" title="class in org.deeplearning4j.nn.conf">NeuralNetConfiguration</a>&nbsp;getDefaultConfiguration()</pre>
</li>
</ul>
<a name="getLabels--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLabels</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;getLabels()</pre>
</li>
</ul>
<a name="getInput--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getInput</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;getInput()</pre>
</li>
</ul>
<a name="setLabels-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLabels</h4>
<pre>public&nbsp;void&nbsp;setLabels(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labels)</pre>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>labels</code> - </dd>
</dl>
</li>
</ul>
<a name="getnLayers--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getnLayers</h4>
<pre>public&nbsp;int&nbsp;getnLayers()</pre>
<div class="block">Get the number of layers in the network</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the number of layers in the network</dd>
</dl>
</li>
</ul>
<a name="getLayers--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayers</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]&nbsp;getLayers()</pre>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="getLayer-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayer</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;getLayer(int&nbsp;i)</pre>
</li>
</ul>
<a name="getLayer-java.lang.String-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayer</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>&nbsp;getLayer(java.lang.String&nbsp;name)</pre>
</li>
</ul>
<a name="getLayerNames--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayerNames</h4>
<pre>public&nbsp;java.util.List&lt;java.lang.String&gt;&nbsp;getLayerNames()</pre>
</li>
</ul>
<a name="setLayers-org.deeplearning4j.nn.api.Layer:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLayers</h4>
<pre>public&nbsp;void&nbsp;setLayers(<a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a>[]&nbsp;layers)</pre>
</li>
</ul>
<a name="getMask--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getMask</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;getMask()</pre>
</li>
</ul>
<a name="setMask-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setMask</h4>
<pre>public&nbsp;void&nbsp;setMask(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;mask)</pre>
</li>
</ul>
<a name="getMaskArray--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getMaskArray</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;getMaskArray()</pre>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getMaskArray--">getMaskArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="isPretrainLayer--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isPretrainLayer</h4>
<pre>public&nbsp;boolean&nbsp;isPretrainLayer()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#isPretrainLayer--">Layer</a></code></span></div>
<div class="block">Returns true if the layer can be trained in an unsupervised/pretrain manner (AE, VAE, etc)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#isPretrainLayer--">isPretrainLayer</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>true if the layer can be pretrained (using fit(INDArray), false otherwise</dd>
</dl>
</li>
</ul>
<a name="clearNoiseWeightParams--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clearNoiseWeightParams</h4>
<pre>public&nbsp;void&nbsp;clearNoiseWeightParams()</pre>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#clearNoiseWeightParams--">clearNoiseWeightParams</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="allowInputModification-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>allowInputModification</h4>
<pre>public&nbsp;void&nbsp;allowInputModification(boolean&nbsp;allow)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#allowInputModification-boolean-">Layer</a></code></span></div>
<div class="block">A performance optimization: mark whether the layer is allowed to modify its input array in-place. In many cases,
 this is totally safe - in others, the input array will be shared by multiple layers, and hence it's not safe to
 modify the input array.
 This is usually used by ops such as dropout.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#allowInputModification-boolean-">allowInputModification</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>allow</code> - If true: the input array is safe to modify. If false: the input array should be copied before it
              is modified (i.e., in-place modifications are un-safe)</dd>
</dl>
</li>
</ul>
<a name="feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForwardMaskArray</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/primitives/Pair.html" title="class in org.nd4j.linalg.primitives">Pair</a>&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>,<a href="../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api">MaskState</a>&gt;&nbsp;feedForwardMaskArray(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;maskArray,
                                                     <a href="../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api">MaskState</a>&nbsp;currentMaskState,
                                                     int&nbsp;minibatchSize)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-">Layer</a></code></span></div>
<div class="block">Feed forward the input mask array, setting in in the layer as appropriate. This allows different layers to
 handle masks differently - for example, bidirectional RNNs and normal RNNs operate differently with masks (the
 former sets activations to 0 outside of the data present region (and keeps the mask active for future layers like
 dense layers), whereas normal RNNs don't zero out the activations/errors )instead relying on backpropagated error
 arrays to handle the variable length case.<br>
 This is also used for example for networks that contain global pooling layers, arbitrary preprocessors, etc.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-">feedForwardMaskArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>maskArray</code> - Mask array to set</dd>
<dd><code>currentMaskState</code> - Current state of the mask - see <a href="../../../../org/deeplearning4j/nn/api/MaskState.html" title="enum in org.deeplearning4j.nn.api"><code>MaskState</code></a></dd>
<dd><code>minibatchSize</code> - Current minibatch size. Needs to be known as it cannot always be inferred from the activations
                         array due to reshaping (such as a DenseLayer within a recurrent neural network)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>New mask array after this layer, along with the new mask state.</dd>
</dl>
</li>
</ul>
<a name="getHelper--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getHelper</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/layers/LayerHelper.html" title="interface in org.deeplearning4j.nn.layers">LayerHelper</a>&nbsp;getHelper()</pre>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getHelper--">getHelper</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Get the layer helper, if any</dd>
</dl>
</li>
</ul>
<a name="type--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>type</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Layer.Type.html" title="enum in org.deeplearning4j.nn.api">Layer.Type</a>&nbsp;type()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#type--">Layer</a></code></span></div>
<div class="block">Returns the layer type</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#type--">type</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="activate-org.deeplearning4j.nn.api.Layer.TrainingMode-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;activate(<a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</pre>
</li>
</ul>
<a name="activate-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.Layer.TrainingMode-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;activate(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                         <a href="../../../../org/deeplearning4j/nn/api/Layer.TrainingMode.html" title="enum in org.deeplearning4j.nn.api">Layer.TrainingMode</a>&nbsp;training)</pre>
</li>
</ul>
<a name="backpropGradient-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>backpropGradient</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/primitives/Pair.html" title="class in org.nd4j.linalg.primitives">Pair</a>&lt;<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;backpropGradient(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;epsilon,
                                                <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;workspaceMgr)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#backpropGradient-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">Layer</a></code></span></div>
<div class="block">Calculate the gradient relative to the error in the next layer</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#backpropGradient-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">backpropGradient</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>epsilon</code> - w^(L+1)*delta^(L+1). Or, equiv: dC/da, i.e., (dC/dz)*(dz/da) = dC/da, where C
                     is cost function a=sigma(z) is activation.</dd>
<dd><code>workspaceMgr</code> - Workspace manager</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Pair<Gradient   ,   INDArray> where Gradient is gradient for this layer, INDArray is epsilon (activation gradient)
 needed by next layer, but before element-wise multiply by sigmaPrime(z). So for standard feed-forward layer, if this layer is
 L, then return.getSecond() == dL/dIn = (w^(L)*(delta^(L))^T)^T. Note that the returned array should be placed in the
 <a href="../../../../org/deeplearning4j/nn/workspace/ArrayType.html#ACTIVATION_GRAD"><code>ArrayType.ACTIVATION_GRAD</code></a> workspace via the workspace manager</dd>
</dl>
</li>
</ul>
<a name="setIndex-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setIndex</h4>
<pre>public&nbsp;void&nbsp;setIndex(int&nbsp;index)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setIndex-int-">Layer</a></code></span></div>
<div class="block">Set the layer index.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setIndex-int-">setIndex</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="getIndex--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getIndex</h4>
<pre>public&nbsp;int&nbsp;getIndex()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getIndex--">Layer</a></code></span></div>
<div class="block">Get the layer index.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getIndex--">getIndex</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="getIterationCount--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getIterationCount</h4>
<pre>public&nbsp;int&nbsp;getIterationCount()</pre>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getIterationCount--">getIterationCount</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The current iteration count (number of parameter updates) for the layer/network</dd>
</dl>
</li>
</ul>
<a name="getEpochCount--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getEpochCount</h4>
<pre>public&nbsp;int&nbsp;getEpochCount()</pre>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getEpochCount--">getEpochCount</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The current epoch count (number of training epochs passed) for the layer/network</dd>
</dl>
</li>
</ul>
<a name="setIterationCount-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setIterationCount</h4>
<pre>public&nbsp;void&nbsp;setIterationCount(int&nbsp;iterationCount)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setIterationCount-int-">Layer</a></code></span></div>
<div class="block">Set the current iteration count (number of parameter updates) for the layer/network</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setIterationCount-int-">setIterationCount</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="setEpochCount-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setEpochCount</h4>
<pre>public&nbsp;void&nbsp;setEpochCount(int&nbsp;epochCount)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setEpochCount-int-">Layer</a></code></span></div>
<div class="block">Set the current epoch count (number of epochs passed ) for the layer/network</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setEpochCount-int-">setEpochCount</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="calcL2-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcL2</h4>
<pre>public&nbsp;double&nbsp;calcL2(boolean&nbsp;backpropParamsOnly)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcL2-boolean-">Layer</a></code></span></div>
<div class="block">Calculate the l2 regularization term<br>
 0.0 if regularization is not used. Or 0.5 * l2Coeff * l2Magnitude otherwise.<br>
 Note that this does not divide by mini-batch size</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcL2-boolean-">calcL2</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>backpropParamsOnly</code> - If true: calculate L2 based on backprop params only. If false: calculate
                           based on all params (including pretrain params, if any)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the l2 regularization term for this layer.</dd>
</dl>
</li>
</ul>
<a name="calcL1-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>calcL1</h4>
<pre>public&nbsp;double&nbsp;calcL1(boolean&nbsp;backpropParamsOnly)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcL1-boolean-">Layer</a></code></span></div>
<div class="block">Calculate the l1 regularization term<br>
 0.0 if regularization is not used. Or l1Coeff * l1Magnitude otherwise.<br>
 Note that this does not divide by mini-batch size</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#calcL1-boolean-">calcL1</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>backpropParamsOnly</code> - If true: calculate L1 based on backprop params only. If false: calculate
                           based on all params (including pretrain params, if any)</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the l1 regularization term for this layer.</dd>
</dl>
</li>
</ul>
<a name="update-org.deeplearning4j.nn.gradient.Gradient-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>update</h4>
<pre>public&nbsp;void&nbsp;update(<a href="../../../../org/deeplearning4j/nn/gradient/Gradient.html" title="interface in org.deeplearning4j.nn.gradient">Gradient</a>&nbsp;gradient)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html#update-org.deeplearning4j.nn.gradient.Gradient-">Model</a></code></span></div>
<div class="block">Update layer weights and biases with gradient change</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Model.html#update-org.deeplearning4j.nn.gradient.Gradient-">update</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Model.html" title="interface in org.deeplearning4j.nn.api">Model</a></code></dd>
</dl>
</li>
</ul>
<a name="activate-boolean-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;activate(boolean&nbsp;training,
                         <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;mgr)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-boolean-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">Layer</a></code></span></div>
<div class="block">Perform forward pass and return the activations array with the last set input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-boolean-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>training</code> - training or test mode</dd>
<dd><code>mgr</code> - Workspace manager</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>the activation (layer output) of the last specified input. Note that the returned array should be placed
 in the <a href="../../../../org/deeplearning4j/nn/workspace/ArrayType.html#ACTIVATIONS"><code>ArrayType.ACTIVATIONS</code></a> workspace via the workspace manager</dd>
</dl>
</li>
</ul>
<a name="activate-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>activate</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;activate(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                         boolean&nbsp;training,
                         <a href="../../../../org/deeplearning4j/nn/workspace/LayerWorkspaceMgr.html" title="class in org.deeplearning4j.nn.workspace">LayerWorkspaceMgr</a>&nbsp;mgr)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">Layer</a></code></span></div>
<div class="block">Perform forward pass and return the activations array with the specified input</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#activate-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.deeplearning4j.nn.workspace.LayerWorkspaceMgr-">activate</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - the input to use</dd>
<dd><code>training</code> - train or test mode</dd>
<dd><code>mgr</code> - Workspace manager.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Activations array. Note that the returned array should be placed in the
 <a href="../../../../org/deeplearning4j/nn/workspace/ArrayType.html#ACTIVATIONS"><code>ArrayType.ACTIVATIONS</code></a> workspace via the workspace manager</dd>
</dl>
</li>
</ul>
<a name="setInputMiniBatchSize-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setInputMiniBatchSize</h4>
<pre>public&nbsp;void&nbsp;setInputMiniBatchSize(int&nbsp;size)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInputMiniBatchSize-int-">Layer</a></code></span></div>
<div class="block">Set current/last input mini-batch size.<br>
 Used for score and gradient calculations. Mini batch size may be different from
 getInput().size(0) due to reshaping operations - for example, when using RNNs with
 DenseLayer and OutputLayer. Called automatically during forward pass.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInputMiniBatchSize-int-">setInputMiniBatchSize</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
</dl>
</li>
</ul>
<a name="getInputMiniBatchSize--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getInputMiniBatchSize</h4>
<pre>public&nbsp;int&nbsp;getInputMiniBatchSize()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getInputMiniBatchSize--">Layer</a></code></span></div>
<div class="block">Get current/last input mini-batch size, as set by setInputMiniBatchSize(int)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#getInputMiniBatchSize--">getInputMiniBatchSize</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setInputMiniBatchSize-int-"><code>Layer.setInputMiniBatchSize(int)</code></a></dd>
</dl>
</li>
</ul>
<a name="setMaskArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setMaskArray</h4>
<pre>public&nbsp;void&nbsp;setMaskArray(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;maskArray)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setMaskArray-org.nd4j.linalg.api.ndarray.INDArray-">Layer</a></code></span></div>
<div class="block">Set the mask array. Note: In general, <a href="../../../../org/deeplearning4j/nn/api/Layer.html#feedForwardMaskArray-org.nd4j.linalg.api.ndarray.INDArray-org.deeplearning4j.nn.api.MaskState-int-"><code>Layer.feedForwardMaskArray(INDArray, MaskState, int)</code></a> should be used in
 preference to this.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/Layer.html#setMaskArray-org.nd4j.linalg.api.ndarray.INDArray-">setMaskArray</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/Layer.html" title="interface in org.deeplearning4j.nn.api">Layer</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>maskArray</code> - Mask array to set</dd>
</dl>
</li>
</ul>
<a name="rnnTimeStep-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnTimeStep</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;rnnTimeStep(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input)</pre>
<div class="block">If this MultiLayerNetwork contains one or more RNN layers: conduct forward pass (prediction)
 but using previous stored state for any RNN layers. The activations for the final step are
 also stored in the RNN layers for use next time rnnTimeStep() is called.<br>
 This method can be used to generate output one or more steps at a time instead of always having to do
 forward pass from t=0. Example uses are for streaming data, and for generating samples from network output
 one step at a time (where samples are then fed back into the network as input)<br>
 If no previous state is present in RNN layers (i.e., initially or after calling rnnClearPreviousState()),
 the default initialization (usually 0) is used.<br>
 Supports mini-batch (i.e., multiple predictions/forward pass in parallel) as well as for single examples.<br></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - Input to network. May be for one or multiple time steps. For single time step:
  input has shape [miniBatchSize,inputSize] or [miniBatchSize,inputSize,1]. miniBatchSize=1 for single example.<br>
  For multiple time steps: [miniBatchSize,inputSize,inputTimeSeriesLength]</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Output activations. If output is RNN layer (such as RnnOutputLayer): if input has shape [miniBatchSize,inputSize]
 i.e., is 2d, output has shape [miniBatchSize,outputSize] (i.e., also 2d).<br>
 Otherwise output is 3d [miniBatchSize,outputSize,inputTimeSeriesLength] when using RnnOutputLayer.</dd>
</dl>
</li>
</ul>
<a name="rnnGetPreviousState-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnGetPreviousState</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.String,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;rnnGetPreviousState(int&nbsp;layer)</pre>
<div class="block">Get the state of the RNN layer, as used in rnnTimeStep().</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layer</code> - Number/index of the layer.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Hidden state, or null if layer is not an RNN layer</dd>
</dl>
</li>
</ul>
<a name="rnnSetPreviousState-int-java.util.Map-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnSetPreviousState</h4>
<pre>public&nbsp;void&nbsp;rnnSetPreviousState(int&nbsp;layer,
                                java.util.Map&lt;java.lang.String,<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;state)</pre>
<div class="block">Set the state of the RNN layer.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layer</code> - The number/index of the layer.</dd>
<dd><code>state</code> - The state to set the specified layer to</dd>
</dl>
</li>
</ul>
<a name="rnnClearPreviousState--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnClearPreviousState</h4>
<pre>public&nbsp;void&nbsp;rnnClearPreviousState()</pre>
<div class="block">Clear the previous state of the RNN layers (if any).</div>
</li>
</ul>
<a name="rnnActivateUsingStoredState-org.nd4j.linalg.api.ndarray.INDArray-boolean-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>rnnActivateUsingStoredState</h4>
<pre>public&nbsp;java.util.List&lt;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&gt;&nbsp;rnnActivateUsingStoredState(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;input,
                                                            boolean&nbsp;training,
                                                            boolean&nbsp;storeLastForTBPTT)</pre>
<div class="block">Similar to rnnTimeStep and feedForward() methods. Difference here is that this method:<br>
 (a) like rnnTimeStep does forward pass using stored state for RNN layers, and<br>
 (b) unlike rnnTimeStep does not modify the RNN layer state<br>
 Therefore multiple calls to this method with the same input should have the same output.<br>
 Typically used during training only. Use rnnTimeStep for prediction/forward pass at test time.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>input</code> - Input to network</dd>
<dd><code>training</code> - Whether training or not</dd>
<dd><code>storeLastForTBPTT</code> - set to true if used as part of truncated BPTT training</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Activations for each layer (including input, as per feedforward() etc)</dd>
</dl>
</li>
</ul>
<a name="getUpdater--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getUpdater</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a>&nbsp;getUpdater()</pre>
<div class="block">Get the updater for this MultiLayerNetwork</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Updater for MultiLayerNetwork</dd>
</dl>
</li>
</ul>
<a name="getUpdater-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getUpdater</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a>&nbsp;getUpdater(boolean&nbsp;initializeIfReq)</pre>
</li>
</ul>
<a name="setUpdater-org.deeplearning4j.nn.api.Updater-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setUpdater</h4>
<pre>public&nbsp;void&nbsp;setUpdater(<a href="../../../../org/deeplearning4j/nn/api/Updater.html" title="interface in org.deeplearning4j.nn.api">Updater</a>&nbsp;updater)</pre>
<div class="block">Set the updater for the MultiLayerNetwork</div>
</li>
</ul>
<a name="setLayerMaskArrays-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLayerMaskArrays</h4>
<pre>public&nbsp;void&nbsp;setLayerMaskArrays(<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;featuresMaskArray,
                               <a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;labelsMaskArray)</pre>
<div class="block">Set the mask arrays for features and labels. Mask arrays are typically used in situations such as one-to-many
 and many-to-one learning with recurrent neural networks, as well as for supporting time series of varying lengths
 within the same minibatch.<br>
 For example, with RNN data sets with input of shape [miniBatchSize,nIn,timeSeriesLength] and outputs of shape
 [miniBatchSize,nOut,timeSeriesLength], the features and mask arrays will have shape [miniBatchSize,timeSeriesLength]
 and contain values 0 or 1 at each element (to specify whether a given input/example is present - or merely padding -
 at a given time step).<br>
 <b>NOTE</b>: This method is not usually used directly. Instead, methods such as <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#feedForward-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-"><code>feedForward(INDArray, INDArray, INDArray)</code></a>
 and <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#output-org.nd4j.linalg.api.ndarray.INDArray-boolean-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-"><code>output(INDArray, boolean, INDArray, INDArray)</code></a> handle setting of masking internally.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>featuresMaskArray</code> - Mask array for features (input)</dd>
<dd><code>labelsMaskArray</code> - Mask array for labels (output)</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#clearLayerMaskArrays--"><code>clearLayerMaskArrays()</code></a></dd>
</dl>
</li>
</ul>
<a name="clearLayerMaskArrays--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clearLayerMaskArrays</h4>
<pre>public&nbsp;void&nbsp;clearLayerMaskArrays()</pre>
<div class="block">Remove the mask arrays from all layers.<br>
 See <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLayerMaskArrays-org.nd4j.linalg.api.ndarray.INDArray-org.nd4j.linalg.api.ndarray.INDArray-"><code>setLayerMaskArrays(INDArray, INDArray)</code></a> for details on mask arrays.</div>
</li>
</ul>
<a name="evaluate-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluate</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/Evaluation.html" title="class in org.deeplearning4j.eval">Evaluation</a>&nbsp;evaluate(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator)</pre>
<div class="block">Evaluate the network (classification performance)</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Iterator to evaluate on</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Evaluation object; results of evaluation on all examples in the data set</dd>
</dl>
</li>
</ul>
<a name="evaluateRegression-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluateRegression</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/RegressionEvaluation.html" title="class in org.deeplearning4j.eval">RegressionEvaluation</a>&nbsp;evaluateRegression(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator)</pre>
<div class="block">Evaluate the network for regression performance</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Data to evaluate on</dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="evaluateROC-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluateROC</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval">ROC</a>&nbsp;evaluateROC(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator)</pre>
<div class="block">Evaluate the network (must be a binary classifier) on the specified data, using the <a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval"><code>ROC</code></a> class.
 Defaults to exact mode for <a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval"><code>ROC</code></a> instead of thresholded</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Data to evaluate on</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>ROC evaluation on the given dataset</dd>
</dl>
</li>
</ul>
<a name="evaluateROC-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluateROC</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval">ROC</a>&nbsp;evaluateROC(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
                       int&nbsp;rocThresholdSteps)</pre>
<div class="block">Evaluate the network (must be a binary classifier) on the specified data, using the <a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval"><code>ROC</code></a> class</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Data to evaluate on</dd>
<dd><code>rocThresholdSteps</code> - Number of threshold steps to use with <a href="../../../../org/deeplearning4j/eval/ROC.html" title="class in org.deeplearning4j.eval"><code>ROC</code></a></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>ROC evaluation on the given dataset</dd>
</dl>
</li>
</ul>
<a name="evaluateROCMultiClass-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluateROCMultiClass</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval">ROCMultiClass</a>&nbsp;evaluateROCMultiClass(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator)</pre>
<div class="block">Evaluate the network on the specified data, using the <a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval"><code>ROCMultiClass</code></a> class. Defaults to exact mode for
 <a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval"><code>ROCMultiClass</code></a> instead of thresholded</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Data to evaluate on</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Multi-class ROC evaluation on the given dataset</dd>
</dl>
</li>
</ul>
<a name="evaluateROCMultiClass-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluateROCMultiClass</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval">ROCMultiClass</a>&nbsp;evaluateROCMultiClass(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
                                           int&nbsp;rocThresholdSteps)</pre>
<div class="block">Evaluate the network on the specified data, using the <a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval"><code>ROCMultiClass</code></a> class</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Data to evaluate on</dd>
<dd><code>rocThresholdSteps</code> - Number of threshold steps to use with <a href="../../../../org/deeplearning4j/eval/ROCMultiClass.html" title="class in org.deeplearning4j.eval"><code>ROCMultiClass</code></a></dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Multi-class ROC evaluation on the given dataset</dd>
</dl>
</li>
</ul>
<a name="doEvaluation-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-org.deeplearning4j.eval.IEvaluation:A-">
<!--   -->
</a><a name="doEvaluation-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-T...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>doEvaluation</h4>
<pre>public&nbsp;&lt;T extends <a href="../../../../org/deeplearning4j/eval/IEvaluation.html" title="interface in org.deeplearning4j.eval">IEvaluation</a>&gt;&nbsp;T[]&nbsp;doEvaluation(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
                                                T...&nbsp;evaluations)</pre>
<div class="block">Perform evaluation using an arbitrary IEvaluation instance.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#doEvaluation-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-T...-">doEvaluation</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html" title="interface in org.deeplearning4j.nn.api">NeuralNetwork</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - data to evaluate on</dd>
</dl>
</li>
</ul>
<a name="doEvaluationHelper-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-org.deeplearning4j.eval.IEvaluation:A-">
<!--   -->
</a><a name="doEvaluationHelper-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-T...-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>doEvaluationHelper</h4>
<pre>public&nbsp;&lt;T extends <a href="../../../../org/deeplearning4j/eval/IEvaluation.html" title="interface in org.deeplearning4j.eval">IEvaluation</a>&gt;&nbsp;T[]&nbsp;doEvaluationHelper(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
                                                      T...&nbsp;evaluations)</pre>
</li>
</ul>
<a name="evaluate-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-java.util.List-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluate</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/Evaluation.html" title="class in org.deeplearning4j.eval">Evaluation</a>&nbsp;evaluate(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
                           java.util.List&lt;java.lang.String&gt;&nbsp;labelsList)</pre>
<div class="block">Evaluate the network on the provided data set. Used for evaluating the performance of classifiers</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Data to undertake evaluation on</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Evaluation object, summarizing the results of the evaluation on the provided DataSetIterator</dd>
</dl>
</li>
</ul>
<a name="updaterState--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>updaterState</h4>
<pre>public&nbsp;<a href="../../../../org/nd4j/linalg/api/ndarray/INDArray.html" title="interface in org.nd4j.linalg.api.ndarray">INDArray</a>&nbsp;updaterState()</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#updaterState--">NeuralNetwork</a></code></span></div>
<div class="block">This method returns updater state (if applicable), null otherwise</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#updaterState--">updaterState</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html" title="interface in org.deeplearning4j.nn.api">NeuralNetwork</a></code></dd>
<dt><span class="returnLabel">Returns:</span></dt>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.dataset.api.MultiDataSet-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(<a href="../../../../org/nd4j/linalg/dataset/api/MultiDataSet.html" title="interface in org.nd4j.linalg.dataset.api">MultiDataSet</a>&nbsp;dataSet)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#fit-org.nd4j.linalg.dataset.api.MultiDataSet-">NeuralNetwork</a></code></span></div>
<div class="block">This method fits model with a given MultiDataSet</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#fit-org.nd4j.linalg.dataset.api.MultiDataSet-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html" title="interface in org.deeplearning4j.nn.api">NeuralNetwork</a></code></dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.dataset.api.iterator.MultiDataSetIterator-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(@NonNull
                <a href="../../../../org/nd4j/linalg/dataset/api/iterator/MultiDataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">MultiDataSetIterator</a>&nbsp;iterator,
                int&nbsp;numEpochs)</pre>
<div class="block">Perform minibatch training on all minibatches in the MultiDataSetIterator, for the specified number of epochs.
 Equvalent to calling <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.dataset.api.iterator.MultiDataSetIterator-"><code>fit(MultiDataSetIterator)</code></a> numEpochs times in a loop</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Training data (DataSetIterator). Iterator must support resetting</dd>
<dd><code>numEpochs</code> - Number of training epochs, >= 1</dd>
</dl>
</li>
</ul>
<a name="fit-org.nd4j.linalg.dataset.api.iterator.MultiDataSetIterator-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fit</h4>
<pre>public&nbsp;void&nbsp;fit(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/MultiDataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">MultiDataSetIterator</a>&nbsp;iterator)</pre>
<div class="block">Perform minibatch training on all minibatches in the MultiDataSetIterator.<br>
 Note: The MultiDataSets in the MultiDataSetIterator must have exactly 1 input and output array (as
 MultiLayerNetwork only supports 1 input and 1 output)</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#fit-org.nd4j.linalg.dataset.api.iterator.MultiDataSetIterator-">fit</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html" title="interface in org.deeplearning4j.nn.api">NeuralNetwork</a></code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Training data (DataSetIterator). Iterator must support resetting</dd>
</dl>
</li>
</ul>
<a name="doEvaluation-org.nd4j.linalg.dataset.api.iterator.MultiDataSetIterator-org.deeplearning4j.eval.IEvaluation:A-">
<!--   -->
</a><a name="doEvaluation-org.nd4j.linalg.dataset.api.iterator.MultiDataSetIterator-T:A-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>doEvaluation</h4>
<pre>public&nbsp;&lt;T extends <a href="../../../../org/deeplearning4j/eval/IEvaluation.html" title="interface in org.deeplearning4j.eval">IEvaluation</a>&gt;&nbsp;T[]&nbsp;doEvaluation(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/MultiDataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">MultiDataSetIterator</a>&nbsp;iterator,
                                                T[]&nbsp;evaluations)</pre>
<div class="block"><span class="descfrmTypeLabel">Description copied from interface:&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#doEvaluation-org.nd4j.linalg.dataset.api.iterator.MultiDataSetIterator-T...-">NeuralNetwork</a></code></span></div>
<div class="block">This method executes evaluation of the model against given iterator and evaluation implementations</div>
<dl>
<dt><span class="overrideSpecifyLabel">Specified by:</span></dt>
<dd><code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html#doEvaluation-org.nd4j.linalg.dataset.api.iterator.MultiDataSetIterator-T...-">doEvaluation</a></code>&nbsp;in interface&nbsp;<code><a href="../../../../org/deeplearning4j/nn/api/NeuralNetwork.html" title="interface in org.deeplearning4j.nn.api">NeuralNetwork</a></code></dd>
</dl>
</li>
</ul>
<a name="evaluate-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-java.util.List-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>evaluate</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/eval/Evaluation.html" title="class in org.deeplearning4j.eval">Evaluation</a>&nbsp;evaluate(<a href="../../../../org/nd4j/linalg/dataset/api/iterator/DataSetIterator.html" title="interface in org.nd4j.linalg.dataset.api.iterator">DataSetIterator</a>&nbsp;iterator,
                           java.util.List&lt;java.lang.String&gt;&nbsp;labelsList,
                           int&nbsp;topN)</pre>
<div class="block">Evaluate the network (for classification) on the provided data set, with top N accuracy in addition to standard accuracy.
 For 'standard' accuracy evaluation only, use topN = 1</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>iterator</code> - Iterator (data) to evaluate on</dd>
<dd><code>labelsList</code> - List of labels. May be null.</dd>
<dd><code>topN</code> - N value for top N accuracy evaluation</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Evaluation object, summarizing the results of the evaluation on the provided DataSetIterator</dd>
</dl>
</li>
</ul>
<a name="update-org.nd4j.linalg.heartbeat.reports.Task-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>update</h4>
<pre>protected&nbsp;void&nbsp;update(<a href="../../../../org/nd4j/linalg/heartbeat/reports/Task.html" title="class in org.nd4j.linalg.heartbeat.reports">Task</a>&nbsp;task)</pre>
</li>
</ul>
<a name="summary--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>summary</h4>
<pre>public&nbsp;java.lang.String&nbsp;summary()</pre>
<div class="block">String detailing the architecture of the multilayernetwork.
 Columns are LayerIndex with layer type, nIn, nOut, Total number of parameters and the Shapes of the parameters
 Will also give information about frozen layers, if any.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Summary as a string</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#memoryInfo-int-org.deeplearning4j.nn.conf.inputs.InputType-"><code>memoryInfo(int, InputType)</code></a></dd>
</dl>
</li>
</ul>
<a name="summary-org.deeplearning4j.nn.conf.inputs.InputType-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>summary</h4>
<pre>public&nbsp;java.lang.String&nbsp;summary(<a href="../../../../org/deeplearning4j/nn/conf/inputs/InputType.html" title="class in org.deeplearning4j.nn.conf.inputs">InputType</a>&nbsp;inputType)</pre>
<div class="block">String detailing the architecture of the multilayernetwork.
 Will also display activation size when given an input type.
 Columns are LayerIndex with layer type, nIn, nOut, Total number of parameters, Shapes of the parameters, Input activation shape, Output activation shape
 Will also give information about frozen layers, if any.</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Summary as a string</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#memoryInfo-int-org.deeplearning4j.nn.conf.inputs.InputType-"><code>memoryInfo(int, InputType)</code></a></dd>
</dl>
</li>
</ul>
<a name="memoryInfo-int-org.deeplearning4j.nn.conf.inputs.InputType-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>memoryInfo</h4>
<pre>public&nbsp;java.lang.String&nbsp;memoryInfo(int&nbsp;minibatch,
                                   <a href="../../../../org/deeplearning4j/nn/conf/inputs/InputType.html" title="class in org.deeplearning4j.nn.conf.inputs">InputType</a>&nbsp;inputType)</pre>
<div class="block">Generate information regarding memory use for the network, for the given input type and minibatch size.
 Note that when using workspaces or CuDNN, the network should be trained for some iterations so that the memory
 workspaces have time to initialize. Without this, the memory requirements during training may be underestimated.

 Note also that this is the same information that is generated during an OOM crash when training or performing
 inference.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>minibatch</code> - Minibatch size to estimate memory for</dd>
<dd><code>inputType</code> - Input type to the network</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>A String with information about network memory use information</dd>
</dl>
</li>
</ul>
<a name="clearLayersStates--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clearLayersStates</h4>
<pre>protected&nbsp;void&nbsp;clearLayersStates()</pre>
<div class="block">This method just makes sure there's no state preserved within layers</div>
</li>
</ul>
<a name="incrementEpochCount--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>incrementEpochCount</h4>
<pre>public&nbsp;void&nbsp;incrementEpochCount()</pre>
<div class="block">Increment the epoch count (in the underlying <a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html" title="class in org.deeplearning4j.nn.conf"><code>MultiLayerConfiguration</code></a> by 1).
 Note that this is done <i>automatically</i> when using iterator-based fitting methods, such as
 <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#fit-org.nd4j.linalg.dataset.api.iterator.DataSetIterator-"><code>fit(DataSetIterator)</code></a>. However, when using non-iterator fit methods (DataSet, INDArray/INDArray etc),
 the network has no way to know when one epoch ends and another starts. In such situations, this method
 can be used to increment the epoch counter.<br>
 Note that the epoch counter is used for situations such as some learning rate schedules, and the like.

 The current epoch count can be obtained using <code>MultiLayerConfiguration.getLayerwiseConfiguration().getEpochCount()</code></div>
</li>
</ul>
<a name="synchronizeIterEpochCounts--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>synchronizeIterEpochCounts</h4>
<pre>protected&nbsp;void&nbsp;synchronizeIterEpochCounts()</pre>
</li>
</ul>
<a name="save-java.io.File-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>save</h4>
<pre>public&nbsp;void&nbsp;save(java.io.File&nbsp;f)
          throws java.io.IOException</pre>
<div class="block">Save the MultiLayerNetwork to a file. Restore using <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#load-java.io.File-boolean-"><code>load(File, boolean)</code></a>.
 Note that this saves the updater (i.e., the state array for momentum/Adam/rmsprop etc), which is desirable
 if further training will be undertaken.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>f</code> - File to save the network to</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>java.io.IOException</code></dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/util/ModelSerializer.html" title="class in org.deeplearning4j.util"><code>ModelSerializer for more details (and saving/loading via streams)</code></a>, 
<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#save-java.io.File-boolean-"><code>save(File, boolean)</code></a></dd>
</dl>
</li>
</ul>
<a name="save-java.io.File-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>save</h4>
<pre>public&nbsp;void&nbsp;save(java.io.File&nbsp;f,
                 boolean&nbsp;saveUpdater)
          throws java.io.IOException</pre>
<div class="block">Save the MultiLayerNetwork to a file. Restore using <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#load-java.io.File-boolean-"><code>load(File, boolean)</code></a>.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>f</code> - File to save the network to</dd>
<dd><code>saveUpdater</code> - If true: save the updater (i.e., the state array for momentum/Adam/rmsprop etc), which should
                    usually be saved if further training is required</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>java.io.IOException</code></dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/util/ModelSerializer.html" title="class in org.deeplearning4j.util"><code>ModelSerializer for more details (and saving/loading via streams)</code></a>, 
<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#save-java.io.File-boolean-"><code>save(File, boolean)</code></a></dd>
</dl>
</li>
</ul>
<a name="load-java.io.File-boolean-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>load</h4>
<pre>public static&nbsp;<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" title="class in org.deeplearning4j.nn.multilayer">MultiLayerNetwork</a>&nbsp;load(java.io.File&nbsp;f,
                                     boolean&nbsp;loadUpdater)
                              throws java.io.IOException</pre>
<div class="block">Restore a MultiLayerNetwork to a file, saved using <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#save-java.io.File-"><code>save(File)</code></a> or <a href="../../../../org/deeplearning4j/util/ModelSerializer.html" title="class in org.deeplearning4j.util"><code>ModelSerializer</code></a></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>f</code> - File to load the network from</dd>
<dd><code>loadUpdater</code> - If true: load the updater if it is available (i.e., the state array for momentum/Adam/rmsprop
                   etc) - use <i>false</i> if no further training is required, or <i>true</i> if further training
                    will be undertaken</dd>
<dt><span class="throwsLabel">Throws:</span></dt>
<dd><code>java.io.IOException</code></dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/util/ModelSerializer.html" title="class in org.deeplearning4j.util"><code>ModelSerializer for more details (and saving/loading via streams)</code></a></dd>
</dl>
</li>
</ul>
<a name="toComputationGraph--">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>toComputationGraph</h4>
<pre>public&nbsp;<a href="../../../../org/deeplearning4j/nn/graph/ComputationGraph.html" title="class in org.deeplearning4j.nn.graph">ComputationGraph</a>&nbsp;toComputationGraph()</pre>
<div class="block">Convert this MultiLayerNetwork to a ComputationGraph</div>
<dl>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>ComputationGraph equivalent to this network (including parameters and updater state)</dd>
</dl>
</li>
</ul>
<a name="setLearningRate-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLearningRate</h4>
<pre>public&nbsp;void&nbsp;setLearningRate(double&nbsp;newLr)</pre>
<div class="block">Set the learning rate for all layers in the network to the specified value. Note that if any learning rate
 schedules are currently present, these will be removed in favor of the new (fixed) learning rate.<br>
 <br>
 <b>Note</b>: <i>This method not free from a performance point of view</i>: a proper learning rate schedule
 should be used in preference to calling this method at every iteration.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>newLr</code> - New learning rate for all layers</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-org.nd4j.linalg.schedule.ISchedule-"><code>setLearningRate(ISchedule)</code></a>, 
<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-int-double-"><code>setLearningRate(int, double)</code></a></dd>
</dl>
</li>
</ul>
<a name="setLearningRate-org.nd4j.linalg.schedule.ISchedule-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLearningRate</h4>
<pre>public&nbsp;void&nbsp;setLearningRate(<a href="../../../../org/nd4j/linalg/schedule/ISchedule.html" title="interface in org.nd4j.linalg.schedule">ISchedule</a>&nbsp;newLr)</pre>
<div class="block">Set the learning rate schedule for all layers in the network to the specified schedule.
 This schedule will replace any/all existing schedules, and also any fixed learning rate values.<br>
 Note that the iteration/epoch counts will <i>not</i> be reset. Use <code>MultiLayerConfiguration#setIterationCount(int)</code>
 and <a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html#setEpochCount-int-"><code>MultiLayerConfiguration.setEpochCount(int)</code></a> if this is required</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>newLr</code> - New learning rate schedule for all layers</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-org.nd4j.linalg.schedule.ISchedule-"><code>setLearningRate(ISchedule)</code></a>, 
<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-int-double-"><code>setLearningRate(int, double)</code></a></dd>
</dl>
</li>
</ul>
<a name="setLearningRate-int-double-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLearningRate</h4>
<pre>public&nbsp;void&nbsp;setLearningRate(int&nbsp;layerNumber,
                            double&nbsp;newLr)</pre>
<div class="block">Set the learning rate for a single layer in the network to the specified value. Note that if any learning rate
 schedules are currently present, these will be removed in favor of the new (fixed) learning rate.<br>
 <br>
 <b>Note</b>: <i>This method not free from a performance point of view</i>: a proper learning rate schedule
 should be used in preference to calling this method at every iteration. Note also that
 <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-double-"><code>setLearningRate(double)</code></a> should also be used in preference, when all layers need to be set to a new LR</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerNumber</code> - Number of the layer to set the LR for</dd>
<dd><code>newLr</code> - New learning rate for a single layer</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-org.nd4j.linalg.schedule.ISchedule-"><code>setLearningRate(ISchedule)</code></a>, 
<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-int-double-"><code>setLearningRate(int, double)</code></a></dd>
</dl>
</li>
</ul>
<a name="setLearningRate-int-org.nd4j.linalg.schedule.ISchedule-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLearningRate</h4>
<pre>public&nbsp;void&nbsp;setLearningRate(int&nbsp;layerNumber,
                            <a href="../../../../org/nd4j/linalg/schedule/ISchedule.html" title="interface in org.nd4j.linalg.schedule">ISchedule</a>&nbsp;newLr)</pre>
<div class="block">Set the learning rate schedule for a single layer in the network to the specified value.<br>
 Note also that <a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-org.nd4j.linalg.schedule.ISchedule-"><code>setLearningRate(ISchedule)</code></a> should also be used in preference, when all layers need
 to be set to a new LR schedule.<br>
 This schedule will replace any/all existing schedules, and also any fixed learning rate values.<br>
 Note also that the iteration/epoch counts will <i>not</i> be reset. Use <code>MultiLayerConfiguration#setIterationCount(int)</code>
 and <a href="../../../../org/deeplearning4j/nn/conf/MultiLayerConfiguration.html#setEpochCount-int-"><code>MultiLayerConfiguration.setEpochCount(int)</code></a> if this is required</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerNumber</code> - Number of the layer to set the LR schedule for</dd>
<dd><code>newLr</code> - New learning rate for a single layer</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-org.nd4j.linalg.schedule.ISchedule-"><code>setLearningRate(ISchedule)</code></a>, 
<a href="../../../../org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html#setLearningRate-int-double-"><code>setLearningRate(int, double)</code></a></dd>
</dl>
</li>
</ul>
<a name="getLearningRate-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLearningRate</h4>
<pre>public&nbsp;java.lang.Double&nbsp;getLearningRate(int&nbsp;layerNumber)</pre>
<div class="block">Get the current learning rate, for the specified layer, from the network.
 Note: If the layer has no learning rate (no parameters, or an updater without a learning rate) then null is returned</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layerNumber</code> - Layer number to get the learning rate for</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Learning rate for the specified layer, or null</dd>
</dl>
</li>
</ul>
<a name="layerSize-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layerSize</h4>
<pre>public&nbsp;int&nbsp;layerSize(int&nbsp;layer)</pre>
<div class="block">Return the layer size (number of units) for the specified layer.<br>
 Note that the meaning of the "layer size" can depend on the type of layer. For example:<br>
 - DenseLayer, OutputLayer, recurrent layers: number of units (nOut configuration option)<br>
 - ConvolutionLayer: the channels (number of channels)<br>
 - Subsampling layers, global pooling layers, etc: size of 0 is always returned<br></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layer</code> - Index of the layer to get the size of. Must be in range 0 to nLayers-1 inclusive</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Size of the layer</dd>
</dl>
</li>
</ul>
<a name="layerInputSize-int-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>layerInputSize</h4>
<pre>public&nbsp;int&nbsp;layerInputSize(int&nbsp;layer)</pre>
<div class="block">Return the input size (number of inputs) for the specified layer.<br>
 Note that the meaning of the "input size" can depend on the type of layer. For example:<br>
 - DenseLayer, OutputLayer, etc: the feature vector size (nIn configuration option)<br>
 - Recurrent layers: the feature vector size <i>per time step</i> (nIn configuration option)<br>
 - ConvolutionLayer: the channels (number of channels)<br>
 - Subsampling layers, global pooling layers, etc: size of 0 is always returned<br></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>layer</code> - Index of the layer to get the size of. Must be in range 0 to nLayers-1 inclusive</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>Size of the layer</dd>
</dl>
</li>
</ul>
<a name="equals-java.lang.Object-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>equals</h4>
<pre>public&nbsp;boolean&nbsp;equals(java.lang.Object&nbsp;obj)</pre>
<div class="block">Indicates whether some other object is "equal to" this one.
 <p>
 The <code>equals</code> method implements an equivalence relation
 on non-null object references:
 <ul>
 <li>It is <i>reflexive</i>: for any non-null reference value
 <code>x</code>, <code>x.equals(x)</code> should return
 <code>true</code>.
 <li>It is <i>symmetric</i>: for any non-null reference values
 <code>x</code> and <code>y</code>, <code>x.equals(y)</code>
 should return <code>true</code> if and only if
 <code>y.equals(x)</code> returns <code>true</code>.
 <li>It is <i>transitive</i>: for any non-null reference values
 <code>x</code>, <code>y</code>, and <code>z</code>, if
 <code>x.equals(y)</code> returns <code>true</code> and
 <code>y.equals(z)</code> returns <code>true</code>, then
 <code>x.equals(z)</code> should return <code>true</code>.
 <li>It is <i>consistent</i>: for any non-null reference values
 <code>x</code> and <code>y</code>, multiple invocations of
 <code>x.equals(y)</code> consistently return <code>true</code>
 or consistently return <code>false</code>, provided no
 information used in <code>equals</code> comparisons on the
 objects is modified.
 <li>For any non-null reference value <code>x</code>,
 <code>x.equals(null)</code> should return <code>false</code>.
 </ul>
 <p>
 The <code>equals</code> method for class <code>Object</code> implements
 the most discriminating possible equivalence relation on objects;
 that is, for any non-null reference values <code>x</code> and
 <code>y</code>, this method returns <code>true</code> if and only
 if <code>x</code> and <code>y</code> refer to the same object
 (<code>x == y</code> has the value <code>true</code>).
 <p>
 Note that it is generally necessary to override the <code>hashCode</code>
 method whenever this method is overridden, so as to maintain the
 general contract for the <code>hashCode</code> method, which states
 that equal objects must have equal hash codes.</div>
<dl>
<dt><span class="overrideSpecifyLabel">Overrides:</span></dt>
<dd><code>equals</code>&nbsp;in class&nbsp;<code>java.lang.Object</code></dd>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>obj</code> - the reference object with which to compare.</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd><code>true</code> if this object is the same as the obj
 argument; <code>false</code> otherwise.</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><code>Object.hashCode()</code>, 
<code>HashMap</code></dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev&nbsp;Class</li>
<li>Next&nbsp;Class</li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/deeplearning4j/nn/multilayer/MultiLayerNetwork.html" target="_top">Frames</a></li>
<li><a href="MultiLayerNetwork.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor.detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
