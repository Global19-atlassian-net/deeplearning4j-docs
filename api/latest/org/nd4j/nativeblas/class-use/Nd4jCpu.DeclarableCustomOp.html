<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="de">
<head>
<!-- Generated by javadoc (1.8.0_151) on Sat Mar 14 12:12:07 CET 2020 -->
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Uses of Class org.nd4j.nativeblas.Nd4jCpu.DeclarableCustomOp (deeplearning4j 1.0.0-beta6 API)</title>
<meta name="date" content="2020-03-14">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="Uses of Class org.nd4j.nativeblas.Nd4jCpu.DeclarableCustomOp (deeplearning4j 1.0.0-beta6 API)";
        }
    }
    catch(err) {
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="../package-summary.html">Package</a></li>
<li><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.DeclarableCustomOp.html" title="class in org.nd4j.nativeblas">Class</a></li>
<li class="navBarCell1Rev">Use</li>
<li><a href="../package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev</li>
<li>Next</li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/nd4j/nativeblas/class-use/Nd4jCpu.DeclarableCustomOp.html" target="_top">Frames</a></li>
<li><a href="Nd4jCpu.DeclarableCustomOp.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<div class="header">
<h2 title="Uses of Class org.nd4j.nativeblas.Nd4jCpu.DeclarableCustomOp" class="title">Uses of Class<br>org.nd4j.nativeblas.Nd4jCpu.DeclarableCustomOp</h2>
</div>
<div class="classUseContainer">
<ul class="blockList">
<li class="blockList">
<table class="useSummary" border="0" cellpadding="3" cellspacing="0" summary="Use table, listing packages, and an explanation">
<caption><span>Packages that use <a href="../../../../org/nd4j/nativeblas/Nd4jCpu.DeclarableCustomOp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.DeclarableCustomOp</a></span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Package</th>
<th class="colLast" scope="col">Description</th>
</tr>
<tbody>
<tr class="altColor">
<td class="colFirst"><a href="#org.nd4j.nativeblas">org.nd4j.nativeblas</a></td>
<td class="colLast">&nbsp;</td>
</tr>
</tbody>
</table>
</li>
<li class="blockList">
<ul class="blockList">
<li class="blockList"><a name="org.nd4j.nativeblas">
<!--   -->
</a>
<h3>Uses of <a href="../../../../org/nd4j/nativeblas/Nd4jCpu.DeclarableCustomOp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.DeclarableCustomOp</a> in <a href="../../../../org/nd4j/nativeblas/package-summary.html">org.nd4j.nativeblas</a></h3>
<table class="useSummary" border="0" cellpadding="3" cellspacing="0" summary="Use table, listing subclasses, and an explanation">
<caption><span>Subclasses of <a href="../../../../org/nd4j/nativeblas/Nd4jCpu.DeclarableCustomOp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.DeclarableCustomOp</a> in <a href="../../../../org/nd4j/nativeblas/package-summary.html">org.nd4j.nativeblas</a></span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tbody>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.absolute_difference_loss.html" title="class in org.nd4j.nativeblas">Nd4jCpu.absolute_difference_loss</a></span></code>
<div class="block">Implementation of Absolute Difference loss function |predictions - labels|
 
 Input arrays: 
    0: predictions - the predicted values, type float.
    1: weights - is used for weighting (multiplying) of loss values, type float.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.absolute_difference_loss_grad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.absolute_difference_loss_grad</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.add.html" title="class in org.nd4j.nativeblas">Nd4jCpu.add</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.add_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.add_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.argmax.html" title="class in org.nd4j.nativeblas">Nd4jCpu.argmax</a></span></code>
<div class="block">This operation returns index of max element in a given NDArray (optionally: along given dimension(s))
 Expected input:
 0: N-dimensional array
 1: optional axis vector

 Int args:
 0: optional axis</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.argmin.html" title="class in org.nd4j.nativeblas">Nd4jCpu.argmin</a></span></code>
<div class="block">This operation returns index of min element in a given NDArray (optionally: along given dimension(s))
 Expected input:
 0: N-dimensional array
 1: optional axis vector

 Int args:
 0: optional axis</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.assign.html" title="class in org.nd4j.nativeblas">Nd4jCpu.assign</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.assign_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.assign_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.avgpool2d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.avgpool2d</a></span></code>
<div class="block">This op implements average pooling for convolution networks.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.avgpool2d_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.avgpool2d_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.avgpool3dnew.html" title="class in org.nd4j.nativeblas">Nd4jCpu.avgpool3dnew</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.avgpool3dnew_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.avgpool3dnew_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.batch_to_space.html" title="class in org.nd4j.nativeblas">Nd4jCpu.batch_to_space</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.batch_to_space_nd.html" title="class in org.nd4j.nativeblas">Nd4jCpu.batch_to_space_nd</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.batched_gemm.html" title="class in org.nd4j.nativeblas">Nd4jCpu.batched_gemm</a></span></code>
<div class="block">This operation implements batched matrix multiplication
 Expected arguments:
 alpha: vector of T
 beta: vector of T
 ...: A, B matrices sequentially. i.e: AAAAABBBBB
 
 Integer arguments:
 transA, transB, M, N, K, ldA, ldB, ldC - usual BLAS gemm arguments
 batchCount - number of operations in this batch
 
 PLEASE NOTE: M, N, K, ldA, ldB, ldC should be equal for all matrices within batch.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.batchnorm.html" title="class in org.nd4j.nativeblas">Nd4jCpu.batchnorm</a></span></code>
<div class="block">Batch normalization implementation.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.batchnorm_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.batchnorm_bp</a></span></code>
<div class="block">back prop in batch normalization

 Expected arguments:
 input: input array (any number of dimensions)
 mean:
 variance:
 gamma: optional
 beta: optional
 dLdOut: next epsilon

 Int args:
 0: apply scale
 1: apply offset

 T args:
 0: epsilon

 output arrays:
 dL/dInput
 dL/dMean
 dL/dVariance
 dL/dGamma, optional
 dL/dBeta, optional</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.biasadd.html" title="class in org.nd4j.nativeblas">Nd4jCpu.biasadd</a></span></code>
<div class="block">This operation is added for compatibility purposes mostly.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.biasadd_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.biasadd_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.bincount.html" title="class in org.nd4j.nativeblas">Nd4jCpu.bincount</a></span></code>
<div class="block">bincount operation return a vector with element counted.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.bitcast.html" title="class in org.nd4j.nativeblas">Nd4jCpu.bitcast</a></span></code>
<div class="block">This operation change type of input and modified shape of output to conform with given data type

 all as above op</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.bits_hamming_distance.html" title="class in org.nd4j.nativeblas">Nd4jCpu.bits_hamming_distance</a></span></code>
<div class="block">This operation returns hamming distance based on bits

 PLEASE NOTE: This operation is applicable only to integer data types

 \tparam T</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.bitwise_and.html" title="class in org.nd4j.nativeblas">Nd4jCpu.bitwise_and</a></span></code>
<div class="block">This operation applies bitwise AND

 PLEASE NOTE: This operation is applicable only to integer data types

 \tparam T</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.bitwise_or.html" title="class in org.nd4j.nativeblas">Nd4jCpu.bitwise_or</a></span></code>
<div class="block">This operation applies bitwise OR

 PLEASE NOTE: This operation is applicable only to integer data types

 \tparam T</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.bitwise_xor.html" title="class in org.nd4j.nativeblas">Nd4jCpu.bitwise_xor</a></span></code>
<div class="block">This operation applies bitwise XOR

 PLEASE NOTE: This operation is applicable only to integer data types

 \tparam T</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.boolean_and.html" title="class in org.nd4j.nativeblas">Nd4jCpu.boolean_and</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.boolean_or.html" title="class in org.nd4j.nativeblas">Nd4jCpu.boolean_or</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.boolean_xor.html" title="class in org.nd4j.nativeblas">Nd4jCpu.boolean_xor</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.broadcast_dynamic_shape.html" title="class in org.nd4j.nativeblas">Nd4jCpu.broadcast_dynamic_shape</a></span></code>
<div class="block">broadcast_dynamic_shape op.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.broadcast_to.html" title="class in org.nd4j.nativeblas">Nd4jCpu.broadcast_to</a></span></code>
<div class="block">This op broadcast given input up to given shape
  
 inputs:
  input array - array to be broadcasted to given shape
  shape array - array containing shape be broadcasted to</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.BroadcastableOp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.BroadcastableOp</a></span></code>
<div class="block">Copyright (c) 2015-2018 Skymind, Inc.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.cast.html" title="class in org.nd4j.nativeblas">Nd4jCpu.cast</a></span></code>
<div class="block">This operation casts elements of input array to specified data type
 
 PLEASE NOTE: This op is disabled atm, and reserved for future releases.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.check_numerics.html" title="class in org.nd4j.nativeblas">Nd4jCpu.check_numerics</a></span></code>
<div class="block">This op checks for Inf/NaN values within input array, and throws exception if there's at least one</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.choose.html" title="class in org.nd4j.nativeblas">Nd4jCpu.choose</a></span></code>
<div class="block">This op takes either 1 argument and 1 scalar
 or 1 argument and another comparison array
 and runs a pre defined conditional op.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.clip_by_global_norm.html" title="class in org.nd4j.nativeblas">Nd4jCpu.clip_by_global_norm</a></span></code>
<div class="block">clip a list of given tensors with given average norm when needed

 Input:
    a list of tensors (at least one)

 Input floating point argument:
    clip_norm - a value that used as threshold value and norm to be used

 return a list of clipped tensors
  and global_norm as scalar tensor at the end</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.clipbynorm_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.clipbynorm_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.col2im.html" title="class in org.nd4j.nativeblas">Nd4jCpu.col2im</a></span></code>
<div class="block">This op implements col2im algorithm, widely used in convolution neural networks
 Input: 6D input expected (like output of im2col op)

 Int args:
 0: stride height
 1: stride width
 2: padding height
 3: padding width
 4: image height
 5: image width
 6: dilation height
 7: dilation width</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.compare_and_bitpack.html" title="class in org.nd4j.nativeblas">Nd4jCpu.compare_and_bitpack</a></span></code>
<div class="block">compare_and_bitpack - compare with greater and pack result with uint8

 input params:
    0 - NDArray (input)
    1 - 0D Tensor - threshold


 output:
    0 - NDArray with the same shape as input and type uint8</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.concat.html" title="class in org.nd4j.nativeblas">Nd4jCpu.concat</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.concat_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.concat_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.confusion_matrix.html" title="class in org.nd4j.nativeblas">Nd4jCpu.confusion_matrix</a></span></code>
<div class="block">This operation calculate the confusion matrix for a
 pair of prediction and label 1-D arrays.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.conv1d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.conv1d</a></span></code>
<div class="block">1D temporal convolution implementation
 Expected input:
 x: 3D array
 weight: 3D Array
 bias: optional vector

 Int args:
 0: kernel
 1: stride
 2: padding</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.conv1d_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.conv1d_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.conv2d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.conv2d</a></span></code>
<div class="block">2D convolution implementation
 Expected input:
 x: 4D array
 weight: 4D Array
 bias: optional vector, length of outputChannels

 IntArgs:
 0: kernel height
 1: kernel width
 2: stride height
 3: stride width
 4: padding height
 5: padding width
 6: dilation height
 7: dilation width
 8: same mode:   1 true, 0 false
 9: data format: 1 NHWC, 0 NCHW</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.conv2d_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.conv2d_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.conv2d_input_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.conv2d_input_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.conv3dnew.html" title="class in org.nd4j.nativeblas">Nd4jCpu.conv3dnew</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.conv3dnew_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.conv3dnew_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.cosine_distance_loss.html" title="class in org.nd4j.nativeblas">Nd4jCpu.cosine_distance_loss</a></span></code>
<div class="block">Implementation of cosine-distance loss function 1. - (predictions * labels).reduce_sum_along(dimension)
 
 Input arrays: 
    0: predictions - the predicted values, type float
    1: weights - is used for weighting (multiplying) of loss values, type float.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.cosine_distance_loss_grad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.cosine_distance_loss_grad</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.create.html" title="class in org.nd4j.nativeblas">Nd4jCpu.create</a></span></code>
<div class="block">This operation creates new array
 Input:
    array with shape values

 IArgs:
    order value
    data type value

 BArgs:
    initialization option</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.crelu.html" title="class in org.nd4j.nativeblas">Nd4jCpu.crelu</a></span></code>
<div class="block">This is Concatenated RELU implementation.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.crelu_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.crelu_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.crop_and_resize.html" title="class in org.nd4j.nativeblas">Nd4jCpu.crop_and_resize</a></span></code>
<div class="block">This op make bilinear or nearest neighbor interpolated resize for given tensor

 input array:
    0 - 4D-Tensor with shape (batch, sizeX, sizeY, channels) numeric type
    1 - 2D-Tensor with shape (num_boxes, 4) float type
    2 - 1D-Tensor with shape (num_boxes) int type
    3 - 1D-Tensor with 2 values (newWidth, newHeight) (optional) int type

 float arguments (optional)
   0 - exprapolation_value (optional) default 0.f

 int arguments: (optional)
   0 - mode (default 0 - bilinear interpolation)

 output array:
   the 4D-Tensor with resized to crop_size images given - float type</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.cumprod_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.cumprod_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.cumsum_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.cumsum_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.cyclic_rshift_bits.html" title="class in org.nd4j.nativeblas">Nd4jCpu.cyclic_rshift_bits</a></span></code>
<div class="block">This operation shift individual bits of each element in array, shifting to the right

 PLEASE NOTE: This operation is applicable only to integer data types

 \tparam T</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.cyclic_shift_bits.html" title="class in org.nd4j.nativeblas">Nd4jCpu.cyclic_shift_bits</a></span></code>
<div class="block">This operation shift individual bits of each element in array, shifting to the left

 PLEASE NOTE: This operation is applicable only to integer data types

 \tparam T</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.deconv2d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.deconv2d</a></span></code>
<div class="block">2D deconvolution implementation

 IntArgs:
 0: kernel height
 1: kernel width
 2: stride height
 3: stride width
 4: padding height
 5: padding width
 6: dilation height
 7: dilation width
 8: same mode: 0 false, 1 true</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.deconv2d_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.deconv2d_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.deconv2d_tf.html" title="class in org.nd4j.nativeblas">Nd4jCpu.deconv2d_tf</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.deconv3d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.deconv3d</a></span></code>
<div class="block">3D deconvolution implementation

 IntArgs:
 0:  filter(kernel) depth
 1:  filter(kernel) height
 2:  filter(kernel) width
 3:  strides depth
 4:  strides height
 5:  strides width
 6:  paddings depth
 7:  paddings height
 8:  paddings width
 9:  dilations depth
 10: dilations height
 11: dilations width
 12: same mode: 0 false, 1 true
 13: data format (optional): 0-NDHWC, 1-NCDHW, default is 1</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.deconv3d_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.deconv3d_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.depth_to_space.html" title="class in org.nd4j.nativeblas">Nd4jCpu.depth_to_space</a></span></code>
<div class="block">This operation rearranges data from depth into blocks of spatial data.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.depthwise_conv2d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.depthwise_conv2d</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.depthwise_conv2d_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.depthwise_conv2d_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.diag.html" title="class in org.nd4j.nativeblas">Nd4jCpu.diag</a></span></code>
<div class="block">Returns a diagonal tensor with a given diagonal values.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.diag_part.html" title="class in org.nd4j.nativeblas">Nd4jCpu.diag_part</a></span></code>
<div class="block">Returns a diagonal tensor with a given diagonal values.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.dilation2d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.dilation2d</a></span></code>
<div class="block">Dilation2D op

 Int args:
 0: isSameMode</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.divide.html" title="class in org.nd4j.nativeblas">Nd4jCpu.divide</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.divide_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.divide_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.divide_no_nan.html" title="class in org.nd4j.nativeblas">Nd4jCpu.divide_no_nan</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.dot_product_attention.html" title="class in org.nd4j.nativeblas">Nd4jCpu.dot_product_attention</a></span></code>
<div class="block">This operation performs dot product attention on the given timeseries input with the given queries
 out = sum(similarity(k_i, q) * v_i)

 similarity(k, q) = softmax(k * q) where x * q is the dot product of x and q

 Optionally with normalization step:
 similarity(k, q) = softmax(k * q / sqrt(size(q))

 See also "Attention is all you need" (https://arxiv.org/abs/1706.03762, p. 4, eq. 1)

 Note: This supports multiple queries at once, if only one query is available the queries vector still has to
 be 3D but can have queryCount = 1

 Note: keys and values usually is the same array.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.dot_product_attention_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.dot_product_attention_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.dynamic_bidirectional_rnn.html" title="class in org.nd4j.nativeblas">Nd4jCpu.dynamic_bidirectional_rnn</a></span></code>
<div class="block">Implementation of operation "static RNN time sequences" with peep hole connections:

 Input arrays:
    0: input with shape [time x batchSize x inSize] or [batchSize x time x inSize], time - number of time steps, batchSize - batch size, inSize - number of features
    1: input-to-hidden  weights for forward RNN, [inSize   x numUnitsFW]
    2: hidden-to-hidden weights for forward RNN, [numUnitsFW x numUnitsFW]
    3: biases for forward RNN, [2*numUnitsFW]
    4: input-to-hidden  weights for backward RNN, [inSize   x numUnitsBW]
    5: hidden-to-hidden weights for backward RNN, [numUnitsBW x numUnitsBW]
    6: biases for backward RNN, [2*numUnitsBW]
    7: (optional) initial cell output for forward RNN [batchSize x numUnitsFW], that is at time step = 0
    8: (optional) initial cell output for backward RNN [batchSize x numUnitsBW], that is at time step = 0
    9: (optional) vector with shape [batchSize] containing integer values within [0,time), each element of this vector set max time step per each input in batch, this provides no calculations for time >= maxTimeStep

  Input integer arguments:
    0: (optional) timeMajor - if non zero then input shape is [time, batchSize, ...], else [batchSize, time, ...]</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.dynamic_partition.html" title="class in org.nd4j.nativeblas">Nd4jCpu.dynamic_partition</a></span></code>
<div class="block">dynamic_partition - partition a input tensor onto num_partitions
 accordingly to index array given.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.dynamic_partition_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.dynamic_partition_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.dynamic_rnn.html" title="class in org.nd4j.nativeblas">Nd4jCpu.dynamic_rnn</a></span></code>
<div class="block">Implementation of operation "static RNN time sequences" with peep hole connections:

 Input arrays:
    0: input with shape [time x batchSize x inSize] or [batchSize x time x numUnits], time - number of time steps, batchSize - batch size, inSize - number of features
    1: input-to-hidden  weights, [inSize   x numUnits]
    2: hidden-to-hidden weights, [numUnits x numUnits]
    3: biases, [2*numUnits]
    4: (optional) initial cell output [batchSize x numUnits], that is at time step = 0
    5: (optional) vector with shape [batchSize] containing integer values within [0,time), each element of this vector set max time step per each input in batch, this provides no calculations for time >= maxTimeStep

  Input integer arguments:
    0: (optional) timeMajor - if non zero then input shape is [time, batchSize, ...], else [batchSize, time, ...]</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.dynamic_stitch.html" title="class in org.nd4j.nativeblas">Nd4jCpu.dynamic_stitch</a></span></code>
<div class="block">dynamic_stitch - merge partitions from the second param a input tensor
 into a single tensor accordingly to index array given.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.embedding_lookup.html" title="class in org.nd4j.nativeblas">Nd4jCpu.embedding_lookup</a></span></code>
<div class="block">embedding_lookup - search for submatrices in given matrix and retunts them
 accordingly to index array given.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.equals.html" title="class in org.nd4j.nativeblas">Nd4jCpu.equals</a></span></code>
<div class="block">This op takes 2 equally shaped arrays as input, and provides binary matrix as output.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.evaluate_reduction_shape.html" title="class in org.nd4j.nativeblas">Nd4jCpu.evaluate_reduction_shape</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.expand_dims.html" title="class in org.nd4j.nativeblas">Nd4jCpu.expand_dims</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.expose.html" title="class in org.nd4j.nativeblas">Nd4jCpu.expose</a></span></code>
<div class="block">This operations exposes given arguments as it's own outputs, but does it only once.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.extract_image_patches.html" title="class in org.nd4j.nativeblas">Nd4jCpu.extract_image_patches</a></span></code>
<div class="block">extract_image_patches op - Extract patches from images and put them in the "depth" output dimension.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.eye.html" title="class in org.nd4j.nativeblas">Nd4jCpu.eye</a></span></code>
<div class="block">creates identity 2D matrix or batch of identical 2D identity matrices

 Input array:
 provide some array - in any case operation simply neglects it

 Input float argument (if passed):
 TArgs[0] - type of elements of output array, default value is 5 (float)

 Input integer arguments:
 IArgs[0]       - order of output identity matrix, 99 -> 'c'-order, 102 -> 'f'-order
 IArgs[1]       - the number of rows in output inner-most 2D identity matrix
 IArgs[2]       - optional, the number of columns in output inner-most 2D identity matrix, if this argument is not provided then it is taken to be equal to number of rows
 IArgs[3,4,...] - optional, shape of batch, output matrix will have leading batch dimensions of this shape</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.fill.html" title="class in org.nd4j.nativeblas">Nd4jCpu.fill</a></span></code>
<div class="block">This operation takes shape as first argument, and returns new NDArray filled with specific scalar value.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.firas_sparse.html" title="class in org.nd4j.nativeblas">Nd4jCpu.firas_sparse</a></span></code>
<div class="block">Copyright (c) 2015-2018 Skymind, Inc.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.flatten.html" title="class in org.nd4j.nativeblas">Nd4jCpu.flatten</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.floordiv.html" title="class in org.nd4j.nativeblas">Nd4jCpu.floordiv</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.floordiv_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.floordiv_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.floormod.html" title="class in org.nd4j.nativeblas">Nd4jCpu.floormod</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.floormod_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.floormod_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.fused_batch_norm.html" title="class in org.nd4j.nativeblas">Nd4jCpu.fused_batch_norm</a></span></code>
<div class="block">This operation performs batch normalization of layer, it is based on following article https://arxiv.org/abs/1502.03167.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.gather.html" title="class in org.nd4j.nativeblas">Nd4jCpu.gather</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.gather_nd.html" title="class in org.nd4j.nativeblas">Nd4jCpu.gather_nd</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.get_seed.html" title="class in org.nd4j.nativeblas">Nd4jCpu.get_seed</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.greater.html" title="class in org.nd4j.nativeblas">Nd4jCpu.greater</a></span></code>
<div class="block">This op takes 2 equally shaped arrays as input, and provides binary matrix as output.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.greater_equal.html" title="class in org.nd4j.nativeblas">Nd4jCpu.greater_equal</a></span></code>
<div class="block">This op takes 2 equally shaped arrays as input, and provides binary matrix as output.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.gru.html" title="class in org.nd4j.nativeblas">Nd4jCpu.gru</a></span></code>
<div class="block">Implementation of gated Recurrent Unit:

 Input arrays:
    0: input with shape [time x batchSize x inSize], time - number of time steps, batchSize - batch size, inSize - number of features
    1: initial cell output [batchSize x numUnits],  that is at time step = 0
    2: input-to-hidden  weights, [inSize   x 3*numUnits]
    3: hidden-to-hidden weights, [numUnits x 3*numUnits]
    4: biases, [3*numUnits]

 Output arrays:
    0: cell outputs [time x batchSize x numUnits], that is per each time step</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.gruCell.html" title="class in org.nd4j.nativeblas">Nd4jCpu.gruCell</a></span></code>
<div class="block">Implementation of gated Recurrent Unit cell:
    Kyunghyun Cho, Bart van Merrienboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio
    "Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation"

 Input arrays:
    0: input with shape [batchSize x inSize], batchSize - batch size, inSize - number of features
    1: previous cell output [batchSize x numUnits],  that is at previous time step t-1
    2: RU weights - [(inSize+numUnits), 2*numUnits] - reset and update gates (input/recurrent weights)
    3: C weights - [(inSize+numUnits), numUnits] - cell gate (input/recurrent weights)
    4: reset and update biases, [2*numUnits] - reset and update gates
    5: cell biases, [numUnits]

 Output arrays:
    0: Reset gate output [bS, numUnits]
    1: Update gate output [bS, numUnits]
    2: Cell gate output [bS, numUnits]
    3: Current cell output [bS, numUnits]</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.gruCell_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.gruCell_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.hinge_loss.html" title="class in org.nd4j.nativeblas">Nd4jCpu.hinge_loss</a></span></code>
<div class="block">Implementation of hinge loss function max(0, 1 - labels*logits)
 
 Input arrays: 
    0: logits - logits, type float
    1: weights - is used for weighting (multiplying) of loss values, type float.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.hinge_loss_grad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.hinge_loss_grad</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.histogram.html" title="class in org.nd4j.nativeblas">Nd4jCpu.histogram</a></span></code>
<div class="block">This operation calculates number of entries per bin</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.histogram_fixed_width.html" title="class in org.nd4j.nativeblas">Nd4jCpu.histogram_fixed_width</a></span></code>
<div class="block">returns histogram (as 1D array) with fixed bins width

 Input arrays:
 - input array with elements to be binned into output histogram
 - range array with first element being bottom limit and second element being top limit of histogram,
             please note that input_value <= range[0] will be mapped to histogram[0], input_value >= range[1] will be mapped to histogram[-1]

 Input integer arguments:
    nbins (optional) - number of histogram bins, default value is 100</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.huber_loss.html" title="class in org.nd4j.nativeblas">Nd4jCpu.huber_loss</a></span></code>
<div class="block">Implementation of Huber loss function:
    0.5 * (labels-predictions)^2                                if |labels-predictions| <= delta
    0.5 * delta^2 + delta * (|labels-predictions| - delta)      if |labels-predictions| >  delta
 
 Input arrays: 
    0: predictions - the predicted values, type float
    1: weights - is used for weighting (multiplying) of loss values, type float.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.huber_loss_grad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.huber_loss_grad</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.identity_n.html" title="class in org.nd4j.nativeblas">Nd4jCpu.identity_n</a></span></code>
<div class="block">This is Indentity operation.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.igamma.html" title="class in org.nd4j.nativeblas">Nd4jCpu.igamma</a></span></code>
<div class="block">Broadcastable igamma implementation

 igamma(a, x) = gamma(а, x) / Gamma(a) - Gamma distribution function P(a,x)
 Gamma(a) = int from 0 to infinity { t ^ {a - 1} e^{-t}dt }
 gamma(a, x) = int from 0 to x { t ^ {a - 1} e^{-t}dt }
 \tparam T</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.igammac.html" title="class in org.nd4j.nativeblas">Nd4jCpu.igammac</a></span></code>
<div class="block">Broadcastable igammac implementation
 igammac(a, x) = Gamma(a,x)/Gamma(а) - Gamma distribution function Q(a,x)
 Gamma(a) = int from 0 to infinity { t ^ {a - 1} e^{-t}dt }
 Gamma(a, x) = int from x to infinity { t ^ {a - 1} e^{-t}dt }
 \tparam T</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.im2col.html" title="class in org.nd4j.nativeblas">Nd4jCpu.im2col</a></span></code>
<div class="block">This op implements im2col algorithm, widely used in convolution neural networks
 Input: 4D input expected

 Int args:
 0: kernel height
 1: kernel width
 2: stride height
 3: stride width
 4: padding height
 5: padding width
 6: dilation height
 7: dilation width
 8: isSameMode</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.im2col_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.im2col_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.image_resize.html" title="class in org.nd4j.nativeblas">Nd4jCpu.image_resize</a></span></code>
<div class="block">This op make interpolated resize for given tensor with given algorithm.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.in_top_k.html" title="class in org.nd4j.nativeblas">Nd4jCpu.in_top_k</a></span></code>
<div class="block">in_top_k operation returns a vector of k boolean values for
  given NDArray as 2D matrix of predicted in the NDArray k top values
  The first parameter is a NDArray of predicted values (2d array).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.l2_loss.html" title="class in org.nd4j.nativeblas">Nd4jCpu.l2_loss</a></span></code>
<div class="block">l2_loss op.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.layer_norm_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.layer_norm_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.less.html" title="class in org.nd4j.nativeblas">Nd4jCpu.less</a></span></code>
<div class="block">This op takes 2 equally shaped arrays as input, and provides binary matrix as output.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.less_equal.html" title="class in org.nd4j.nativeblas">Nd4jCpu.less_equal</a></span></code>
<div class="block">This op takes 2 equally shaped arrays as input, and provides binary matrix as output.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.lin_space.html" title="class in org.nd4j.nativeblas">Nd4jCpu.lin_space</a></span></code>
<div class="block">lin_space - op porting from TF (https://www.tensorflow.org/api_docs/python/tf/lin_space)

 input params:
    0 - startVal - NDArray scalar (float point)
    1 - finishVal - NDArray scalar (float point)
    2 - numOfElements - NDArray scalar (integer)

 output:
    0 - 1D NDArray with the same type as input and length as given with numOfElements param.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.listdiff.html" title="class in org.nd4j.nativeblas">Nd4jCpu.listdiff</a></span></code>
<div class="block">This operation takes 2 arrays: original values, and values to be excluded.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.log_loss.html" title="class in org.nd4j.nativeblas">Nd4jCpu.log_loss</a></span></code>
<div class="block">Implementation of logarithmic loss function ( y_i * log(p_i) + (1 - y_i) * log(1 - p_i) )
 
 Input arrays: 
    0: predictions - the predicted values, type float
    1: weights - is used for weighting (multiplying) of loss values, type float.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.log_loss_grad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.log_loss_grad</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.log_matrix_determinant.html" title="class in org.nd4j.nativeblas">Nd4jCpu.log_matrix_determinant</a></span></code>
<div class="block">log_matrix_determinant op.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.log_poisson_loss.html" title="class in org.nd4j.nativeblas">Nd4jCpu.log_poisson_loss</a></span></code>
<div class="block">This op calculates logarithmic loss of poisson distributed input.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.log_poisson_loss_grad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.log_poisson_loss_grad</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.logdet.html" title="class in org.nd4j.nativeblas">Nd4jCpu.logdet</a></span></code>
<div class="block">logdet op.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.lstm.html" title="class in org.nd4j.nativeblas">Nd4jCpu.lstm</a></span></code>
<div class="block">Implementation of operation "LSTM time sequences" with peep hole connections:

 Input arrays:
    0: input with shape [time x batchSize x inSize], time - number of time steps, batchSize - batch size, inSize - number of features
    1: initial cell output [batchSize x numProj],  that is at time step = 0, in case of projection=false -> numProj=numUnits!!!</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.lstmBlock.html" title="class in org.nd4j.nativeblas">Nd4jCpu.lstmBlock</a></span></code>
<div class="block">Implementation of operation for LSTM layer with optional peep hole connections.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.lstmBlockCell.html" title="class in org.nd4j.nativeblas">Nd4jCpu.lstmBlockCell</a></span></code>
<div class="block">Implementation of operation for LSTM cell with optional peep hole connections:
    S.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.lstmCell.html" title="class in org.nd4j.nativeblas">Nd4jCpu.lstmCell</a></span></code>
<div class="block">Implementation of operation for LSTM cell with peep hole connections:
    S.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.lstmLayer.html" title="class in org.nd4j.nativeblas">Nd4jCpu.lstmLayer</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.matmul.html" title="class in org.nd4j.nativeblas">Nd4jCpu.matmul</a></span></code>
<div class="block">This op is general matmum implementation.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.matmul_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.matmul_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.matrix_determinant.html" title="class in org.nd4j.nativeblas">Nd4jCpu.matrix_determinant</a></span></code>
<div class="block">matrix_determinant op.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.matrix_diag.html" title="class in org.nd4j.nativeblas">Nd4jCpu.matrix_diag</a></span></code>
<div class="block">Inserts elements provided by diagonal array into the main diagonal of innermost matrices of output array,
 rest output elements are set to zeros

 Input array:
    diagonal: array containing elements to be inserted into output array,
              following rank condition is present: diagonal_rank = ouput_rank - 1

 Output array:
   0: is considered as batch of matrices, if for example diagonal array has shape [A,B,C] then output array has shape [A,B,C,C]</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.matrix_diag_part.html" title="class in org.nd4j.nativeblas">Nd4jCpu.matrix_diag_part</a></span></code>
<div class="block">Returns a diagonal vector for any submatricies with in a given tensor.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.max_pool_with_argmax.html" title="class in org.nd4j.nativeblas">Nd4jCpu.max_pool_with_argmax</a></span></code>
<div class="block">This op same as maxpool2d with a variant to return a matrix of indexes for max values

 Input - 4D tensor
 Output:
     0 - 4D tensor as input
     1 - 4D tensor with max value indexes

 Int params:
   9 int with 2x4 vectors and 1 bool value</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.maximum.html" title="class in org.nd4j.nativeblas">Nd4jCpu.maximum</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.maximum_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.maximum_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.maxpool2d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.maxpool2d</a></span></code>
<div class="block">This op implements max pooling for convolution networks.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.maxpool2d_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.maxpool2d_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.maxpool3dnew.html" title="class in org.nd4j.nativeblas">Nd4jCpu.maxpool3dnew</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.maxpool3dnew_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.maxpool3dnew_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.mean_pairwssqerr_loss.html" title="class in org.nd4j.nativeblas">Nd4jCpu.mean_pairwssqerr_loss</a></span></code>
<div class="block">Implementation of pairwise-errors-squared loss function 
 
 Input arrays: 
    0: predictions - the predicted values, type float.
    1: weights - is used for weighting (multiplying) of loss values, type float.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.mean_pairwssqerr_loss_grad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.mean_pairwssqerr_loss_grad</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.mean_sqerr_loss.html" title="class in org.nd4j.nativeblas">Nd4jCpu.mean_sqerr_loss</a></span></code>
<div class="block">Implementation of Sum-of-Squares loss function 1/N * sum_{i}^{N}(predictions_i - labels_i)^2
 
 Input arrays: 
    0: predictions - the predicted values, type float
    1: weights - is used for weighting (multiplying) of loss values, type float.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.mean_sqerr_loss_grad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.mean_sqerr_loss_grad</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.mergemaxindex.html" title="class in org.nd4j.nativeblas">Nd4jCpu.mergemaxindex</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.meshgrid.html" title="class in org.nd4j.nativeblas">Nd4jCpu.meshgrid</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.minimum.html" title="class in org.nd4j.nativeblas">Nd4jCpu.minimum</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.minimum_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.minimum_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.mirror_pad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.mirror_pad</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.mod.html" title="class in org.nd4j.nativeblas">Nd4jCpu.mod</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.mod_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.mod_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.moments.html" title="class in org.nd4j.nativeblas">Nd4jCpu.moments</a></span></code>
<div class="block">moments operation calculate a mean and variation for given NDArray
 with reduce a result according to axis array given.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.multi_head_dot_product_attention.html" title="class in org.nd4j.nativeblas">Nd4jCpu.multi_head_dot_product_attention</a></span></code>
<div class="block">This performs multi-headed dot product attention on the given timeseries input
 out = concat(head_1, head_2, ..., head_n) * Wo
 head_i = dot_product_attention(Wq_i*q, Wk_i*k, Wv_i*v)

 Optionally with normalization when calculating the attention for each head.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.multi_head_dot_product_attention_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.multi_head_dot_product_attention_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.multiply.html" title="class in org.nd4j.nativeblas">Nd4jCpu.multiply</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.multiply_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.multiply_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.non_max_suppression.html" title="class in org.nd4j.nativeblas">Nd4jCpu.non_max_suppression</a></span></code>
<div class="block">image.non_max_suppression ops.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.non_max_suppression_overlaps.html" title="class in org.nd4j.nativeblas">Nd4jCpu.non_max_suppression_overlaps</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.non_max_suppression_v3.html" title="class in org.nd4j.nativeblas">Nd4jCpu.non_max_suppression_v3</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.normalize_moments.html" title="class in org.nd4j.nativeblas">Nd4jCpu.normalize_moments</a></span></code>
<div class="block">normalize_moments operation normalize already calculated mean and variation
 accordingly to shift and count.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.not_equals.html" title="class in org.nd4j.nativeblas">Nd4jCpu.not_equals</a></span></code>
<div class="block">This op takes 2 equally shaped arrays as input, and provides binary matrix as output.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.nth_element.html" title="class in org.nd4j.nativeblas">Nd4jCpu.nth_element</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.onehot.html" title="class in org.nd4j.nativeblas">Nd4jCpu.onehot</a></span></code>
<div class="block">This operation return one-hot encoded n-dimensional array
 Expected arguments:
 input: N-dimensional array

 T args:
 0: 'on' value
 1: 'off' value

 Int args:
 0: depth
 1: axis</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.order.html" title="class in org.nd4j.nativeblas">Nd4jCpu.order</a></span></code>
<div class="block">This op changes order of given array to specified order.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.pad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.pad</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.parallel_stack.html" title="class in org.nd4j.nativeblas">Nd4jCpu.parallel_stack</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.percentile.html" title="class in org.nd4j.nativeblas">Nd4jCpu.percentile</a></span></code>
<div class="block">This operation performs calculation of percentile of input array along given axises

 Input - tensor with rank N > 0
 Output - tensor with rank (N - length(axis)) or scalar if number of Integer arguments is zero
 Float arguments:
   0: percentile (scalar) in range [0,100] (inclusively)
   1: interpolation (optional), possible values are 0-"lower", 1-"higher", 2-"nearest"(default)
   2: keepDims (optional), if it is non zero, then unities are kept in reduced resulting shape of output array, default is 0
 Integer arguments - axis - the sequence of axises to calculate percentile along, if sequence is empty then calculate percentile for whole input tensor and return result as scalar</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.permute.html" title="class in org.nd4j.nativeblas">Nd4jCpu.permute</a></span></code>
<div class="block">Copyright (c) 2015-2018 Skymind, Inc.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.pnormpool2d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.pnormpool2d</a></span></code>
<div class="block">This op implements pnorm pooling for convolution networks.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.pnormpool2d_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.pnormpool2d_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.pointwise_conv2d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.pointwise_conv2d</a></span></code>
<div class="block">point-wise 2D convolution
 Expected input:
 x: 4D array
 weight: 4D Array [1,  1,  iC, oC] (NHWC) or [oC, iC,  1,  1] (NCHW)
 bias: optional vector, length of oC

 IntArgs:
 0: data format: 1 NHWC, 0 NCHW (optional, by default = NHWC)</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.Pow.html" title="class in org.nd4j.nativeblas">Nd4jCpu.Pow</a></span></code>
<div class="block">Broadcastable pow implementation
 \tparam T</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.random_bernoulli.html" title="class in org.nd4j.nativeblas">Nd4jCpu.random_bernoulli</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.random_crop.html" title="class in org.nd4j.nativeblas">Nd4jCpu.random_crop</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.random_exponential.html" title="class in org.nd4j.nativeblas">Nd4jCpu.random_exponential</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.random_gamma.html" title="class in org.nd4j.nativeblas">Nd4jCpu.random_gamma</a></span></code>
<div class="block">random_gamma op.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.random_normal.html" title="class in org.nd4j.nativeblas">Nd4jCpu.random_normal</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.random_poisson.html" title="class in org.nd4j.nativeblas">Nd4jCpu.random_poisson</a></span></code>
<div class="block">random_poisson op.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.randomuniform.html" title="class in org.nd4j.nativeblas">Nd4jCpu.randomuniform</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.range.html" title="class in org.nd4j.nativeblas">Nd4jCpu.range</a></span></code>
<div class="block">This operation generate sequences.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.rank.html" title="class in org.nd4j.nativeblas">Nd4jCpu.rank</a></span></code>
<div class="block">This operation returns rank of input array as scalar value.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.realdiv.html" title="class in org.nd4j.nativeblas">Nd4jCpu.realdiv</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.realdiv_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.realdiv_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_dot_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_dot_bp</a></span></code>
<div class="block">This op calculates backprop dot for two tensors along given dimensions

 input array:
    x: tensor to calculate dot for
    y: tensor to calculate dot for
    z: tensor with gradient output of the FF dot for x and y

 int arguments:
   list of integers - dimensions to calculate dot along,
   default corresponds to empty list in which case calculation
   is performed for all dimensions and scalar is returned.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_logsumexp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_logsumexp</a></span></code>
<div class="block">reduce_logsumexp - tf.reduce_logsumexe operation

 input params:
    0 - NDArray (input)
    1 - 1D NDArray (axis) (optional) - integer array

 T_ARG param (optional):
 0 - keep_dims !</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_max.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_max</a></span></code>
<div class="block">This op calculates max of elements along given dimensions

 input array:
    x: tensor to calculate maxes for

 float arguments:
   keepDims: if non zero, then keep reduced dimensions with length = 1, default value is zero

 int arguments:
    list of integers - dimensions to calculate max along, default corresponds to empty list in which case calculation is performed for all dimensions and scalar is returned

 output array:
    reduced tensor with calculated maxes</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_max_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_max_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_mean.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_mean</a></span></code>
<div class="block">This op calculates mean of elements along given dimensions

 input array:
    x: tensor to calculate mean for

 float arguments:
   keepDims: if non zero, then keep reduced dimensions with length = 1, default value is zero

 int arguments:
    list of integers - dimensions to calculate mean along, default corresponds to empty list in which case calculation is performed for all dimensions and scalar is returned

 output array:
    reduced tensor with calculated means</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_mean_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_mean_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_min.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_min</a></span></code>
<div class="block">This op calculates min of elements along given dimensions

 input array:
    x: tensor to calculate mins for

 float arguments:
   keepDims: if non zero, then keep reduced dimensions with length = 1, default value is zero

 int arguments:
    list of integers - dimensions to calculate min along, default corresponds to empty list in which case calculation is performed for all dimensions and scalar is returned

 output array:
    reduced tensor with calculated mins</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_min_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_min_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_norm_max.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_norm_max</a></span></code>
<div class="block">This op calculates norm max of elements along given dimensions

 input array:
    x: tensor to calculate norm max for

 float arguments:
   keepDims: if non zero, then keep reduced dimensions with length = 1, default value is zero

 int arguments:
    list of integers - dimensions to calculate norm max along, default corresponds to empty list in which case calculation is performed for all dimensions and scalar is returned

 output array:
    reduced tensor with calculated norm</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_norm_max_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_norm_max_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_norm1.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_norm1</a></span></code>
<div class="block">This op calculates norm1 of elements along given dimensions

 input array:
    x: tensor to calculate norm1 for

 float arguments:
   keepDims: if non zero, then keep reduced dimensions with length = 1, default value is zero

 int arguments:
    list of integers - dimensions to calculate norm1 along, default corresponds to empty list in which case calculation is performed for all dimensions and scalar is returned

 output array:
    reduced tensor with calculated norm1</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_norm1_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_norm1_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_norm2.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_norm2</a></span></code>
<div class="block">This op calculates norm2 of elements along given dimensions

 input array:
    x: tensor to calculate norm2 for

 float arguments:
   keepDims: if non zero, then keep reduced dimensions with length = 1, default value is zero

 int arguments:
    list of integers - dimensions to calculate norm2 along, default corresponds to empty list in which case calculation is performed for all dimensions and scalar is returned

 output array:
    reduced tensor with calculated norm2</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_norm2_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_norm2_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_prod.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_prod</a></span></code>
<div class="block">reduction_prod - tf.reduction_prod operation

 input params:
    0 - NDArray

 T_ARG param (optional):
 0 - keep_dims !</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_prod_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_prod_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_sqnorm.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_sqnorm</a></span></code>
<div class="block">This op calculates squared norm of elements along given dimensions

 input array:
    x: tensor to calculate squared norm for

 float arguments:
   keepDims: if non zero, then keep reduced dimensions with length = 1, default value is zero

 int arguments:
    list of integers - dimensions to calculate squared norm along, default corresponds to empty list in which case calculation is performed for all dimensions and scalar is returned

 output array:
    reduced tensor with calculated norm</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_sqnorm_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_sqnorm_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_stdev.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_stdev</a></span></code>
<div class="block">This op calculates sample standard deviation of elements along given dimensions

 input array:
    x: tensor to calculate mean for

 float arguments:
   keepDims: if non zero, then keep reduced dimensions with length = 1, default value is zero
   biasCorrected - if non zero, then bias correction will be applied, default value is zero

 int arguments:
    list of integers - dimensions to calculate mean along, default corresponds to empty list in which case calculation is performed for all dimensions and scalar is returned

 output array:
    reduced tensor with calculated means</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_stdev_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_stdev_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_sum.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_sum</a></span></code>
<div class="block">reduction_sum - tf.reduction_sum operation

 input params:
    0 - NDArray

 T_ARG param (optional):
 0 - keep_dims !</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_sum_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_sum_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_variance.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_variance</a></span></code>
<div class="block">This op calculates sample variance of elements along given dimensions

 input array:
    x: tensor to calculate mean for

 float arguments:
   keepDims: if non zero, then keep reduced dimensions with length = 1, default value is zero
   biasCorrected -  if non zero, then bias correction will be applied, default value is zero

 int arguments:
    list of integers - dimensions to calculate mean along, default corresponds to empty list in which case calculation is performed for all dimensions and scalar is returned

 output array:
    reduced tensor with calculated means</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reduce_variance_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reduce_variance_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.relu_layer.html" title="class in org.nd4j.nativeblas">Nd4jCpu.relu_layer</a></span></code>
<div class="block">relu_layer = relu(x*w + b)</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.repeat.html" title="class in org.nd4j.nativeblas">Nd4jCpu.repeat</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reshape.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reshape</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reshapeas.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reshapeas</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.resize_bicubic.html" title="class in org.nd4j.nativeblas">Nd4jCpu.resize_bicubic</a></span></code>
<div class="block">This op make bicubic interpolated resize for given tensor

 input array:
    0 - 4D-Tensor with shape (batch, sizeX, sizeY, channels)
    1 - 1D-Tensor with 2 values (newWidth, newHeight)

 output array:
   the 4D-Tensor with resized image (shape is {batch, newWidth, newHeight, channels})</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.resize_bilinear.html" title="class in org.nd4j.nativeblas">Nd4jCpu.resize_bilinear</a></span></code>
<div class="block">This op make bilinear interpolated resize for given tensor

 input array:
    0 - 4D-Tensor with shape (batch, sizeX, sizeY, channels)
    1 - 1D-Tensor with 2 values (newWidth, newHeight) (optional)

 int arguments: (optional)
   0 - new width
   1 - new height

 output array:
   the 4D-Tensor with calculated backproped dots

 CAUTION: either size tensor or a pair of int params should be provided.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.resize_nearest_neighbor.html" title="class in org.nd4j.nativeblas">Nd4jCpu.resize_nearest_neighbor</a></span></code>
<div class="block">This op make nearest neighbor interpolated resize for given tensor

 input array:
    0 - 4D-Tensor with shape (batch, sizeX, sizeY, channels)
    1 - 1D-Tensor with 2 values (newWidth, newHeight) (optional)

 int arguments: (optional)
   0 - new width
   1 - new height

 output array:
   the 4D-Tensor with resized image (shape is {batch, newWidth, newHeight, channels})

 CAUTION: either size tensor or a pair of int params should be provided.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reverse_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reverse_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reverse_sequence.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reverse_sequence</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reversedivide.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reversedivide</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reversedivide_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reversedivide_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reversemod.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reversemod</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reversemod_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reversemod_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reversesubtract.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reversesubtract</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.reversesubtract_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.reversesubtract_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.rshift_bits.html" title="class in org.nd4j.nativeblas">Nd4jCpu.rshift_bits</a></span></code>
<div class="block">This operation shift individual bits of each element in array to the right: >>

 PLEASE NOTE: This operation is applicable only to integer data types

 \tparam T</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.scatter_nd.html" title="class in org.nd4j.nativeblas">Nd4jCpu.scatter_nd</a></span></code>
<div class="block">This operation scatter "updates" elements into new output array according to given "indices"
 Expected arguments:
 indices: array containing elements/slices indexes of output array to put "updates" elements into, the rest output elements will be zeros
 updates: array containing elements to be inserted into output array
 shape: contains shape of output array</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sconv2d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sconv2d</a></span></code>
<div class="block">Depthwise convolution2d op:
 Expected inputs:
 x: 4D array, NCHW format
 weightsDepth: 4D array,
 weightsPointwise: optional, 4D array
 bias: optional, vector</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sconv2d_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sconv2d_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.segment_max.html" title="class in org.nd4j.nativeblas">Nd4jCpu.segment_max</a></span></code>
<div class="block">segment_max op. - make a tensor filled by max values according to index tensor given.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.segment_max_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.segment_max_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.segment_mean.html" title="class in org.nd4j.nativeblas">Nd4jCpu.segment_mean</a></span></code>
<div class="block">segment_mean op. - make a tensor filled by average of values according to index tensor given.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.segment_mean_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.segment_mean_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.segment_min.html" title="class in org.nd4j.nativeblas">Nd4jCpu.segment_min</a></span></code>
<div class="block">segment_min op. - make a tensor filled by min values according to index tensor given.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.segment_min_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.segment_min_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.segment_prod.html" title="class in org.nd4j.nativeblas">Nd4jCpu.segment_prod</a></span></code>
<div class="block">segment_prod op. - make a tensor filled by product of values according to index tensor given.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.segment_prod_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.segment_prod_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.segment_sum.html" title="class in org.nd4j.nativeblas">Nd4jCpu.segment_sum</a></span></code>
<div class="block">segment_sum op. - make a tensor filled by sum of values according to index tensor given.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.segment_sum_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.segment_sum_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.select.html" title="class in org.nd4j.nativeblas">Nd4jCpu.select</a></span></code>
<div class="block">This op takes 2 n-dimensional arrays as input, and return
 array of the same shape, with elements, either from x or y, depending on the condition.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sequence_mask.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sequence_mask</a></span></code>
<div class="block">sequence_mask op. - make mask for given tensor filled by (j > x[i_1, i_2,...</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.set_seed.html" title="class in org.nd4j.nativeblas">Nd4jCpu.set_seed</a></span></code>
<div class="block">Copyright (c) 2015-2018 Skymind, Inc.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.shape_of.html" title="class in org.nd4j.nativeblas">Nd4jCpu.shape_of</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.shapes_of.html" title="class in org.nd4j.nativeblas">Nd4jCpu.shapes_of</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.shift_bits.html" title="class in org.nd4j.nativeblas">Nd4jCpu.shift_bits</a></span></code>
<div class="block">This operation shift individual bits of each element in array to the left: <<

 PLEASE NOTE: This operation is applicable only to integer data types

 \tparam T</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sigm_cross_entropy_loss.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sigm_cross_entropy_loss</a></span></code>
<div class="block">Implementation of sigmoid cross-entropy loss function max(logits, 0.) - logits * labels + log(1. + exp(-abs(logits))); 
 
 Input arrays: 
    0: logits - logits, type float
    1: weights - is used for weighting (multiplying) of loss values, type float.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sigm_cross_entropy_loss_grad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sigm_cross_entropy_loss_grad</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.size.html" title="class in org.nd4j.nativeblas">Nd4jCpu.size</a></span></code>
<div class="block">This operation returns length of input array
 Expected arguments:
 input: N-dimensional array

 TODO: make this operation reduction, to allow TAD -> size</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.size_at.html" title="class in org.nd4j.nativeblas">Nd4jCpu.size_at</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.slice.html" title="class in org.nd4j.nativeblas">Nd4jCpu.slice</a></span></code>
<div class="block">This operation extracts a slice from a tensor.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.slice_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.slice_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.softmax_cross_entropy_loss.html" title="class in org.nd4j.nativeblas">Nd4jCpu.softmax_cross_entropy_loss</a></span></code>
<div class="block">Implementation of softmax cross-entropy loss function max(logits, 0.) - logits * labels + log(1. + exp(-abs(logits))); 
 
 Input arrays: 
    0: logits - logits, type float
    1: weights - is used for weighting (multiplying) of loss values, type float.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.softmax_cross_entropy_loss_grad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.softmax_cross_entropy_loss_grad</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.softmax_cross_entropy_loss_with_logits.html" title="class in org.nd4j.nativeblas">Nd4jCpu.softmax_cross_entropy_loss_with_logits</a></span></code>
<div class="block">Implementation of softmax cross-entropy loss function 
 
 Input arrays: 
    0: logits - logits, type float
    1: labels - ground truth vales, expected to be 0. or 1., type float.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.softmax_cross_entropy_loss_with_logits_grad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.softmax_cross_entropy_loss_with_logits_grad</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.space_to_batch.html" title="class in org.nd4j.nativeblas">Nd4jCpu.space_to_batch</a></span></code>
<div class="block">Zero-pads and then rearranges (permutes) blocks of spatial data into batch.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.space_to_batch_nd.html" title="class in org.nd4j.nativeblas">Nd4jCpu.space_to_batch_nd</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.space_to_depth.html" title="class in org.nd4j.nativeblas">Nd4jCpu.space_to_depth</a></span></code>
<div class="block">This operation rearranges blocks of spatial data, into depth.This op output is a copy of the input tensor
 where values from the height and width dimensions are moved to the depth dimension.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sparse_softmax_cross_entropy_loss_with_logits.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sparse_softmax_cross_entropy_loss_with_logits</a></span></code>
<div class="block">Implementation of sparse softmax cross-entropy loss function
 
 Input arrays:        
    0: labels - ground truth vales, expected to be within range [0, num_classes), type float.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sparse_softmax_cross_entropy_loss_with_logits_grad.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sparse_softmax_cross_entropy_loss_with_logits_grad</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.split.html" title="class in org.nd4j.nativeblas">Nd4jCpu.split</a></span></code>
<div class="block">This operation splits given NDArray into chunks of specific size, along given dimension
 0 - input array
 1 - optional axis

 Integer arguments:
 0 - number of splits
 1 - optional axis</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.split_v.html" title="class in org.nd4j.nativeblas">Nd4jCpu.split_v</a></span></code>
<div class="block">This operation splits given NDArray into chunks of specific size, along given dimension
 Input arrays:
 0 - input array
 1 - array of sizes
 2 - optional axis

 Integer arguments:
 0 - optional axis</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.squaredsubtract.html" title="class in org.nd4j.nativeblas">Nd4jCpu.squaredsubtract</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.squaredsubtract_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.squaredsubtract_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.squeeze.html" title="class in org.nd4j.nativeblas">Nd4jCpu.squeeze</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sru.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sru</a></span></code>
<div class="block">Implementation of operation for Simple Recurrent Unit: "Training RNNs as Fast as CNNs" Tao Lei, Yu Zhang, Yoav Artzi

 Input arrays:
    0: input 3d tensor with shape [bS x K x N], N - number of time steps, bS - batch size, K - number of features
    1: 2d tensor of weights [3K x K]
    2: row of biases with twice length [1 x 2K]
    3: 2d tensor of previous cell state [bS x K]
    4: optional, 2d tensor of dropout mask [bS x K]

 Output arrays:
    0: 3d tensor of cell output [bS x K x N]
    1: 3d tensor of cell state [bS x K x N]</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sru_bi.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sru_bi</a></span></code>
<div class="block">Implementation of operation for Simple Recurrent Unit (bidirectional case): "Training RNNs as Fast as CNNs" Tao Lei, Yu Zhang, Yoav Artzi

 Input arrays:
    0: input 3d tensor with shape [N x bS x 2K], N - number of time steps, bS - batch size, K - number of features
    1: 2d tensor of weights [2K x 6K]
    2: row of biases with twice length [1 x 4K]
    3: 2d tensor of previous cell state [bS x 2K]
    4: optional, 2d tensor of dropout mask [bS x 2K]

 Output arrays:
    0: 3d tensor of cell output [N x bS x 2K]
    1: 3d tensor of cell state [N x bS x 2K]</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sru_bi_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sru_bi_bp</a></span></code>
<div class="block">Implementation of operation for back propagation in Simple Recurrent Unit (bidirectional case): "Training RNNs as Fast as CNNs" Tao Lei, Yu Zhang, Yoav Artzi

 Input arrays:
    0: input 3d tensor with shape [N x bS x 2K], N - number of time steps, bS - batch size, K - number of features
    1: 2d tensor of weights [2K x 6K]
    2: row of biases with twice length [1 x 4K]
    3: 2d tensor of previous cell state [bS x 2K]
    4: 3d tensor of cell state [N x bS x 2K]
    5: 2d tensor of cell state gradients [bS x 2K]
    6: 3d tensor of state output gradients [N x bS x 2K]
    7: optional, 2d tensor of dropout mask [bS x 2K]

 Output arrays:
    0: 3d tensor of input gradients [N x bS x 2K]
    1: 3d tensor of weights gradients [N x 2K x 6K]
    2: 2d, row of biases gradients [1 x 4K]
    3: 2d, tensor of state gradients [bS x 2K]</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sru_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sru_bp</a></span></code>
<div class="block">Implementation of operation for back propagation in Simple Recurrent Unit: "Training RNNs as Fast as CNNs" Tao Lei, Yu Zhang, Yoav Artzi

 Input arrays:
    0: input 3d tensor with shape [bS x K x N], N - number of time steps, bS - batch size, K - number of features
    1: 2d tensor of weights [3K x K]
    2: row of biases with twice length [1 x 2K]
    3: 2d tensor of previous cell state [bS x K]
    4: 3d tensor of cell state [bS x K x N]
    5: 2d tensor of cell state gradients [bS x K]
    6: 3d tensor of state output gradients [bS x K x N]
    7: optional, 2d tensor of dropout mask [bS x K]

 Output arrays:
    0: 3d tensor of input gradients [bS x K x N]
    1: 3d tensor of weights gradients [bS x 3K x K]
    2: 2d, row of biases gradients [1 x 2K]
    3: 2d, tensor of state gradients [bS x K]</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sruCell.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sruCell</a></span></code>
<div class="block">Implementation of operations for Simple Recurrent Unit cell: "Training RNNs as Fast as CNNs" Tao Lei, Yu Zhang, Yoav Artzi

 Input arrays:
    0: input with shape [batchSize x inSize], batchSize - batch size, inSize - number of features
    1: previous cell state [batchSize x inSize], that is at previous time step t-1
    2: weights [inSize x 3*inSize]
    3: biases [1 x 2*inSize]

 Output arrays:
    0: current cell output [batchSize x inSize], that is at current time step t
    1: current cell state  [batchSize x inSize], that is at current time step t</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.stack.html" title="class in org.nd4j.nativeblas">Nd4jCpu.stack</a></span></code>
<div class="block">This operation stacks a list of rank tensors into one rank-(R+1) tensor.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.standardize_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.standardize_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.static_bidirectional_rnn.html" title="class in org.nd4j.nativeblas">Nd4jCpu.static_bidirectional_rnn</a></span></code>
<div class="block">Implementation of operation "static RNN time sequences" with peep hole connections:

 Input arrays:
    0: input with shape [time x batchSize x inSize], time - number of time steps, batchSize - batch size, inSize - number of features
    1: input-to-hidden  weights for forward RNN, [inSize   x numUnitsFW]
    2: hidden-to-hidden weights for forward RNN, [numUnitsFW x numUnitsFW]
    3: biases for forward RNN, [2*numUnitsFW]
    4: input-to-hidden  weights for backward RNN, [inSize   x numUnitsBW]
    5: hidden-to-hidden weights for backward RNN, [numUnitsBW x numUnitsBW]
    6: biases for backward RNN, [2*numUnitsBW]
    7: (optional) initial cell output for forward RNN [batchSize x numUnitsFW], that is at time step = 0
    8: (optional) initial cell output for backward RNN [batchSize x numUnitsBW], that is at time step = 0
    9: (optional) vector with shape [batchSize] containing integer values within [0,time), each element of this vector set max time step per each input in batch, this provides no calculations for time >= maxTimeStep

 Output arrays:
    0: cell outputs [time x batchSize x (numUnitsFW + numUnitsBW)]
    1: cell final non-zero output for forward RNN  [batchSize x numUnitsFW]
    2: cell final non-zero output for backward RNN [batchSize x numUnitsBW]</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.static_rnn.html" title="class in org.nd4j.nativeblas">Nd4jCpu.static_rnn</a></span></code>
<div class="block">Implementation of operation "static RNN time sequences" with peep hole connections:

 Input arrays:
    0: input with shape [time x batchSize x inSize], time - number of time steps, batchSize - batch size, inSize - number of features
    1: input-to-hidden  weights, [inSize   x numUnits]
    2: hidden-to-hidden weights, [numUnits x numUnits]
    3: biases, [2*numUnits]
    4: (optional) initial cell output [batchSize x numUnits], that is at time step = 0
    5: (optional) vector with shape [batchSize] containing integer values within [0,time), each element of this vector set max time step per each input in batch, this provides no calculations for time >= maxTimeStep

 Output arrays:
    0: cell outputs [time x batchSize x numUnits]
    1: cell final non-zero output [batchSize x numUnits]</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.strided_slice.html" title="class in org.nd4j.nativeblas">Nd4jCpu.strided_slice</a></span></code>
<div class="block">This operation extracts a strided (optionally) slice from a tensor,</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.strided_slice_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.strided_slice_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.subtract.html" title="class in org.nd4j.nativeblas">Nd4jCpu.subtract</a></span></code>
<div class="block">This is one of auto-broadcastable operations.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.subtract_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.subtract_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.sufficient_statistics.html" title="class in org.nd4j.nativeblas">Nd4jCpu.sufficient_statistics</a></span></code>
<div class="block">sufficient_statistics operation return calculated mean and variation with data count.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.svd.html" title="class in org.nd4j.nativeblas">Nd4jCpu.svd</a></span></code>
<div class="block">performs singular value decomposition (SVD) of one or more matrices, evaluates the SVD of each inner-most 2D matrix in input array:
 x[..., :, :] = u[..., :, :] * s[...,:] * transpose(v[..., :, :]) 

 Input array:
 x[..., Rows, Cols], the necessary condition is: rank of x >= 2
 
 Outputs arrays:
 s[..., diagSize] - array with singular values which are stored in decreasing order, diagSize is smaller among Rows and Cols
 u[..., Rows, Rows] if IArgs[1] is true, else u[..., Rows, diagSize] - array with right singular vectors
 v[..., Cols, Cols] if IArgs[1] is true, else v[..., Cols, diagSize] - array with left singular vectors
 
 Integer arguments:
 IArgs[0] - bool, whether to calculate u and v, s is calculated in any case
 IArgs[1] - bool, whether to calculate full-sized u and v
 IArgs[2] - the number of cols or rows which determines what algorithm to use.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.tear.html" title="class in org.nd4j.nativeblas">Nd4jCpu.tear</a></span></code>
<div class="block">This operation splits input NDArray into multiple TADs along given dimensions
 Expected arguments:
 input: N-dimensional array

 Int args:
 0..: TAD axis</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.tensormmul.html" title="class in org.nd4j.nativeblas">Nd4jCpu.tensormmul</a></span></code>
<div class="block">tensorMmul/tensorDot operation
 takes 2 ndarrays, and 2 sets of axes

 Integer argumens map:
 IArgs[0] - number of axes along for first array
 IArgs[1]... axes values for first array
 IArgs[] - number of axes along for second array
 IArgs[1]... axes values for second array</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.test_scalar.html" title="class in org.nd4j.nativeblas">Nd4jCpu.test_scalar</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.testcustom.html" title="class in org.nd4j.nativeblas">Nd4jCpu.testcustom</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.tf_atan2.html" title="class in org.nd4j.nativeblas">Nd4jCpu.tf_atan2</a></span></code>
<div class="block">Special atan2 op impl for TF's args order
 \tparam T</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.tile.html" title="class in org.nd4j.nativeblas">Nd4jCpu.tile</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.tile_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.tile_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.tile_to_shape.html" title="class in org.nd4j.nativeblas">Nd4jCpu.tile_to_shape</a></span></code>
<div class="block">This op boosts specified input up to specified shape

 \tparam T</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.tile_to_shape_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.tile_to_shape_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.to_double.html" title="class in org.nd4j.nativeblas">Nd4jCpu.to_double</a></span></code>
<div class="block">This operation casts elements of input array to double data type
 
 PLEASE NOTE: This op is disabled atm, and reserved for future releases.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.to_float16.html" title="class in org.nd4j.nativeblas">Nd4jCpu.to_float16</a></span></code>
<div class="block">This operation casts elements of input array to float16 data type
 
 PLEASE NOTE: This op is disabled atm, and reserved for future releases.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.to_float32.html" title="class in org.nd4j.nativeblas">Nd4jCpu.to_float32</a></span></code>
<div class="block">This operation casts elements of input array to float data type
 
 PLEASE NOTE: This op is disabled atm, and reserved for future releases.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.to_int32.html" title="class in org.nd4j.nativeblas">Nd4jCpu.to_int32</a></span></code>
<div class="block">This operation casts elements of input array to int32 data type
 
 PLEASE NOTE: This op is disabled atm, and reserved for future releases.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.to_int64.html" title="class in org.nd4j.nativeblas">Nd4jCpu.to_int64</a></span></code>
<div class="block">This operation casts elements of input array to int64 (aka long long) data type
 
 PLEASE NOTE: This op is disabled atm, and reserved for future releases.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.to_uint32.html" title="class in org.nd4j.nativeblas">Nd4jCpu.to_uint32</a></span></code>
<div class="block">This operation casts elements of input array to unsinged int32 data type
 
 PLEASE NOTE: This op is disabled atm, and reserved for future releases.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.to_uint64.html" title="class in org.nd4j.nativeblas">Nd4jCpu.to_uint64</a></span></code>
<div class="block">This operation casts elements of input array to unsigned int64 (aka unsigned long long) data type
 
 PLEASE NOTE: This op is disabled atm, and reserved for future releases.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.top_k.html" title="class in org.nd4j.nativeblas">Nd4jCpu.top_k</a></span></code>
<div class="block">top_k operation returns a vector of k top values for
  given NDArray as tensor with default boolean (true)
  as sort for result index array
  will be sorted by the values in descending order.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.trace.html" title="class in org.nd4j.nativeblas">Nd4jCpu.trace</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.transpose.html" title="class in org.nd4j.nativeblas">Nd4jCpu.transpose</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.tri.html" title="class in org.nd4j.nativeblas">Nd4jCpu.tri</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.triu.html" title="class in org.nd4j.nativeblas">Nd4jCpu.triu</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.triu_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.triu_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.truncatediv.html" title="class in org.nd4j.nativeblas">Nd4jCpu.truncatediv</a></span></code>
<div class="block">\tparam T</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unique.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unique</a></span></code>
<div class="block">This operation returns unique elements from input array as vector, and their original indices in input array
 Expected input:
 input: N-dimensional array</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unique_with_counts.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unique_with_counts</a></span></code>
<div class="block">This operation returns 3 1D arrays for given 1D array with unique element count and indexes
 input:
     0 - 1D array

 output:
     0 - 1D array with unique values
     1 - 1D array with ids for values in array above
     2 - 1D array with counts for values in array above</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unsorted_segment_max.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unsorted_segment_max</a></span></code>
<div class="block">unsorted_segment_max op. - make a tensor filled by max values according to index tensor given.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unsorted_segment_max_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unsorted_segment_max_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unsorted_segment_mean.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unsorted_segment_mean</a></span></code>
<div class="block">unsorted_segment_mean op. - make a tensor filled by average of values according to index tensor given.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unsorted_segment_mean_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unsorted_segment_mean_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unsorted_segment_min.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unsorted_segment_min</a></span></code>
<div class="block">unsorted_segment_min op. - make a tensor filled by min values according to index tensor given.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unsorted_segment_min_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unsorted_segment_min_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unsorted_segment_prod.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unsorted_segment_prod</a></span></code>
<div class="block">unsorted_segment_prod op. - make a tensor filled by product of values according to index tensor given.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unsorted_segment_prod_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unsorted_segment_prod_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unsorted_segment_sqrt_n.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unsorted_segment_sqrt_n</a></span></code>
<div class="block">unsorted_segment_sqrt_n op. - computes the sum along segments of a tensor divided by the sqrt(N).</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unsorted_segment_sqrt_n_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unsorted_segment_sqrt_n_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unsorted_segment_sum.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unsorted_segment_sum</a></span></code>
<div class="block">unsorted_segment_sum op. - make a tensor filled by sum of values according to index tensor given.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unsorted_segment_sum_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unsorted_segment_sum_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.unstack.html" title="class in org.nd4j.nativeblas">Nd4jCpu.unstack</a></span></code>
<div class="block">This op does the same as tear, just uses different input format:
 \tparam T</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.upsampling2d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.upsampling2d</a></span></code>
<div class="block">Expected input: 4D array

 IntArgs:
 0: scale factor for rows (height)
 1: scale factor for columns (width)
 2: data format: 0 NHWC (default), 1 NCHW</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.upsampling2d_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.upsampling2d_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.upsampling3d.html" title="class in org.nd4j.nativeblas">Nd4jCpu.upsampling3d</a></span></code>
<div class="block">Expected input: 4D array

 IntArgs:
 0: scale factor for depth
 1: scale factor for rows (height)
 2: scale factor for columns (width)
 3: data format: 0 NDHWC (default), 1 NCDHW</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.upsampling3d_bp.html" title="class in org.nd4j.nativeblas">Nd4jCpu.upsampling3d_bp</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.Where.html" title="class in org.nd4j.nativeblas">Nd4jCpu.Where</a></span></code>
<div class="block">This op takes 2 n-dimensional arrays as input, and return 
 array of the same shape, with elements, either from x or y, depending on the condition.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.where_np.html" title="class in org.nd4j.nativeblas">Nd4jCpu.where_np</a></span></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.xw_plus_b.html" title="class in org.nd4j.nativeblas">Nd4jCpu.xw_plus_b</a></span></code>
<div class="block">xw_plus_b op.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.zero_fraction.html" title="class in org.nd4j.nativeblas">Nd4jCpu.zero_fraction</a></span></code>
<div class="block">zero_fraction op.</div>
</td>
</tr>
</tbody>
</table>
</li>
</ul>
</li>
</ul>
</div>
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="../package-summary.html">Package</a></li>
<li><a href="../../../../org/nd4j/nativeblas/Nd4jCpu.DeclarableCustomOp.html" title="class in org.nd4j.nativeblas">Class</a></li>
<li class="navBarCell1Rev">Use</li>
<li><a href="../package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-all.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev</li>
<li>Next</li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/nd4j/nativeblas/class-use/Nd4jCpu.DeclarableCustomOp.html" target="_top">Frames</a></li>
<li><a href="Nd4jCpu.DeclarableCustomOp.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
<p class="legalCopy"><small>Copyright &#169; 2020. All rights reserved.</small></p>
</body>
</html>
