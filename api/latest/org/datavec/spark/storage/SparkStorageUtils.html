<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (1.8.0_161) on Thu Aug 09 02:12:59 PDT 2018 -->
<title>SparkStorageUtils</title>
<meta name="date" content="2018-08-09">
<link rel="stylesheet" type="text/css" href="../../../../stylesheet.css" title="Style">
<script type="text/javascript" src="../../../../script.js"></script>
</head>
<body>
<script type="text/javascript"><!--
    try {
        if (location.href.indexOf('is-external=true') == -1) {
            parent.document.title="SparkStorageUtils";
        }
    }
    catch(err) {
    }
//-->
var methods = {"i0":9,"i1":9,"i2":9,"i3":9,"i4":9,"i5":9,"i6":9,"i7":9,"i8":9,"i9":9,"i10":9,"i11":9,"i12":9,"i13":9};
var tabs = {65535:["t0","All Methods"],1:["t1","Static Methods"],8:["t4","Concrete Methods"]};
var altColor = "altColor";
var rowColor = "rowColor";
var tableTab = "tableTab";
var activeTableTab = "activeTableTab";
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar.top">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.top" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.top.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev&nbsp;Class</li>
<li>Next&nbsp;Class</li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/datavec/spark/storage/SparkStorageUtils.html" target="_top">Frames</a></li>
<li><a href="SparkStorageUtils.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.datavec.spark.storage</div>
<h2 title="Class SparkStorageUtils" class="title">Class SparkStorageUtils</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.datavec.spark.storage.SparkStorageUtils</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<hr>
<br>
<pre>public class <span class="typeNameLabel">SparkStorageUtils</span>
extends java.lang.Object</pre>
<div class="block">Utility methods for saving and restoring Writable objects from Spark RDD is to Hadoop formats</div>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static int</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#DEFAULT_MAP_FILE_INTERVAL">DEFAULT_MAP_FILE_INTERVAL</a></span></code>
<div class="block">By default, a map file's index stores only a fraction of the keys.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>static java.lang.String</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#MAP_FILE_INDEX_INTERVAL_KEY">MAP_FILE_INDEX_INTERVAL_KEY</a></span></code>
<div class="block">Configuration key for the map file interval.</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method.summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="memberSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span id="t0" class="activeTableTab"><span>All Methods</span><span class="tabEnd">&nbsp;</span></span><span id="t1" class="tableTab"><span><a href="javascript:show(1);">Static Methods</a></span><span class="tabEnd">&nbsp;</span></span><span id="t4" class="tableTab"><span><a href="javascript:show(8);">Concrete Methods</a></span><span class="tabEnd">&nbsp;</span></span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr id="i0" class="altColor">
<td class="colFirst"><code>static org.apache.spark.api.java.JavaPairRDD&lt;java.lang.Long,java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreMapFile-java.lang.String-org.apache.spark.api.java.JavaSparkContext-">restoreMapFile</a></span>(java.lang.String&nbsp;path,
              org.apache.spark.api.java.JavaSparkContext&nbsp;sc)</code>
<div class="block">Restore a <code>JavaPairRDD&lt;Long,List&lt;Writable&gt;&gt;</code> previously saved with <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFile(String, JavaRDD)</code></a>}<br>
 Note that if the keys are not required, simply use <code>restoreMapFile(...).values()</code></div>
</td>
</tr>
<tr id="i1" class="rowColor">
<td class="colFirst"><code>static org.apache.spark.api.java.JavaPairRDD&lt;java.lang.Long,java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaSparkContext-">restoreMapFileSequences</a></span>(java.lang.String&nbsp;path,
                       org.apache.spark.api.java.JavaSparkContext&nbsp;sc)</code>
<div class="block">Restore a <code>JavaPairRDD&lt;Long,List&lt;List&lt;Writable&gt;&gt;&gt;</code> previously saved with <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFile(String, JavaRDD)</code></a>}<br>
 Note that if the keys are not required, simply use <code>restoreMapFileSequences(...).values()</code></div>
</td>
</tr>
<tr id="i2" class="altColor">
<td class="colFirst"><code>static org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreSequenceFile-java.lang.String-org.apache.spark.api.java.JavaSparkContext-">restoreSequenceFile</a></span>(java.lang.String&nbsp;path,
                   org.apache.spark.api.java.JavaSparkContext&nbsp;sc)</code>
<div class="block">Restore a <code>JavaRDD&lt;List&lt;Writable&gt;&gt;</code> previously saved with <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFile(String, JavaRDD)</code></a></div>
</td>
</tr>
<tr id="i3" class="rowColor">
<td class="colFirst"><code>static org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreSequenceFileSequences-java.lang.String-org.apache.spark.api.java.JavaSparkContext-">restoreSequenceFileSequences</a></span>(java.lang.String&nbsp;path,
                            org.apache.spark.api.java.JavaSparkContext&nbsp;sc)</code>
<div class="block">Restore a <code>JavaRDD&lt;List&lt;List&lt;Writable&gt;&gt;</code> previously saved with <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFileSequences(String, JavaRDD)</code></a></div>
</td>
</tr>
<tr id="i4" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-">saveMapFile</a></span>(java.lang.String&nbsp;path,
           org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&nbsp;rdd)</code>
<div class="block">Save a <code>JavaRDD&lt;List&lt;Writable&gt;&gt;</code> to a Hadoop <code>MapFile</code>.</div>
</td>
</tr>
<tr id="i5" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-org.apache.hadoop.conf.Configuration-java.lang.Integer-">saveMapFile</a></span>(java.lang.String&nbsp;path,
           org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&nbsp;rdd,
           org.apache.hadoop.conf.Configuration&nbsp;c,
           java.lang.Integer&nbsp;maxOutputFiles)</code>
<div class="block">Save a <code>JavaRDD&lt;List&lt;Writable&gt;&gt;</code> to a Hadoop <code>MapFile</code>.</div>
</td>
</tr>
<tr id="i6" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-int-java.lang.Integer-">saveMapFile</a></span>(java.lang.String&nbsp;path,
           org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&nbsp;rdd,
           int&nbsp;interval,
           java.lang.Integer&nbsp;maxOutputFiles)</code>
<div class="block">Save a <code>JavaRDD&lt;List&lt;Writable&gt;&gt;</code> to a Hadoop <code>MapFile</code>.</div>
</td>
</tr>
<tr id="i7" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-">saveMapFileSequences</a></span>(java.lang.String&nbsp;path,
                    org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;&nbsp;rdd)</code>
<div class="block">Save a <code>JavaRDD&lt;List&lt;List&lt;Writable&gt;&gt;&gt;</code> to a Hadoop <code>MapFile</code>.</div>
</td>
</tr>
<tr id="i8" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-org.apache.hadoop.conf.Configuration-java.lang.Integer-">saveMapFileSequences</a></span>(java.lang.String&nbsp;path,
                    org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;&nbsp;rdd,
                    org.apache.hadoop.conf.Configuration&nbsp;c,
                    java.lang.Integer&nbsp;maxOutputFiles)</code>
<div class="block">Save a <code>JavaRDD&lt;List&lt;List&lt;Writable&gt;&gt;&gt;</code> to a Hadoop <code>MapFile</code>.</div>
</td>
</tr>
<tr id="i9" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-int-java.lang.Integer-">saveMapFileSequences</a></span>(java.lang.String&nbsp;path,
                    org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;&nbsp;rdd,
                    int&nbsp;interval,
                    java.lang.Integer&nbsp;maxOutputFiles)</code>
<div class="block">Save a <code>JavaRDD&lt;List&lt;List&lt;Writable&gt;&gt;&gt;</code> to a Hadoop <code>MapFile</code>.</div>
</td>
</tr>
<tr id="i10" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-">saveSequenceFile</a></span>(java.lang.String&nbsp;path,
                org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&nbsp;rdd)</code>
<div class="block">Save a <code>JavaRDD&lt;List&lt;Writable&gt;&gt;</code> to a Hadoop <code>SequenceFile</code>.</div>
</td>
</tr>
<tr id="i11" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-java.lang.Integer-">saveSequenceFile</a></span>(java.lang.String&nbsp;path,
                org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&nbsp;rdd,
                java.lang.Integer&nbsp;maxOutputFiles)</code>
<div class="block">Save a <code>JavaRDD&lt;List&lt;Writable&gt;&gt;</code> to a Hadoop <code>SequenceFile</code>.</div>
</td>
</tr>
<tr id="i12" class="altColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-">saveSequenceFileSequences</a></span>(java.lang.String&nbsp;path,
                         org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;&nbsp;rdd)</code>
<div class="block">Save a <code>JavaRDD&lt;List&lt;List&lt;Writable&gt;&gt;&gt;</code> to a Hadoop <code>SequenceFile</code>.</div>
</td>
</tr>
<tr id="i13" class="rowColor">
<td class="colFirst"><code>static void</code></td>
<td class="colLast"><code><span class="memberNameLink"><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-java.lang.Integer-">saveSequenceFileSequences</a></span>(java.lang.String&nbsp;path,
                         org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;&nbsp;rdd,
                         java.lang.Integer&nbsp;maxOutputFiles)</code>
<div class="block">Save a <code>JavaRDD&lt;List&lt;List&lt;Writable&gt;&gt;&gt;</code> to a Hadoop <code>SequenceFile</code>.</div>
</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods.inherited.from.class.java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>clone, equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field.detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="MAP_FILE_INDEX_INTERVAL_KEY">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>MAP_FILE_INDEX_INTERVAL_KEY</h4>
<pre>public static final&nbsp;java.lang.String MAP_FILE_INDEX_INTERVAL_KEY</pre>
<div class="block">Configuration key for the map file interval.
 This is defined in MapFile.Writer.INDEX_INTERVAL but unfortunately that field is private, hence cannot be
 referenced here.</div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../constant-values.html#org.datavec.spark.storage.SparkStorageUtils.MAP_FILE_INDEX_INTERVAL_KEY">Constant Field Values</a></dd>
</dl>
</li>
</ul>
<a name="DEFAULT_MAP_FILE_INTERVAL">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>DEFAULT_MAP_FILE_INTERVAL</h4>
<pre>public static final&nbsp;int DEFAULT_MAP_FILE_INTERVAL</pre>
<div class="block">By default, a map file's index stores only a fraction of the keys. This is good, in that it reduces memory
 requirements (all keys are loaded into memory); however, it has a cost in terms of time taken for look up.
 Instead of using the default interval of 128, Will use a default interval of 1: given that the keys are LongWritable
 objects, the marginal increase in space is more than outweighed by the increased performance for use cases such as
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/MapFileRecordReader.html" title="class in org.datavec.hadoop.records.reader.mapfile"><code>MapFileRecordReader</code></a> and <a href="../../../../org/datavec/hadoop/records/reader/mapfile/MapFileSequenceRecordReader.html" title="class in org.datavec.hadoop.records.reader.mapfile"><code>MapFileSequenceRecordReader</code></a></div>
<dl>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../constant-values.html#org.datavec.spark.storage.SparkStorageUtils.DEFAULT_MAP_FILE_INTERVAL">Constant Field Values</a></dd>
</dl>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method.detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveSequenceFile</h4>
<pre>public static&nbsp;void&nbsp;saveSequenceFile(java.lang.String&nbsp;path,
                                    org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&nbsp;rdd)</pre>
<div class="block">Save a <code>JavaRDD&lt;List&lt;Writable&gt;&gt;</code> to a Hadoop <code>SequenceFile</code>. Each record is given
 a unique (but noncontiguous) <code>LongWritable</code> key, and values are stored as <a href="../../../../org/datavec/hadoop/records/reader/mapfile/record/RecordWritable.html" title="class in org.datavec.hadoop.records.reader.mapfile.record"><code>RecordWritable</code></a> instances.
 <p>
 Use <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreSequenceFile-java.lang.String-org.apache.spark.api.java.JavaSparkContext-"><code>restoreSequenceFile(String, JavaSparkContext)</code></a> to restore values saved with this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path to save the sequence file</dd>
<dd><code>rdd</code> - RDD to save</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFileSequences(String, JavaRDD)</code></a>, 
<a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFile(String, JavaRDD)</code></a></dd>
</dl>
</li>
</ul>
<a name="saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-java.lang.Integer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveSequenceFile</h4>
<pre>public static&nbsp;void&nbsp;saveSequenceFile(java.lang.String&nbsp;path,
                                    org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&nbsp;rdd,
                                    java.lang.Integer&nbsp;maxOutputFiles)</pre>
<div class="block">Save a <code>JavaRDD&lt;List&lt;Writable&gt;&gt;</code> to a Hadoop <code>SequenceFile</code>. Each record is given
 a unique (but noncontiguous) <code>LongWritable</code> key, and values are stored as <a href="../../../../org/datavec/hadoop/records/reader/mapfile/record/RecordWritable.html" title="class in org.datavec.hadoop.records.reader.mapfile.record"><code>RecordWritable</code></a> instances.
 <p>
 Use <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreSequenceFile-java.lang.String-org.apache.spark.api.java.JavaSparkContext-"><code>restoreSequenceFile(String, JavaSparkContext)</code></a> to restore values saved with this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path to save the sequence file</dd>
<dd><code>rdd</code> - RDD to save</dd>
<dd><code>maxOutputFiles</code> - Nullable. If non-null: first coalesce the RDD to the specified size (number of partitions)
                       to limit the maximum number of output sequence files</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFileSequences(String, JavaRDD)</code></a>, 
<a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFile(String, JavaRDD)</code></a></dd>
</dl>
</li>
</ul>
<a name="restoreSequenceFile-java.lang.String-org.apache.spark.api.java.JavaSparkContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>restoreSequenceFile</h4>
<pre>public static&nbsp;org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&nbsp;restoreSequenceFile(java.lang.String&nbsp;path,
                                                                                              org.apache.spark.api.java.JavaSparkContext&nbsp;sc)</pre>
<div class="block">Restore a <code>JavaRDD&lt;List&lt;Writable&gt;&gt;</code> previously saved with <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFile(String, JavaRDD)</code></a></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path of the sequence file</dd>
<dd><code>sc</code> - Spark context</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The restored RDD</dd>
</dl>
</li>
</ul>
<a name="saveSequenceFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveSequenceFileSequences</h4>
<pre>public static&nbsp;void&nbsp;saveSequenceFileSequences(java.lang.String&nbsp;path,
                                             org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;&nbsp;rdd)</pre>
<div class="block">Save a <code>JavaRDD&lt;List&lt;List&lt;Writable&gt;&gt;&gt;</code> to a Hadoop <code>SequenceFile</code>. Each record
 is given a unique (but noncontiguous) <code>LongWritable</code> key, and values are stored as <a href="../../../../org/datavec/hadoop/records/reader/mapfile/record/SequenceRecordWritable.html" title="class in org.datavec.hadoop.records.reader.mapfile.record"><code>SequenceRecordWritable</code></a> instances.
 <p>
 Use <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreSequenceFileSequences-java.lang.String-org.apache.spark.api.java.JavaSparkContext-"><code>restoreSequenceFileSequences(String, JavaSparkContext)</code></a> to restore values saved with this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path to save the sequence file</dd>
<dd><code>rdd</code> - RDD to save</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFile(String, JavaRDD)</code></a>, 
<a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFileSequences(String, JavaRDD)</code></a></dd>
</dl>
</li>
</ul>
<a name="saveSequenceFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-java.lang.Integer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveSequenceFileSequences</h4>
<pre>public static&nbsp;void&nbsp;saveSequenceFileSequences(java.lang.String&nbsp;path,
                                             org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;&nbsp;rdd,
                                             java.lang.Integer&nbsp;maxOutputFiles)</pre>
<div class="block">Save a <code>JavaRDD&lt;List&lt;List&lt;Writable&gt;&gt;&gt;</code> to a Hadoop <code>SequenceFile</code>. Each record
 is given a unique (but noncontiguous) <code>LongWritable</code> key, and values are stored as <a href="../../../../org/datavec/hadoop/records/reader/mapfile/record/SequenceRecordWritable.html" title="class in org.datavec.hadoop.records.reader.mapfile.record"><code>SequenceRecordWritable</code></a> instances.
 <p>
 Use <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreSequenceFileSequences-java.lang.String-org.apache.spark.api.java.JavaSparkContext-"><code>restoreSequenceFileSequences(String, JavaSparkContext)</code></a> to restore values saved with this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path to save the sequence file</dd>
<dd><code>rdd</code> - RDD to save</dd>
<dd><code>maxOutputFiles</code> - Nullable. If non-null: first coalesce the RDD to the specified size (number of partitions)
                       to limit the maximum number of output sequence files</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFile(String, JavaRDD)</code></a>, 
<a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFileSequences(String, JavaRDD)</code></a></dd>
</dl>
</li>
</ul>
<a name="restoreSequenceFileSequences-java.lang.String-org.apache.spark.api.java.JavaSparkContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>restoreSequenceFileSequences</h4>
<pre>public static&nbsp;org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;&nbsp;restoreSequenceFileSequences(java.lang.String&nbsp;path,
                                                                                                                       org.apache.spark.api.java.JavaSparkContext&nbsp;sc)</pre>
<div class="block">Restore a <code>JavaRDD&lt;List&lt;List&lt;Writable&gt;&gt;</code> previously saved with <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFileSequences(String, JavaRDD)</code></a></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path of the sequence file</dd>
<dd><code>sc</code> - Spark context</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The restored RDD</dd>
</dl>
</li>
</ul>
<a name="saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveMapFile</h4>
<pre>public static&nbsp;void&nbsp;saveMapFile(java.lang.String&nbsp;path,
                               org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&nbsp;rdd)</pre>
<div class="block">Save a <code>JavaRDD&lt;List&lt;Writable&gt;&gt;</code> to a Hadoop <code>MapFile</code>. Each record is
 given a <i>unique and contiguous</i> <code>LongWritable</code> key, and values are stored as
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/record/RecordWritable.html" title="class in org.datavec.hadoop.records.reader.mapfile.record"><code>RecordWritable</code></a> instances.<br>
 <b>Note 1</b>: If contiguous keys are not required, using a sequence file instead is preferable from a performance
 point of view. Contiguous keys are often only required for non-Spark use cases, such as with
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/MapFileRecordReader.html" title="class in org.datavec.hadoop.records.reader.mapfile"><code>MapFileRecordReader</code></a><br>
 <b>Note 2</b>: This use a MapFile interval of <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#DEFAULT_MAP_FILE_INTERVAL"><code>DEFAULT_MAP_FILE_INTERVAL</code></a>, which is usually suitable for
 use cases such as <a href="../../../../org/datavec/hadoop/records/reader/mapfile/MapFileRecordReader.html" title="class in org.datavec.hadoop.records.reader.mapfile"><code>MapFileRecordReader</code></a>. Use
 <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-int-java.lang.Integer-"><code>saveMapFile(String, JavaRDD, int, Integer)</code></a> or <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-org.apache.hadoop.conf.Configuration-java.lang.Integer-"><code>saveMapFile(String, JavaRDD, Configuration, Integer)</code></a>
 to customize this. <br>
 <p>
 Use <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreMapFile-java.lang.String-org.apache.spark.api.java.JavaSparkContext-"><code>restoreMapFile(String, JavaSparkContext)</code></a> to restore values saved with this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path to save the MapFile</dd>
<dd><code>rdd</code> - RDD to save</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFileSequences(String, JavaRDD)</code></a>, 
<a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFile(String, JavaRDD)</code></a></dd>
</dl>
</li>
</ul>
<a name="saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-int-java.lang.Integer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveMapFile</h4>
<pre>public static&nbsp;void&nbsp;saveMapFile(java.lang.String&nbsp;path,
                               org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&nbsp;rdd,
                               int&nbsp;interval,
                               java.lang.Integer&nbsp;maxOutputFiles)</pre>
<div class="block">Save a <code>JavaRDD&lt;List&lt;Writable&gt;&gt;</code> to a Hadoop <code>MapFile</code>. Each record is
 given a <i>unique and contiguous</i> <code>LongWritable</code> key, and values are stored as
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/record/RecordWritable.html" title="class in org.datavec.hadoop.records.reader.mapfile.record"><code>RecordWritable</code></a> instances.<br>
 <b>Note</b>: If contiguous keys are not required, using a sequence file instead is preferable from a performance
 point of view. Contiguous keys are often only required for non-Spark use cases, such as with
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/MapFileRecordReader.html" title="class in org.datavec.hadoop.records.reader.mapfile"><code>MapFileRecordReader</code></a>
 <p>
 Use <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaSparkContext-"><code>restoreMapFileSequences(String, JavaSparkContext)</code></a> to restore values saved with this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path to save the MapFile</dd>
<dd><code>rdd</code> - RDD to save</dd>
<dd><code>interval</code> - The map file index interval to use. Smaller values may result in the faster look up, at the
                       expense of more memory/disk use. However, usually the increase is relatively minor, due to
                       keys being stored as LongWritable objects</dd>
<dd><code>maxOutputFiles</code> - Nullable. If non-null: first coalesce the RDD to the specified size (number of partitions)
                       to limit the maximum number of output map files</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFileSequences(String, JavaRDD)</code></a>, 
<a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFile(String, JavaRDD)</code></a></dd>
</dl>
</li>
</ul>
<a name="saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-org.apache.hadoop.conf.Configuration-java.lang.Integer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveMapFile</h4>
<pre>public static&nbsp;void&nbsp;saveMapFile(java.lang.String&nbsp;path,
                               org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&nbsp;rdd,
                               org.apache.hadoop.conf.Configuration&nbsp;c,
                               java.lang.Integer&nbsp;maxOutputFiles)</pre>
<div class="block">Save a <code>JavaRDD&lt;List&lt;Writable&gt;&gt;</code> to a Hadoop <code>MapFile</code>. Each record is
 given a <i>unique and contiguous</i> <code>LongWritable</code> key, and values are stored as
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/record/RecordWritable.html" title="class in org.datavec.hadoop.records.reader.mapfile.record"><code>RecordWritable</code></a> instances.<br>
 <b>Note</b>: If contiguous keys are not required, using a sequence file instead is preferable from a performance
 point of view. Contiguous keys are often only required for non-Spark use cases, such as with
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/MapFileRecordReader.html" title="class in org.datavec.hadoop.records.reader.mapfile"><code>MapFileRecordReader</code></a>
 <p>
 Use <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaSparkContext-"><code>restoreMapFileSequences(String, JavaSparkContext)</code></a> to restore values saved with this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path to save the MapFile</dd>
<dd><code>rdd</code> - RDD to save</dd>
<dd><code>c</code> - Configuration object, used to customise options for the map file</dd>
<dd><code>maxOutputFiles</code> - Nullable. If non-null: first coalesce the RDD to the specified size (number of partitions)
                       to limit the maximum number of output map files</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFileSequences(String, JavaRDD)</code></a>, 
<a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFile(String, JavaRDD)</code></a></dd>
</dl>
</li>
</ul>
<a name="restoreMapFile-java.lang.String-org.apache.spark.api.java.JavaSparkContext-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>restoreMapFile</h4>
<pre>public static&nbsp;org.apache.spark.api.java.JavaPairRDD&lt;java.lang.Long,java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&nbsp;restoreMapFile(java.lang.String&nbsp;path,
                                                                                                            org.apache.spark.api.java.JavaSparkContext&nbsp;sc)</pre>
<div class="block">Restore a <code>JavaPairRDD&lt;Long,List&lt;Writable&gt;&gt;</code> previously saved with <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFile(String, JavaRDD)</code></a>}<br>
 Note that if the keys are not required, simply use <code>restoreMapFile(...).values()</code></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path of the MapFile</dd>
<dd><code>sc</code> - Spark context</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The restored RDD, with their unique indices as the key</dd>
</dl>
</li>
</ul>
<a name="saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveMapFileSequences</h4>
<pre>public static&nbsp;void&nbsp;saveMapFileSequences(java.lang.String&nbsp;path,
                                        org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;&nbsp;rdd)</pre>
<div class="block">Save a <code>JavaRDD&lt;List&lt;List&lt;Writable&gt;&gt;&gt;</code> to a Hadoop <code>MapFile</code>. Each record is
 given a <i>unique and contiguous</i> <code>LongWritable</code> key, and values are stored as
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/record/SequenceRecordWritable.html" title="class in org.datavec.hadoop.records.reader.mapfile.record"><code>SequenceRecordWritable</code></a> instances.<br>
 <b>Note 1</b>: If contiguous keys are not required, using a sequence file instead is preferable from a performance
 point of view. Contiguous keys are often only required for non-Spark use cases, such as with
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/MapFileSequenceRecordReader.html" title="class in org.datavec.hadoop.records.reader.mapfile"><code>MapFileSequenceRecordReader</code></a><br>
 <b>Note 2</b>: This use a MapFile interval of <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#DEFAULT_MAP_FILE_INTERVAL"><code>DEFAULT_MAP_FILE_INTERVAL</code></a>, which is usually suitable for
 use cases such as <a href="../../../../org/datavec/hadoop/records/reader/mapfile/MapFileSequenceRecordReader.html" title="class in org.datavec.hadoop.records.reader.mapfile"><code>MapFileSequenceRecordReader</code></a>. Use
 <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-int-java.lang.Integer-"><code>saveMapFileSequences(String, JavaRDD, int, Integer)</code></a> or <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-org.apache.hadoop.conf.Configuration-java.lang.Integer-"><code>saveMapFileSequences(String, JavaRDD, Configuration, Integer)</code></a>
 to customize this. <br>
 <p>
 Use <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaSparkContext-"><code>restoreMapFileSequences(String, JavaSparkContext)</code></a> to restore values saved with this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path to save the MapFile</dd>
<dd><code>rdd</code> - RDD to save</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFileSequences(String, JavaRDD)</code></a>, 
<a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFile(String, JavaRDD)</code></a></dd>
</dl>
</li>
</ul>
<a name="saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-int-java.lang.Integer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveMapFileSequences</h4>
<pre>public static&nbsp;void&nbsp;saveMapFileSequences(java.lang.String&nbsp;path,
                                        org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;&nbsp;rdd,
                                        int&nbsp;interval,
                                        java.lang.Integer&nbsp;maxOutputFiles)</pre>
<div class="block">Save a <code>JavaRDD&lt;List&lt;List&lt;Writable&gt;&gt;&gt;</code> to a Hadoop <code>MapFile</code>. Each record is
 given a <i>unique and contiguous</i> <code>LongWritable</code> key, and values are stored as
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/record/SequenceRecordWritable.html" title="class in org.datavec.hadoop.records.reader.mapfile.record"><code>SequenceRecordWritable</code></a> instances.<br>
 <b>Note</b>: If contiguous keys are not required, using a sequence file instead is preferable from a performance
 point of view. Contiguous keys are often only required for non-Spark use cases, such as with
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/MapFileSequenceRecordReader.html" title="class in org.datavec.hadoop.records.reader.mapfile"><code>MapFileSequenceRecordReader</code></a><br>
 <p>
 Use <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaSparkContext-"><code>restoreMapFileSequences(String, JavaSparkContext)</code></a> to restore values saved with this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path to save the MapFile</dd>
<dd><code>rdd</code> - RDD to save</dd>
<dd><code>interval</code> - The map file index interval to use. Smaller values may result in the faster look up, at the
                 expense of more memory/disk use. However, usually the increase is relatively minor, due to
                 keys being stored as LongWritable objects</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFileSequences(String, JavaRDD)</code></a>, 
<a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFile(String, JavaRDD)</code></a></dd>
</dl>
</li>
</ul>
<a name="saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-org.apache.hadoop.conf.Configuration-java.lang.Integer-">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>saveMapFileSequences</h4>
<pre>public static&nbsp;void&nbsp;saveMapFileSequences(java.lang.String&nbsp;path,
                                        org.apache.spark.api.java.JavaRDD&lt;java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;&nbsp;rdd,
                                        org.apache.hadoop.conf.Configuration&nbsp;c,
                                        java.lang.Integer&nbsp;maxOutputFiles)</pre>
<div class="block">Save a <code>JavaRDD&lt;List&lt;List&lt;Writable&gt;&gt;&gt;</code> to a Hadoop <code>MapFile</code>. Each record is
 given a <i>unique and contiguous</i> <code>LongWritable</code> key, and values are stored as
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/record/SequenceRecordWritable.html" title="class in org.datavec.hadoop.records.reader.mapfile.record"><code>SequenceRecordWritable</code></a> instances.<br>
 <b>Note</b>: If contiguous keys are not required, using a sequence file instead is preferable from a performance
 point of view. Contiguous keys are often only required for non-Spark use cases, such as with
 <a href="../../../../org/datavec/hadoop/records/reader/mapfile/MapFileSequenceRecordReader.html" title="class in org.datavec.hadoop.records.reader.mapfile"><code>MapFileSequenceRecordReader</code></a><br>
 <p>
 Use <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#restoreMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaSparkContext-"><code>restoreMapFileSequences(String, JavaSparkContext)</code></a> to restore values saved with this method.</div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path to save the MapFile</dd>
<dd><code>rdd</code> - RDD to save</dd>
<dd><code>c</code> - Configuration object, used to customise options for the map file</dd>
<dt><span class="seeLabel">See Also:</span></dt>
<dd><a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFileSequences(String, JavaRDD)</code></a>, 
<a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveSequenceFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveSequenceFile(String, JavaRDD)</code></a></dd>
</dl>
</li>
</ul>
<a name="restoreMapFileSequences-java.lang.String-org.apache.spark.api.java.JavaSparkContext-">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>restoreMapFileSequences</h4>
<pre>public static&nbsp;org.apache.spark.api.java.JavaPairRDD&lt;java.lang.Long,java.util.List&lt;java.util.List&lt;<a href="../../../../org/datavec/api/writable/Writable.html" title="interface in org.datavec.api.writable">Writable</a>&gt;&gt;&gt;&nbsp;restoreMapFileSequences(java.lang.String&nbsp;path,
                                                                                                                                     org.apache.spark.api.java.JavaSparkContext&nbsp;sc)</pre>
<div class="block">Restore a <code>JavaPairRDD&lt;Long,List&lt;List&lt;Writable&gt;&gt;&gt;</code> previously saved with <a href="../../../../org/datavec/spark/storage/SparkStorageUtils.html#saveMapFile-java.lang.String-org.apache.spark.api.java.JavaRDD-"><code>saveMapFile(String, JavaRDD)</code></a>}<br>
 Note that if the keys are not required, simply use <code>restoreMapFileSequences(...).values()</code></div>
<dl>
<dt><span class="paramLabel">Parameters:</span></dt>
<dd><code>path</code> - Path of the MapFile</dd>
<dd><code>sc</code> - Spark context</dd>
<dt><span class="returnLabel">Returns:</span></dt>
<dd>The restored RDD, with their unique indices as the key</dd>
</dl>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar.bottom">
<!--   -->
</a>
<div class="skipNav"><a href="#skip.navbar.bottom" title="Skip navigation links">Skip navigation links</a></div>
<a name="navbar.bottom.firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev&nbsp;Class</li>
<li>Next&nbsp;Class</li>
</ul>
<ul class="navList">
<li><a href="../../../../index.html?org/datavec/spark/storage/SparkStorageUtils.html" target="_top">Frames</a></li>
<li><a href="SparkStorageUtils.html" target="_top">No&nbsp;Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../../allclasses-noframe.html">All&nbsp;Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li>Nested&nbsp;|&nbsp;</li>
<li><a href="#field.summary">Field</a>&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field.detail">Field</a>&nbsp;|&nbsp;</li>
<li>Constr&nbsp;|&nbsp;</li>
<li><a href="#method.detail">Method</a></li>
</ul>
</div>
<a name="skip.navbar.bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
